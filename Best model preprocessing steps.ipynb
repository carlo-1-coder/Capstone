{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFE, RFECV, VarianceThreshold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, permutation_test_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import shap\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "import dice_ml\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return specificity\n",
    "\n",
    "specificity_scorer = make_scorer(specificity_score)\n",
    "\n",
    "def npv_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    npv = tn / (tn + fn)\n",
    "    return npv\n",
    "\n",
    "npv_scorer = make_scorer(npv_score)\n",
    "\n",
    "g_mean_scorer = make_scorer(geometric_mean_score)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(10, shuffle=True, random_state=0)\n",
    "\n",
    "# def get_cat_cols(df):\n",
    "#     one_hot_encoded_columns = []\n",
    "\n",
    "#     for idx, column in enumerate(df.columns):\n",
    "#         if df[column].nunique() == 2 and set(df[column].unique()) == {0, 1}:\n",
    "#             one_hot_encoded_columns.append(idx)\n",
    "\n",
    "#     return one_hot_encoded_columns\n",
    "\n",
    "def get_cat_cols(df):\n",
    "    return df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# get_cat_cols(ho_t02)\n",
    "# cat_cols = get_cat_cols(ho_t02)\n",
    "# num_cols = [col for col in ho_t02.columns if col not in cat_cols]\n",
    "# cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "dataset = pd.read_csv('data/df_merged_no_nans.csv')\n",
    "# dataset = dataset.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Creating 'daysFromDateEntryStart'\n",
    "dataset['dateEntry'] = pd.to_datetime(dataset['dateEntry'], format='%Y-%m-%d')\n",
    "dateEntryStart = pd.to_datetime('2022-03-28', format='%Y-%m-%d')\n",
    "dataset['daysFromDateEntryStart'] = (dataset['dateEntry'] - dateEntryStart).dt.days\n",
    "\n",
    "# Dropping irrelevant columns\n",
    "cols_to_drop = [\n",
    "    'id', 'fullName', 'firstName', 'lastName', 'address', 'occupation', 'dateEntry'\n",
    "]\n",
    "dataset = dataset.drop(cols_to_drop, axis=1)\n",
    "\n",
    "boolean_columns = [col for col in dataset.columns if dataset[col].dtype == bool]\n",
    "dataset[boolean_columns] = dataset[boolean_columns].apply(lambda x: x.astype('int'))\n",
    "\n",
    "columns_to_move = ['lastFirstName', 'age', 'gender', 'province', 'job']\n",
    "columns_remaining = [col for col in dataset.columns if col not in columns_to_move]\n",
    "\n",
    "new_column_order = columns_to_move + columns_remaining\n",
    "dataset = dataset[new_column_order]\n",
    "dataset.insert(0, 'userId', dataset.pop('userId'))\n",
    "\n",
    "def map_ageing_class(row):\n",
    "    found_in_hdmf = row['foundInHDMF']\n",
    "    home_ownership_class = row['home_ownership_class']\n",
    "\n",
    "    if home_ownership_class == 0:\n",
    "        return np.nan\n",
    "    elif found_in_hdmf in [' Current', 'FP', '01 mos', '02 mos', '03 mos']:\n",
    "        return 0\n",
    "    elif found_in_hdmf in ['04 mos', '05 mos']:\n",
    "        return 1\n",
    "\n",
    "# One-hot encoding of categorical columns\n",
    "# dataset = pd.get_dummies(dataset, columns=['gender'], prefix='gender', drop_first='True')\n",
    "# dataset = pd.get_dummies(dataset, columns=['province'], prefix='province')\n",
    "# dataset = pd.get_dummies(dataset, columns=['job'], prefix='job')\n",
    "\n",
    "dataset['home_ownership_class'] = ((dataset['foundInOS'] != 'False') |\n",
    "                                   (dataset['foundInHDMF'] != 'False')).astype('int')\n",
    "\n",
    "# dataset['ageing_class'] = dataset['home_ownership_class'].astype('int64')\n",
    "# dataset['ageing_class'] = dataset.apply(map_ageing_class, axis=1)\n",
    "\n",
    "cols_to_drop = ['foundInOS', 'foundInHDMF']\n",
    "dataset = dataset.drop(cols_to_drop, axis=1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()\n",
    "\n",
    "df['monthlyUtilityBills'] = (\n",
    "    df['water'] + df['electricity'] + df['rent'] +\n",
    "    df['internet'] + df['mobileLoad']\n",
    ")\n",
    "df['monthlyVices'] = (\n",
    "    df['smoking'] + df['alcohol'] + df['gambling'] +\n",
    "    df['smallLottery'] + df['otherVices']\n",
    ")\n",
    "df['monthlyExpenses'] = (\n",
    "    df['food'] + df['hygiene'] + df['houseCleaning'] +\n",
    "    df['fare'] + df['parking'] + df['gasoline'] +\n",
    "    df['tuition'] + df['allowance'] + df['uniform'] +\n",
    "    df['otherEducation'] + df['emergency'] + df['medicine'] +\n",
    "    df['repair'] + df['cinema'] + df['dineOut'] +\n",
    "    df['leisure'] + df['personalCare'] + df['clothing'] +\n",
    "    df['vehicleLoan'] + df['monthlyUtilityBills'] +\n",
    "    df['informalLenders'] + df['companyLoan'] + df['privateLoans'] +\n",
    "    df['governmentLoans'] + df['monthlyVices']\n",
    ")\n",
    "df['monthlySoloNetIncome'] = (\n",
    "    df['basicMonthlySalary'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positiveMonthlySoloNetIncome'] = (\n",
    "    df['monthlySoloNetIncome'] > 0\n",
    ").astype(int)\n",
    "df['monthlyFamilyNetIncome'] = (\n",
    "    df['monthlyFamilyIncome'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positiveMonthlyFamilyNetIncome'] = (\n",
    "    df['monthlyFamilyNetIncome'] > 0\n",
    ").astype(int)\n",
    "df['monthlySoloNetIncomeWithSavings'] = (\n",
    "    df['basicMonthlySalary'] + df['savings'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positiveMonthlySoloNetIncomeWithSavings'] = (\n",
    "    df['monthlySoloNetIncomeWithSavings'] > 0\n",
    ").astype(int)\n",
    "df['monthlyFamilyNetIncomeWithSavings'] = (\n",
    "    df['monthlyFamilyIncome'] + df['savings'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positiveMonthlyFamilyNetIncomeWithSavings'] = (\n",
    "    df['monthlyFamilyNetIncomeWithSavings'] > 0\n",
    ").astype(int)\n",
    "df['monthlyFamilyIncome - basicMonthlySalary'] = (\n",
    "    df['monthlyFamilyIncome'] - df['basicMonthlySalary']\n",
    ")\n",
    "df['positive monthlyFamilyIncome - basicMonthlySalary'] = (\n",
    "    df['monthlyFamilyIncome - basicMonthlySalary'] > 0\n",
    ").astype(int)\n",
    "df['basicMonthlySalary - monthlyExpenses'] = (\n",
    "    df['basicMonthlySalary'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positive basicMonthlySalary - monthlyExpenses'] = (\n",
    "    df['basicMonthlySalary - monthlyExpenses'] > 0\n",
    ").astype(int)\n",
    "df['monthlyFamilyIncome - monthlyExpenses'] = (\n",
    "    df['monthlyFamilyIncome'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positive monthlyFamilyIncome - monthlyExpenses'] = (\n",
    "    df['monthlyFamilyIncome - monthlyExpenses'] > 0\n",
    ").astype(int)\n",
    "df['basicMonthlySalary / monthlyFamilyIncome'] = np.where(\n",
    "    df['monthlyFamilyIncome'] == 0,\n",
    "    np.nan,\n",
    "    df['basicMonthlySalary'] / df['monthlyFamilyIncome']\n",
    ")\n",
    "df['monthlyExpenses / basicMonthlySalary'] = np.where(\n",
    "    df['basicMonthlySalary'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyExpenses'] / df['basicMonthlySalary']\n",
    ")\n",
    "df['monthlyExpenses / monthlyFamilyIncome'] = np.where(\n",
    "    df['monthlyFamilyIncome'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyExpenses'] / df['monthlyFamilyIncome']\n",
    ")\n",
    "df['monthlyVices / basicMonthlySalary'] = np.where(\n",
    "    df['basicMonthlySalary'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyVices'] / df['basicMonthlySalary']\n",
    ")\n",
    "df['monthlyVices / monthlyFamilyIncome'] = np.where(\n",
    "    df['monthlyFamilyIncome'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyVices'] / df['monthlyFamilyIncome']\n",
    ")\n",
    "df['basicMonthlySalary / workingFamilyCount'] = np.where(\n",
    "    df['workingFamilyCount'] == 0,\n",
    "    np.nan,\n",
    "    df['basicMonthlySalary'] / df['workingFamilyCount']\n",
    ")\n",
    "df['basicMonthlySalary / residentsCount'] = np.where(\n",
    "    df['residentsCount'] == 0,\n",
    "    np.nan,\n",
    "    df['basicMonthlySalary'] / df['residentsCount']\n",
    ")\n",
    "df['monthlyFamilyIncome / workingFamilyCount'] = np.where(\n",
    "    df['workingFamilyCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyFamilyIncome'] / df['workingFamilyCount']\n",
    ")\n",
    "df['monthlyFamilyIncome / residentsCount'] = np.where(\n",
    "    df['residentsCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyFamilyIncome'] / df['residentsCount']\n",
    ")\n",
    "df['monthlyExpenses / workingFamilyCount'] = np.where(\n",
    "    df['workingFamilyCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyExpenses'] / df['workingFamilyCount']\n",
    ")\n",
    "df['monthlyExpenses / residentsCount'] = np.where(\n",
    "    df['residentsCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyExpenses'] / df['residentsCount']\n",
    ")\n",
    "df['monthlyUtilityBills / workingFamilyCount'] = np.where(\n",
    "    df['workingFamilyCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyUtilityBills'] / df['workingFamilyCount']\n",
    ")\n",
    "df['monthlyUtilityBills / residentsCount'] = np.where(\n",
    "    df['residentsCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyUtilityBills'] / df['residentsCount']\n",
    ")\n",
    "dataset = df.copy()\n",
    "\n",
    "# Convert all int32 columns to int64\n",
    "for col in dataset.select_dtypes(include='int32').columns:\n",
    "    dataset[col] = dataset[col].astype('int64')\n",
    "\n",
    "dataset['userId'] = dataset['userId'].astype(str)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_nulls = [\n",
    "    'monthlyExpenses / basicMonthlySalary',\n",
    "    'monthlyVices / basicMonthlySalary',\n",
    "    'basicMonthlySalary / workingFamilyCount',\n",
    "    'basicMonthlySalary / residentsCount',\n",
    "    'monthlyFamilyIncome / workingFamilyCount',\n",
    "    'monthlyFamilyIncome / residentsCount',\n",
    "    'monthlyExpenses / workingFamilyCount',\n",
    "    'monthlyExpenses / residentsCount',\n",
    "    'monthlyUtilityBills / workingFamilyCount',\n",
    "    'monthlyUtilityBills / residentsCount'\n",
    "]\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating `t01` - dataset used for the modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = dataset.copy().drop(columns=cols_with_nulls)\n",
    "# t01_num = t01.drop(columns=['gender', 'province', 'job'])\n",
    "t01 = pd.get_dummies(t01, columns=['gender'], prefix='gender', drop_first='True')\n",
    "t01 = pd.get_dummies(t01, columns=['province'], prefix='province', drop_first='True')\n",
    "t01 = pd.get_dummies(t01, columns=['job'], prefix='job', drop_first='True')\n",
    "\n",
    "t01.isna().sum()[t01.isna().sum() > 0]\n",
    "# t01 = t01.loc[:, ['userId', 'lastFirstName', ]]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
