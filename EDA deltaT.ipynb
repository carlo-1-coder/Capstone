{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_data_types(df):\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].unique()\n",
    "        if df[col].dtypes == 'object':\n",
    "            None\n",
    "#         elif (set(unique_vals) == {0, 1}) or col == 'userId':\n",
    "#             df[col] = df[col].astype('int64')\n",
    "#         else:\n",
    "#             df[col] = df[col].astype('float64')\n",
    "        elif (set(unique_vals) != {0, 1}):\n",
    "            df[col] = df[col].astype('float64')\n",
    "        else:\n",
    "            df[col] = df[col].astype('int64')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ho_t02['userId'] = ho_t02['userId'].astype('str')\n",
    "# ho_t02 = adjust_data_types(ho_t02)\n",
    "# ho_t02.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "UserConfigValidationException will be deprecated from dice_ml.utils. Please import UserConfigValidationException from raiutils.exceptions.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFE, RFECV, VarianceThreshold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, permutation_test_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import shap\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "import dice_ml\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return specificity\n",
    "\n",
    "specificity_scorer = make_scorer(specificity_score)\n",
    "\n",
    "def npv_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    npv = tn / (tn + fn)\n",
    "    return npv\n",
    "\n",
    "npv_scorer = make_scorer(npv_score)\n",
    "\n",
    "g_mean_scorer = make_scorer(geometric_mean_score)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(10, shuffle=True, random_state=0)\n",
    "\n",
    "# def get_cat_cols(df):\n",
    "#     one_hot_encoded_columns = []\n",
    "\n",
    "#     for idx, column in enumerate(df.columns):\n",
    "#         if df[column].nunique() == 2 and set(df[column].unique()) == {0, 1}:\n",
    "#             one_hot_encoded_columns.append(idx)\n",
    "\n",
    "#     return one_hot_encoded_columns\n",
    "\n",
    "def get_cat_cols(df):\n",
    "    return df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# get_cat_cols(ho_t02)\n",
    "# cat_cols = get_cat_cols(ho_t02)\n",
    "# num_cols = [col for col in ho_t02.columns if col not in cat_cols]\n",
    "# cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DropCategoricalFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Assuming X is a DataFrame\n",
    "        non_categorical_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "        return X[non_categorical_cols]\n",
    "\n",
    "\n",
    "def knn_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [StandardScaler(),\n",
    "#                    MinMaxScaler(),\n",
    "#                    RobustScaler()\n",
    "#                   ],\n",
    "#         'resampling': [SMOTE(random_state=random_state),\n",
    "#                        SMOTENC(categorical_features=get_cat_cols(X),\n",
    "#                                random_state=random_state),\n",
    "#                        ADASYN(random_state=random_state),\n",
    "# #                        RandomOverSampler(random_state=random_state),\n",
    "#                        RandomUnderSampler(random_state=random_state)],\n",
    "#         'scaler': [RobustScaler(),\n",
    "#                    PowerTransformer()],\n",
    "#         'resampling': [SMOTENC(categorical_features=get_cat_cols(X),\n",
    "#                                random_state=random_state),\n",
    "        'resampling': [\n",
    "            SMOTE(random_state=random_state),\n",
    "            ADASYN(random_state=random_state),\n",
    "#             SMOTEENN(random_state=random_state),\n",
    "#             SMOTETomek(random_state=random_state),\n",
    "            EditedNearestNeighbours(),\n",
    "#             TomekLinks(),\n",
    "            RandomOverSampler(random_state=random_state),\n",
    "            RandomUnderSampler(random_state=random_state)\n",
    "        ],\n",
    "        'classifier__n_neighbors': list(range(1, 16)),\n",
    "        'classifier__metric': ['euclidean', 'cosine', 'hamming', 'braycurtis',\n",
    "                               'chebyshev', 'canberra', 'cityblock', 'sqeuclidean'\n",
    "                              ]\n",
    "    }\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "def svm_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', SVC(random_state=random_state, max_iter=1000,\n",
    "                           verbose=True))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [StandardScaler(),\n",
    "#                    MinMaxScaler(),\n",
    "#                    RobustScaler()\n",
    "#         ],\n",
    "        'resampling': [SMOTE(random_state=random_state),\n",
    "                       ADASYN(random_state=random_state),\n",
    "#                        SMOTEENN(random_state=random_state),\n",
    "#                        SMOTETomek(random_state=random_state),\n",
    "                       EditedNearestNeighbours(),\n",
    "#                        TomekLinks(),\n",
    "                       RandomOverSampler(random_state=random_state),\n",
    "                       RandomUnderSampler(random_state=random_state)],\n",
    "        'classifier__C': list(np.logspace(-6, 6, num=13)),\n",
    "        'classifier__probability': [True, False],\n",
    "        'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "def logreg_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     pca = PCA().fit(X_scaled)\n",
    "\n",
    "#     # 2. Plot the cumulative explained variance\n",
    "#     explained_var_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_explained_var = np.cumsum(explained_var_ratio)\n",
    "\n",
    "#     # 3. Find the number of components that explain up to 90% of the variance\n",
    "#     num_components = np.argmax(cumulative_explained_var >= 0.90) + 1\n",
    "#     print(f\"Number of components that explain up to 90% of variance: {num_components}\")\n",
    "\n",
    "#     # Refit PCA with the selected number of components\n",
    "#     pca_90 = PCA(n_components=num_components)\n",
    "#     X = pca_90.fit_transform(X_scaled)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "#         ('drop_categorical', None),\n",
    "#         ('encoder', None),\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', LogisticRegression(random_state=random_state, max_iter=1000))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'drop_categorical': [None, DropCategoricalFeatures()]\n",
    "#         'encoder': [None, OneHotEncoder(sparse_output=False)],\n",
    "#         'scaler': [\n",
    "#             StandardScaler(),\n",
    "#             MinMaxScaler(),\n",
    "#             RobustScaler()\n",
    "#         ],\n",
    "        'resampling': [SMOTE(random_state=random_state),\n",
    "                       ADASYN(random_state=random_state),\n",
    "#                        SMOTEENN(random_state=random_state),\n",
    "#                        SMOTETomek(random_state=random_state),\n",
    "                       EditedNearestNeighbours(),\n",
    "#                        TomekLinks(),\n",
    "                       RandomOverSampler(random_state=random_state),\n",
    "                       RandomUnderSampler(random_state=random_state)],\n",
    "        'classifier__C': list(np.logspace(-6, 6, num=13)),\n",
    "        'classifier__penalty': ['l2', None],\n",
    "        'classifier__solver': ['liblinear', 'lbfgs', 'newton-cholesky']\n",
    "#         'classifier__penalty': ['l1', l2', 'elasticnet', 'None']\n",
    "    }\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "\n",
    "\n",
    "def dt_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     pca = PCA().fit(X_scaled)\n",
    "\n",
    "#     # 2. Plot the cumulative explained variance\n",
    "#     explained_var_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_explained_var = np.cumsum(explained_var_ratio)\n",
    "\n",
    "#     # 3. Find the number of components that explain up to 90% of the variance\n",
    "#     num_components = np.argmax(cumulative_explained_var >= 0.90) + 1\n",
    "#     print(f\"Number of components that explain up to 90% of variance: {num_components}\")\n",
    "\n",
    "#     # Refit PCA with the selected number of components\n",
    "#     pca_90 = PCA(n_components=num_components)\n",
    "#     X = pca_90.fit_transform(X_scaled)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    cat_cols = get_cat_cols(X_train)\n",
    "    num_cols = [col for col in X_train.columns if col not in cat_cols]\n",
    "\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', DecisionTreeClassifier(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [\n",
    "#             StandardScaler(), \n",
    "#             RobustScaler(),\n",
    "#             MinMaxScaler()\n",
    "#         ],\n",
    "        'resampling': [\n",
    "            SMOTE(random_state=random_state),\n",
    "            ADASYN(random_state=random_state),\n",
    "            SMOTEENN(random_state=random_state),\n",
    "            SMOTETomek(random_state=random_state),\n",
    "            EditedNearestNeighbours(),\n",
    "            TomekLinks(),\n",
    "            RandomOverSampler(random_state=random_state),\n",
    "            RandomUnderSampler(random_state=random_state)\n",
    "        ],\n",
    "#         'classifier__max_depth': [3],\n",
    "# #         'classifier__min_samples_split': [1],\n",
    "#         'classifier__min_samples_leaf': [1],\n",
    "#         'classifier__max_depth': [2, 5],\n",
    "#         'classifier__min_samples_split': [3],\n",
    "#         'classifier__min_samples_leaf': [3],\n",
    "# #         'classifier__max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#         'classifier__criterion': [\"entropy\", \"log_loss\"]\n",
    "#         'classifier__max_depth': [2, 3],\n",
    "#         'classifier__min_samples_split': [1],\n",
    "#         'classifier__min_samples_leaf': [2, 3],\n",
    "        'classifier__max_depth': [2, 3, 5],\n",
    "        'classifier__min_samples_split': [2, 3],\n",
    "        'classifier__min_samples_leaf': [1, 2, 3],\n",
    "        'classifier__max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'classifier__criterion': [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    }\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "#                                cv=10, scoring=scorer,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def rf_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "#     df_majority = df[df.home_ownership_class == 0]\n",
    "#     df_minority = df[df.home_ownership_class == 1]\n",
    "\n",
    "# #     display(df_majority)\n",
    "# #     display(df_minority)\n",
    "# #     print(len(df_majority), len(df_minority))\n",
    "#     # Randomly downsample majority class\n",
    "#     df_majority_downsampled = df_majority.sample(frac=0.2,\n",
    "#                                                  random_state=random_state)\n",
    "#     df = pd.concat([df_majority_downsampled, df_minority], axis=0)\n",
    "\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     pca = PCA().fit(X_scaled)\n",
    "\n",
    "#     # 2. Plot the cumulative explained variance\n",
    "#     explained_var_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_explained_var = np.cumsum(explained_var_ratio)\n",
    "\n",
    "#     # 3. Find the number of components that explain up to 90% of the variance\n",
    "#     num_components = np.argmax(cumulative_explained_var >= 0.90) + 1\n",
    "#     print(f\"Number of components that explain up to 90% of variance: {num_components}\")\n",
    "\n",
    "#     # Refit PCA with the selected number of components\n",
    "#     pca_90 = PCA(n_components=num_components)\n",
    "#     X = pca_90.fit_transform(X_scaled)\n",
    "\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#     n_components = X_scaled.shape[1]  # Maximum number of components\n",
    "#     svd = TruncatedSVD(n_components=n_components)\n",
    "#     X_svd = svd.fit_transform(X_scaled)\n",
    "\n",
    "#     # Step 3: Find number of components that explain at least 90% variance\n",
    "#     cum_variance = np.cumsum(svd.explained_variance_ratio_)\n",
    "#     num_components = np.argmax(cum_variance >= 0.90) + 1  # +1 because Python indexing starts from 0\n",
    "#     X_selected = X_svd[:, :num_components]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "#     X_resampled, y_resampled = RandomOverSampler(random_state=random_state).fit_resample(X_train, y_train)\n",
    "#     class_counts_original = np.bincount(y_train.astype(int))\n",
    "#     class_counts_resampled = np.bincount(y_resampled.astype(int))\n",
    "\n",
    "    # Assuming 0 is the majority class, calculate its upweight factor\n",
    "#     majority_class_original = class_counts_original[0]\n",
    "#     majority_class_resampled = class_counts_resampled[0]\n",
    "#     upweight_factor = majority_class_original / majority_class_resampled\n",
    "\n",
    "#     minority_class_original = class_counts_original[1]\n",
    "#     minority_class_resampled = class_counts_resampled[1]\n",
    "#     downweight_factor = minority_class_original / minority_class_resampled\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', RandomForestClassifier(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [\n",
    "#             StandardScaler(),\n",
    "#             MinMaxScaler(),\n",
    "#             RobustScaler()\n",
    "#         ],\n",
    "#         'resampling': [SMOTE(random_state=random_state),\n",
    "#                        SMOTENC(categorical_features=get_cat_cols(X),\n",
    "#                                random_state=random_state),\n",
    "#                        ADASYN(random_state=random_state),\n",
    "# #                        RandomOverSampler(random_state=random_state),\n",
    "#                        RandomUnderSampler(random_state=random_state)],\n",
    "#         'scaler': [RobustScaler(),\n",
    "#                    PowerTransformer()],\n",
    "#         'resampling': [SMOTENC(categorical_features=get_cat_cols(X),\n",
    "#                                random_state=random_state),\n",
    "        'resampling': [\n",
    "            SMOTE(random_state=random_state),\n",
    "            ADASYN(random_state=random_state),\n",
    "#             SMOTEENN(random_state=random_state),\n",
    "#             SMOTETomek(random_state=random_state),\n",
    "            EditedNearestNeighbours(),\n",
    "#             TomekLinks(),\n",
    "            RandomOverSampler(random_state=random_state),\n",
    "            RandomUnderSampler(random_state=random_state)\n",
    "        ],\n",
    "        'classifier__n_estimators': [200, 300],\n",
    "        'classifier__max_depth': [2, 3],\n",
    "        'classifier__min_samples_split': [2, 3],\n",
    "        'classifier__min_samples_leaf': [2, 3],\n",
    "        'classifier__oob_score': [True, False],\n",
    "        'classifier__criterion': [\"gini\", \"entropy\", \"log_loss\"]\n",
    "\n",
    "#         'classifier__n_estimators': [200, 250],\n",
    "#         'classifier__max_depth': [2, 3],\n",
    "#         'classifier__min_samples_split': [3, 4],\n",
    "#         'classifier__min_samples_leaf': [3, 4],\n",
    "#         'classifier__oob_score': [True, False],\n",
    "#         'classifier__criterion': [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    }\n",
    "#         'classifier__n_estimators': [200, 250, 300],\n",
    "# #         'classifier__max_depth': [2, 3, 4],\n",
    "#         'classifier__max_depth': [2],\n",
    "#         'classifier__class_weight': [{0: 263/807, 1:1}],\n",
    "#         'classifier__oob_score': [True],\n",
    "# #         'classifier__class_weight': [{0: 1, 1:807/263}],\n",
    "#         'classifier__min_samples_split': [3, 4],\n",
    "#         'classifier__min_samples_leaf': [3, 4],\n",
    "#         'classifier__criterion': [\"gini\", \"entropy\", \"log_loss\"]\n",
    "#     }\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "#                                cv=10, scoring=scorer,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "def gbm_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', GradientBoostingClassifier(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [StandardScaler(),\n",
    "#                    MinMaxScaler(),\n",
    "#                    RobustScaler()\n",
    "#                   ],\n",
    "        'resampling': [\n",
    "            SMOTE(random_state=random_state),\n",
    "                       ADASYN(random_state=random_state),\n",
    "#                        SMOTEENN(random_state=random_state),\n",
    "#                        SMOTETomek(random_state=random_state),\n",
    "                       EditedNearestNeighbours(),\n",
    "#                        TomekLinks(),\n",
    "                       RandomOverSampler(random_state=random_state),\n",
    "                       RandomUnderSampler(random_state=random_state)],\n",
    "#         'classifier__n_estimators': [200],\n",
    "#         'classifier__max_depth': [None],\n",
    "#         'classifier__min_samples_leaf': [3],\n",
    "#         'classifier__min_samples_split': [5],\n",
    "#         'classifier__learning_rate': [0.1]\n",
    "        'classifier__n_estimators': [200, 250],\n",
    "        'classifier__max_depth': [2, 3],\n",
    "        'classifier__min_samples_leaf': [2, 3],\n",
    "        'classifier__min_samples_split': [2, 3],\n",
    "        'classifier__learning_rate': [0.1]\n",
    "    }\n",
    "#         'loss': ['log_loss', 'deviance', 'exponential']\n",
    "#         'min_samples_leaf': [1, 2, 3],\n",
    "#         'min_samples_split': [2, 3, 5],\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "def lgbm_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     pca = PCA().fit(X_scaled)\n",
    "\n",
    "#     # 2. Plot the cumulative explained variance\n",
    "#     explained_var_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_explained_var = np.cumsum(explained_var_ratio)\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(range(1, len(explained_var_ratio)+1), cumulative_explained_var, marker='o', linestyle='--')\n",
    "#     plt.title('Cumulative Explained Variance Plot')\n",
    "#     plt.xlabel('Number of Components')\n",
    "#     plt.ylabel('Cumulative Explained Variance')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "#     # 3. Find the number of components that explain up to 90% of the variance\n",
    "#     num_components = np.argmax(cumulative_explained_var >= 0.90) + 1\n",
    "#     print(f\"Number of components that explain up to 90% of variance: {num_components}\")\n",
    "\n",
    "#     # Refit PCA with the selected number of components\n",
    "#     pca_90 = PCA(n_components=num_components)\n",
    "#     X = pca_90.fit_transform(X_scaled)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', LGBMClassifier(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [StandardScaler(),\n",
    "#                    MinMaxScaler(),\n",
    "#                    RobustScaler()\n",
    "#                   ],\n",
    "#         'resampling': [SMOTE(random_state=random_state),\n",
    "#                        SMOTENC(categorical_features=get_cat_cols(X),\n",
    "#                                random_state=random_state),\n",
    "#                        ADASYN(random_state=random_state),\n",
    "# #                        RandomOverSampler(random_state=random_state),\n",
    "#                        RandomUnderSampler(random_state=random_state)],\n",
    "#         'scaler': [RobustScaler(),\n",
    "#                    PowerTransformer()],\n",
    "#         'resampling': [SMOTENC(categorical_features=get_cat_cols(X),\n",
    "#                                random_state=random_state),\n",
    "        'resampling': [SMOTE(random_state=random_state),\n",
    "                       ADASYN(random_state=random_state),\n",
    "#                        SMOTEENN(random_state=random_state),\n",
    "#                        SMOTETomek(random_state=random_state),\n",
    "                       EditedNearestNeighbours(),\n",
    "#                        TomekLinks(),\n",
    "                       RandomOverSampler(random_state=random_state),\n",
    "                       RandomUnderSampler(random_state=random_state)],\n",
    "#         'classifier__n_estimators': [400, 450],\n",
    "#         'classifier__learning_rate': [0.01],\n",
    "#         'classifier__num_leaves': [20, 25],\n",
    "#         'classifier__min_child_samples': [40, 45],\n",
    "#         'classifier__class_weight': [{0: 263/807, 1:1}, {0: 1, 1:807/263}],\n",
    "#         'classifier__class_weight': [{0: 1, 1:807/263}],\n",
    "#         'classifier__max_depth': [2, 3],\n",
    "#         'classifier__boosting_type': ['gbdt', 'dart', 'goss']\n",
    "\n",
    "        'classifier__n_estimators': [200, 300, 400],\n",
    "        'classifier__learning_rate': [0.1, 0.01],\n",
    "#         'classifier__num_leaves': [20, 25],\n",
    "#         'classifier__min_child_samples': [40, 45],\n",
    "#         'classifier__class_weight': [{0: 263/807, 1:1}, {0: 1, 1:807/263}],\n",
    "#         'classifier__class_weight': [{0: 1, 1:807/263}],\n",
    "        'classifier__max_depth': [2, 3],\n",
    "        'classifier__boosting_type': ['gbdt', 'dart', 'goss']\n",
    "    }\n",
    "#         'classifier__num_leaves': [20, 31, 40],\n",
    "#         'classifier__min_child_samples': [10, 20, 30],\n",
    "#         'classifier__max_depth': [-1, 5, 10],\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "def xgb_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     pca = PCA().fit(X_scaled)\n",
    "\n",
    "#     # 2. Plot the cumulative explained variance\n",
    "#     explained_var_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_explained_var = np.cumsum(explained_var_ratio)\n",
    "\n",
    "#     # 3. Find the number of components that explain up to 90% of the variance\n",
    "#     num_components = np.argmax(cumulative_explained_var >= 0.90) + 1\n",
    "#     print(f\"Number of components that explain up to 90% of variance: {num_components}\")\n",
    "\n",
    "#     # Refit PCA with the selected number of components\n",
    "#     pca_90 = PCA(n_components=num_components)\n",
    "#     X = pca_90.fit_transform(X_scaled)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', XGBClassifier(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [\n",
    "#             StandardScaler(),\n",
    "#             MinMaxScaler(),\n",
    "#             RobustScaler()\n",
    "#         ],\n",
    "#         'resampling': [SMOTE(random_state=random_state),\n",
    "#                        SMOTENC(categorical_features=get_cat_cols(X),\n",
    "#                                random_state=random_state),\n",
    "#                        ADASYN(random_state=random_state),\n",
    "# #                        RandomOverSampler(random_state=random_state),\n",
    "#                        RandomUnderSampler(random_state=random_state)],\n",
    "#         'scaler': [RobustScaler(),\n",
    "#                    PowerTransformer()],\n",
    "#         'resampling': [SMOTENC(categorical_features=get_cat_cols(X),\n",
    "#                                random_state=random_state),\n",
    "        'resampling': [SMOTE(random_state=random_state),\n",
    "                       ADASYN(random_state=random_state),\n",
    "#                        SMOTEENN(random_state=random_state),\n",
    "#                        SMOTETomek(random_state=random_state),\n",
    "                       EditedNearestNeighbours(),\n",
    "#                        TomekLinks(),\n",
    "                       RandomOverSampler(random_state=random_state),\n",
    "                       RandomUnderSampler(random_state=random_state)],\n",
    "# #         'classifier__n_estimators': [200, 250],\n",
    "#         'classifier__learning_rate': [2, 3],\n",
    "# #         'classifier__max_depth': [2, 3],\n",
    "#         'classifier__max_leaves': [5],\n",
    "#         'classifier__grow_policy': ['depthwise', 'lossguide']\n",
    "        'classifier__n_estimators': [200, 250],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 1],\n",
    "        'classifier__max_depth': [None, 2, 3],\n",
    "        'classifier__max_leaves': [10, 20, 30],\n",
    "        'classifier__grow_policy': ['depthwise', 'lossguide']\n",
    "    }\n",
    "#         'classifier__max_depth': [None, 5, 10],\n",
    "#         'classifier__max_leaves': [0, 10, 20],\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "def adaboost_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     pca = PCA().fit(X_scaled)\n",
    "\n",
    "#     # 2. Plot the cumulative explained variance\n",
    "#     explained_var_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_explained_var = np.cumsum(explained_var_ratio)\n",
    "\n",
    "#     # 3. Find the number of components that explain up to 90% of the variance\n",
    "#     num_components = np.argmax(cumulative_explained_var >= 0.90) + 1\n",
    "#     print(f\"Number of components that explain up to 90% of variance: {num_components}\")\n",
    "\n",
    "#     # Refit PCA with the selected number of components\n",
    "#     pca_90 = PCA(n_components=num_components)\n",
    "#     X = pca_90.fit_transform(X_scaled)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    cat_cols = get_cat_cols(X_train)\n",
    "    num_cols = [col for col in X_train.columns if col not in cat_cols]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', AdaBoostClassifier(\n",
    "            random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [\n",
    "#             StandardScaler(),\n",
    "#             MinMaxScaler(),\n",
    "#             RobustScaler()\n",
    "#         ],\n",
    "        'resampling': [\n",
    "            SMOTE(random_state=random_state),\n",
    "            ADASYN(random_state=random_state),\n",
    "#             SMOTEENN(random_state=random_state),\n",
    "#             SMOTETomek(random_state=random_state),\n",
    "            EditedNearestNeighbours(),\n",
    "#             TomekLinks(),\n",
    "            RandomOverSampler(random_state=random_state),\n",
    "            RandomUnderSampler(random_state=random_state)],\n",
    "        'classifier__n_estimators': [200, 300],\n",
    "        'classifier__estimator': [DecisionTreeClassifier(\n",
    "            random_state=random_state,\n",
    "#             criterion='entropy', max_depth=3,\n",
    "#             min_samples_leaf=2, min_samples_split=2\n",
    "        ),\n",
    "                                  RandomForestClassifier(\n",
    "            random_state=random_state,\n",
    "#             max_depth=3, min_samples_leaf=2,\n",
    "#             min_samples_split=2, n_estimators=250,\n",
    "#             oob_score=True\n",
    "                                                        )],\n",
    "#         'classifier__learning_rate': [0.01, 0.1, 1],\n",
    "        'classifier__algorithm': ['SAMME', 'SAMME.R']\n",
    "    }\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "def ridge_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     pca = PCA().fit(X_scaled)\n",
    "\n",
    "#     # 2. Plot the cumulative explained variance\n",
    "#     explained_var_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_explained_var = np.cumsum(explained_var_ratio)\n",
    "\n",
    "#     # 3. Find the number of components that explain up to 90% of the variance\n",
    "#     num_components = np.argmax(cumulative_explained_var >= 0.90) + 1\n",
    "#     print(f\"Number of components that explain up to 90% of variance: {num_components}\")\n",
    "\n",
    "#     # Refit PCA with the selected number of components\n",
    "#     pca_90 = PCA(n_components=num_components)\n",
    "#     X = pca_90.fit_transform(X_scaled)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    cat_cols = get_cat_cols(X_train)\n",
    "    num_cols = [col for col in X_train.columns if col not in cat_cols]\n",
    "    \n",
    "    cat_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    num_transformer = Pipeline([\n",
    "        ('variance_threshold', VarianceThreshold(threshold=0.15))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', num_transformer, num_cols),\n",
    "            ('cat', cat_transformer, cat_cols)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    preprocessor_num = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', num_transformer, num_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    preprocessor_drop_cat = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', 'passthrough', num_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "#         ('preprocessor', None),\n",
    "        ('preprocessor', preprocessor_drop_cat),\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('var_threshold', VarianceThreshold(threshold=0.15)),\n",
    "        ('classifier', RidgeClassifier(max_iter=1000, random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'preprocessor': [\n",
    "#             preprocessor_drop_cat,\n",
    "#             preprocessor,\n",
    "#             preprocessor_num            \n",
    "#         ],\n",
    "        'resampling': [ADASYN(random_state=random_state),\n",
    "                       SMOTEENN(random_state=random_state),\n",
    "                       SMOTETomek(random_state=random_state),\n",
    "                       EditedNearestNeighbours(),\n",
    "                       TomekLinks(),\n",
    "                       RandomUnderSampler(random_state=random_state)],\n",
    "        'classifier__alpha': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'classifier__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sag', 'saga'],\n",
    "    }\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=10, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df\n",
    "\n",
    "def catboost_class2(df, scorer, label_col, scaler, random_state=0):\n",
    "    X = df.drop(['userId', 'lastFirstName', label_col], axis=1)\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('resampling', None),\n",
    "        ('classifier', CatBoostClassifier(random_state=random_state, ))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "#         'scaler': [StandardScaler(),\n",
    "#                    MinMaxScaler(),\n",
    "#                    RobustScaler()\n",
    "#                   ],\n",
    "        'resampling': [\n",
    "            SMOTE(random_state=random_state),\n",
    "                       ADASYN(random_state=random_state),\n",
    "#                        SMOTEENN(random_state=random_state),\n",
    "#                        SMOTETomek(random_state=random_state),\n",
    "                       EditedNearestNeighbours(),\n",
    "#                        TomekLinks(),\n",
    "                       RandomOverSampler(random_state=random_state),\n",
    "                       RandomUnderSampler(random_state=random_state)],\n",
    "#         'classifier__n_estimators': [200],\n",
    "#         'classifier__max_depth': [None],\n",
    "#         'classifier__min_samples_leaf': [3],\n",
    "#         'classifier__min_samples_split': [5],\n",
    "#         'classifier__learning_rate': [0.1]\n",
    "#         'classifier__n_estimators': [200, 250],\n",
    "#         'classifier__max_depth': [2, 3],\n",
    "#         'classifier__min_samples_leaf': [2, 3],\n",
    "#         'classifier__min_samples_split': [2, 3],\n",
    "#         'classifier__learning_rate': [0.1]\n",
    "    }\n",
    "#         'loss': ['log_loss', 'deviance', 'exponential']\n",
    "#         'min_samples_leaf': [1, 2, 3],\n",
    "#         'min_samples_split': [2, 3, 5],\n",
    "\n",
    "    start_time_cv = time.time()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                               cv=skf, scoring=scorer,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=4, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    end_time_cv = time.time()\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Score (Precision):\", best_score)\n",
    "    print('Best Estimator:', best_estimator)\n",
    "    print('Mean Train Score (Precision)', np.mean(cv_results['mean_train_score']))\n",
    "    print('Std Train Score (Precision)', np.mean(cv_results['std_train_score']))\n",
    "    elapsed_time_cv = (end_time_cv - start_time_cv)\n",
    "    print(f'GridSearchCV Runtime: {elapsed_time_cv} secs')\n",
    "\n",
    "    num_runs = 5\n",
    "    metrics_per_run = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        modified_random_state = random_state + run\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.25,\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=modified_random_state)\n",
    "\n",
    "        modified_estimator = clone(best_estimator)\n",
    "#         if not (isinstance(best_estimator.named_steps['resampling'], EditedNearestNeighbours) or\n",
    "#             isinstance(best_estimator.named_steps['resampling'], TomekLinks)):\n",
    "#             modified_estimator.named_steps['resampling'].set_params(random_state=modified_random_state)\n",
    "#         modified_estimator.named_steps['classifier'].set_params(random_state=modified_random_state)\n",
    "        modified_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modified_estimator.predict(X_test)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = (end_time - start_time)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = specificity_score(y_test, y_pred)\n",
    "        npv = npv_score(y_test, y_pred)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Run {run + 1} - Random State: {modified_random_state}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "\n",
    "#         y_hat = modified_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "#         gmeans = np.sqrt(tpr * (1-fpr))\n",
    "#         ix = np.argmax(gmeans)\n",
    "#         print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "#         plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "#         plt.plot(fpr, tpr, marker='.', label='Original')\n",
    "#         plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        metrics_per_run.append({\n",
    "            'Random State': modified_random_state,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Test Precision': precision,\n",
    "            'Test Recall': recall,\n",
    "            'Test F1 Score': f1,\n",
    "            'Test Specificity': specificity,\n",
    "            'Test G-mean': g_mean,\n",
    "            'Test NPV': npv,\n",
    "            'Runtime': elapsed_time\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_per_run)\n",
    "\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "\n",
    "    print('Ave Test Precision:', avg_metrics['Test Precision'])\n",
    "    print('Stdev Test Precision:', std_metrics['Test Precision'])\n",
    "    print(\"Ave Test Accuracy:\", avg_metrics['Test Accuracy'])\n",
    "    print('Stdev Test Accuracy:', std_metrics['Test Accuracy'])\n",
    "    print(\"Ave Test Specificity:\", avg_metrics['Test Specificity'])\n",
    "    print(\"Ave Test Recall:\", avg_metrics['Test Recall'])\n",
    "    print('Ave Test NPV:', avg_metrics['Test NPV'])\n",
    "    print(\"Ave Test F1-Score:\", avg_metrics['Test F1 Score'])\n",
    "    print(\"Ave Test G-mean:\", avg_metrics['Test G-mean'])\n",
    "    print(\"Ave Runtime:\", avg_metrics['Runtime'])\n",
    "\n",
    "    model_info = {\n",
    "        'best_params': best_params,\n",
    "        'best_cv_score': best_score,\n",
    "        'mean_train_score': np.mean(cv_results['mean_train_score']),\n",
    "        'std_train_score': np.mean(cv_results['std_train_score']),\n",
    "        'average_test_precision': avg_metrics['Test Precision'],\n",
    "        'stdev_test_precision': std_metrics['Test Precision'],\n",
    "        'average_test_accuracy': avg_metrics['Test Accuracy'],\n",
    "        'stdev_test_accuracy': std_metrics['Test Accuracy'],\n",
    "        'average_runtime': avg_metrics['Runtime'],\n",
    "        'average_test_specificity': avg_metrics['Test Specificity'],\n",
    "        'average_test_recall': avg_metrics['Test Recall'],\n",
    "        'average_test_npv': avg_metrics['Test NPV'],\n",
    "        'average_test_f1_score': avg_metrics['Test F1 Score'],\n",
    "        'average_test_g_mean': avg_metrics['Test G-mean']\n",
    "    }\n",
    "\n",
    "    return grid_search, best_estimator, model_info, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CatBoostClassifier in module catboost.core:\n",
      "\n",
      "class CatBoostClassifier(CatBoost)\n",
      " |  CatBoostClassifier(iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function=None, border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, target_border=None, classes_count=None, class_weights=None, auto_class_weights=None, class_names=None, one_hot_max_size=None, random_strength=None, random_score_type=None, name=None, ignored_features=None, train_dir=None, custom_loss=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, mvs_reg=None, sampling_unit=None, sampling_frequency=None, dev_score_calc_obj_block_size=None, dev_efb_max_buckets=None, sparse_features_conflict_fraction=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, scale_pos_weight=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, per_object_feature_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, posterior_sampling=None, boost_from_average=None, text_features=None, tokenizers=None, dictionaries=None, feature_calcers=None, text_processing=None, embedding_features=None, callback=None, eval_fraction=None, fixed_binary_splits=None)\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for CatBoost classification.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  iterations : int, [default=500]\n",
      " |      Max count of trees.\n",
      " |      range: [1,+inf)\n",
      " |  learning_rate : float, [default value is selected automatically for binary classification with other parameters set to default. In all other cases default is 0.03]\n",
      " |      Step size shrinkage used in update to prevents overfitting.\n",
      " |      range: (0,1]\n",
      " |  depth : int, [default=6]\n",
      " |      Depth of a tree. All trees are the same depth.\n",
      " |      range: [1,16]\n",
      " |  l2_leaf_reg : float, [default=3.0]\n",
      " |      Coefficient at the L2 regularization term of the cost function.\n",
      " |      range: [0,+inf)\n",
      " |  model_size_reg : float, [default=None]\n",
      " |      Model size regularization coefficient.\n",
      " |      range: [0,+inf)\n",
      " |  rsm : float, [default=None]\n",
      " |      Subsample ratio of columns when constructing each tree.\n",
      " |      range: (0,1]\n",
      " |  loss_function : string or object, [default='Logloss']\n",
      " |      The metric to use in training and also selector of the machine learning\n",
      " |      problem to solve. If string, then the name of a supported metric,\n",
      " |      optionally suffixed with parameter description.\n",
      " |      If object, it shall provide methods 'calc_ders_range' or 'calc_ders_multi'.\n",
      " |  border_count : int, [default = 254 for training on CPU or 128 for training on GPU]\n",
      " |      The number of partitions in numeric features binarization. Used in the preliminary calculation.\n",
      " |      range: [1,65535] on CPU, [1,255] on GPU\n",
      " |  feature_border_type : string, [default='GreedyLogSum']\n",
      " |      The binarization mode in numeric features binarization. Used in the preliminary calculation.\n",
      " |      Possible values:\n",
      " |          - 'Median'\n",
      " |          - 'Uniform'\n",
      " |          - 'UniformAndQuantiles'\n",
      " |          - 'GreedyLogSum'\n",
      " |          - 'MaxLogSum'\n",
      " |          - 'MinEntropy'\n",
      " |  per_float_feature_quantization : list of strings, [default=None]\n",
      " |      List of float binarization descriptions.\n",
      " |      Format : described in documentation on catboost.ai\n",
      " |      Example 1: ['0:1024'] means that feature 0 will have 1024 borders.\n",
      " |      Example 2: ['0:border_count=1024', '1:border_count=1024', ...] means that two first features have 1024 borders.\n",
      " |      Example 3: ['0:nan_mode=Forbidden,border_count=32,border_type=GreedyLogSum',\n",
      " |                  '1:nan_mode=Forbidden,border_count=32,border_type=GreedyLogSum'] - defines more quantization properties for first two features.\n",
      " |  input_borders : string or pathlib.Path, [default=None]\n",
      " |      input file with borders used in numeric features binarization.\n",
      " |  output_borders : string, [default=None]\n",
      " |      output file for borders that were used in numeric features binarization.\n",
      " |  fold_permutation_block : int, [default=1]\n",
      " |      To accelerate the learning.\n",
      " |      The recommended value is within [1, 256]. On small samples, must be set to 1.\n",
      " |      range: [1,+inf)\n",
      " |  od_pval : float, [default=None]\n",
      " |      Use overfitting detector to stop training when reaching a specified threshold.\n",
      " |      Can be used only with eval_set.\n",
      " |      range: [0,1]\n",
      " |  od_wait : int, [default=None]\n",
      " |      Number of iterations which overfitting detector will wait after new best error.\n",
      " |  od_type : string, [default=None]\n",
      " |      Type of overfitting detector which will be used in program.\n",
      " |      Posible values:\n",
      " |          - 'IncToDec'\n",
      " |          - 'Iter'\n",
      " |      For 'Iter' type od_pval must not be set.\n",
      " |      If None, then od_type=IncToDec.\n",
      " |  nan_mode : string, [default=None]\n",
      " |      Way to process missing values for numeric features.\n",
      " |      Possible values:\n",
      " |          - 'Forbidden' - raises an exception if there is a missing value for a numeric feature in a dataset.\n",
      " |          - 'Min' - each missing value will be processed as the minimum numerical value.\n",
      " |          - 'Max' - each missing value will be processed as the maximum numerical value.\n",
      " |      If None, then nan_mode=Min.\n",
      " |  counter_calc_method : string, [default=None]\n",
      " |      The method used to calculate counters for dataset with Counter type.\n",
      " |      Possible values:\n",
      " |          - 'PrefixTest' - only objects up to current in the test dataset are considered\n",
      " |          - 'FullTest' - all objects are considered in the test dataset\n",
      " |          - 'SkipTest' - Objects from test dataset are not considered\n",
      " |          - 'Full' - all objects are considered for both learn and test dataset\n",
      " |      If None, then counter_calc_method=PrefixTest.\n",
      " |  leaf_estimation_iterations : int, [default=None]\n",
      " |      The number of steps in the gradient when calculating the values in the leaves.\n",
      " |      If None, then leaf_estimation_iterations=1.\n",
      " |      range: [1,+inf)\n",
      " |  leaf_estimation_method : string, [default=None]\n",
      " |      The method used to calculate the values in the leaves.\n",
      " |      Possible values:\n",
      " |          - 'Newton'\n",
      " |          - 'Gradient'\n",
      " |  thread_count : int, [default=None]\n",
      " |      Number of parallel threads used to run CatBoost.\n",
      " |      If None or -1, then the number of threads is set to the number of CPU cores.\n",
      " |      range: [1,+inf)\n",
      " |  random_seed : int, [default=None]\n",
      " |      Random number seed.\n",
      " |      If None, 0 is used.\n",
      " |      range: [0,+inf)\n",
      " |  use_best_model : bool, [default=None]\n",
      " |      To limit the number of trees in predict() using information about the optimal value of the error function.\n",
      " |      Can be used only with eval_set.\n",
      " |  best_model_min_trees : int, [default=None]\n",
      " |      The minimal number of trees the best model should have.\n",
      " |  verbose: bool\n",
      " |      When set to True, logging_level is set to 'Verbose'.\n",
      " |      When set to False, logging_level is set to 'Silent'.\n",
      " |  silent: bool, synonym for verbose\n",
      " |  logging_level : string, [default='Verbose']\n",
      " |      Possible values:\n",
      " |          - 'Silent'\n",
      " |          - 'Verbose'\n",
      " |          - 'Info'\n",
      " |          - 'Debug'\n",
      " |  metric_period : int, [default=1]\n",
      " |      The frequency of iterations to print the information to stdout. The value should be a positive integer.\n",
      " |  simple_ctr: list of strings, [default=None]\n",
      " |      Binarization settings for categorical features.\n",
      " |          Format : see documentation\n",
      " |          Example: ['Borders:CtrBorderCount=5:Prior=0:Prior=0.5', 'BinarizedTargetMeanValue:TargetBorderCount=10:TargetBorderType=MinEntropy', ...]\n",
      " |          CTR types:\n",
      " |              CPU and GPU\n",
      " |              - 'Borders'\n",
      " |              - 'Buckets'\n",
      " |              CPU only\n",
      " |              - 'BinarizedTargetMeanValue'\n",
      " |              - 'Counter'\n",
      " |              GPU only\n",
      " |              - 'FloatTargetMeanValue'\n",
      " |              - 'FeatureFreq'\n",
      " |          Number_of_borders, binarization type, target borders and binarizations, priors are optional parametrs\n",
      " |  combinations_ctr: list of strings, [default=None]\n",
      " |  per_feature_ctr: list of strings, [default=None]\n",
      " |  ctr_target_border_count: int, [default=None]\n",
      " |      Maximum number of borders used in target binarization for categorical features that need it.\n",
      " |      If TargetBorderCount is specified in 'simple_ctr', 'combinations_ctr' or 'per_feature_ctr' option it\n",
      " |      overrides this value.\n",
      " |      range: [1, 255]\n",
      " |  ctr_leaf_count_limit : int, [default=None]\n",
      " |      The maximum number of leaves with categorical features.\n",
      " |      If the number of leaves exceeds the specified limit, some leaves are discarded.\n",
      " |      The leaves to be discarded are selected as follows:\n",
      " |          - The leaves are sorted by the frequency of the values.\n",
      " |          - The top N leaves are selected, where N is the value specified in the parameter.\n",
      " |          - All leaves starting from N+1 are discarded.\n",
      " |      This option reduces the resulting model size\n",
      " |      and the amount of memory required for training.\n",
      " |      Note that the resulting quality of the model can be affected.\n",
      " |      range: [1,+inf) (for zero limit use ignored_features)\n",
      " |  store_all_simple_ctr : bool, [default=None]\n",
      " |      Ignore categorical features, which are not used in feature combinations,\n",
      " |      when choosing candidates for exclusion.\n",
      " |      Use this parameter with ctr_leaf_count_limit only.\n",
      " |  max_ctr_complexity : int, [default=4]\n",
      " |      The maximum number of Categ features that can be combined.\n",
      " |      range: [0,+inf)\n",
      " |  has_time : bool, [default=False]\n",
      " |      To use the order in which objects are represented in the input data\n",
      " |      (do not perform a random permutation of the dataset at the preprocessing stage).\n",
      " |  allow_const_label : bool, [default=False]\n",
      " |      To allow the constant label value in dataset.\n",
      " |  target_border: float, [default=None]\n",
      " |      Border for target binarization.\n",
      " |  classes_count : int, [default=None]\n",
      " |      The upper limit for the numeric class label.\n",
      " |      Defines the number of classes for multiclassification.\n",
      " |      Only non-negative integers can be specified.\n",
      " |      The given integer should be greater than any of the target values.\n",
      " |      If this parameter is specified the labels for all classes in the input dataset\n",
      " |      should be smaller than the given value.\n",
      " |      If several of 'classes_count', 'class_weights', 'class_names' parameters are defined\n",
      " |      the numbers of classes specified by each of them must be equal.\n",
      " |  class_weights : list or dict, [default=None]\n",
      " |      Classes weights. The values are used as multipliers for the object weights.\n",
      " |      If None, all classes are supposed to have weight one.\n",
      " |      If list - class weights in order of class_names or sequential classes if class_names is undefined\n",
      " |      If dict - dict of class_name -> class_weight.\n",
      " |      If several of 'classes_count', 'class_weights', 'class_names' parameters are defined\n",
      " |      the numbers of classes specified by each of them must be equal.\n",
      " |  auto_class_weights : string [default=None]\n",
      " |      Enables automatic class weights calculation. Possible values:\n",
      " |          - Balanced  # weight = maxSummaryClassWeight / summaryClassWeight, statistics determined from train pool\n",
      " |          - SqrtBalanced  # weight = sqrt(maxSummaryClassWeight / summaryClassWeight)\n",
      " |  class_names: list of strings, [default=None]\n",
      " |      Class names. Allows to redefine the default values for class labels (integer numbers).\n",
      " |      If several of 'classes_count', 'class_weights', 'class_names' parameters are defined\n",
      " |      the numbers of classes specified by each of them must be equal.\n",
      " |  one_hot_max_size : int, [default=None]\n",
      " |      Convert the feature to float\n",
      " |      if the number of different values that it takes exceeds the specified value.\n",
      " |      Ctrs are not calculated for such features.\n",
      " |  random_strength : float, [default=1]\n",
      " |      Score standard deviation multiplier.\n",
      " |  random_score_type : string [default=None]\n",
      " |      Type of random noise added to scores.\n",
      " |      Possible values:\n",
      " |          - 'Gumbel' - Gumbel-distributed\n",
      " |          - 'NormalWithModelSizeDecrease' - Normally-distributed with deviation decreasing with model iteration count\n",
      " |      If None than 'NormalWithModelSizeDecrease' will be used by default.\n",
      " |  name : string, [default='experiment']\n",
      " |      The name that should be displayed in the visualization tools.\n",
      " |  ignored_features : list, [default=None]\n",
      " |      Indices or names of features that should be excluded when training.\n",
      " |  train_dir : string or pathlib.Path, [default=None]\n",
      " |      The directory in which you want to record generated in the process of learning files.\n",
      " |  custom_metric : string or list of strings, [default=None]\n",
      " |      To use your own metric function.\n",
      " |  custom_loss: alias to custom_metric\n",
      " |  eval_metric : string or object, [default=None]\n",
      " |      To optimize your custom metric in loss.\n",
      " |  bagging_temperature : float, [default=None]\n",
      " |      Controls intensity of Bayesian bagging. The higher the temperature the more aggressive bagging is.\n",
      " |      Typical values are in range [0, 1] (0 - no bagging, 1 - default).\n",
      " |  save_snapshot : bool, [default=None]\n",
      " |      Enable progress snapshotting for restoring progress after crashes or interruptions\n",
      " |  snapshot_file : string or pathlib.Path, [default=None]\n",
      " |      Learn progress snapshot file path, if None will use default filename\n",
      " |  snapshot_interval: int, [default=600]\n",
      " |      Interval between saving snapshots (seconds)\n",
      " |  fold_len_multiplier : float, [default=None]\n",
      " |      Fold length multiplier. Should be greater than 1\n",
      " |  used_ram_limit : string or number, [default=None]\n",
      " |      Set a limit on memory consumption (value like '1.2gb' or 1.2e9).\n",
      " |      WARNING: Currently this option affects CTR memory usage only.\n",
      " |  gpu_ram_part : float, [default=0.95]\n",
      " |      Fraction of the GPU RAM to use for training, a value from (0, 1].\n",
      " |  pinned_memory_size: int [default=None]\n",
      " |      Size of additional CPU pinned memory used for GPU learning,\n",
      " |      usually is estimated automatically, thus usually should not be set.\n",
      " |  allow_writing_files : bool, [default=True]\n",
      " |      If this flag is set to False, no files with different diagnostic info will be created during training.\n",
      " |      With this flag no snapshotting can be done. Plus visualisation will not\n",
      " |      work, because visualisation uses files that are created and updated during training.\n",
      " |  final_ctr_computation_mode : string, [default='Default']\n",
      " |      Possible values:\n",
      " |          - 'Default' - Compute final ctrs for all pools.\n",
      " |          - 'Skip' - Skip final ctr computation. WARNING: model without ctrs can't be applied.\n",
      " |  approx_on_full_history : bool, [default=False]\n",
      " |      If this flag is set to True, each approximated value is calculated using all the preceeding rows in the fold (slower, more accurate).\n",
      " |      If this flag is set to False, each approximated value is calculated using only the beginning 1/fold_len_multiplier fraction of the fold (faster, slightly less accurate).\n",
      " |  boosting_type : string, default value depends on object count and feature count in train dataset and on learning mode.\n",
      " |      Boosting scheme.\n",
      " |      Possible values:\n",
      " |          - 'Ordered' - Gives better quality, but may slow down the training.\n",
      " |          - 'Plain' - The classic gradient boosting scheme. May result in quality degradation, but does not slow down the training.\n",
      " |  task_type : string, [default=None]\n",
      " |      The calcer type used to train the model.\n",
      " |      Possible values:\n",
      " |          - 'CPU'\n",
      " |          - 'GPU'\n",
      " |  device_config : string, [default=None], deprecated, use devices instead\n",
      " |  devices : list or string, [default=None], GPU devices to use.\n",
      " |      String format is: '0' for 1 device or '0:1:3' for multiple devices or '0-3' for range of devices.\n",
      " |      List format is : [0] for 1 device or [0,1,3] for multiple devices.\n",
      " |  \n",
      " |  bootstrap_type : string, Bayesian, Bernoulli, Poisson, MVS.\n",
      " |      Default bootstrap is Bayesian for GPU and MVS for CPU.\n",
      " |      Poisson bootstrap is supported only on GPU.\n",
      " |      MVS bootstrap is supported only on GPU.\n",
      " |  \n",
      " |  subsample : float, [default=None]\n",
      " |      Sample rate for bagging. This parameter can be used Poisson or Bernoully bootstrap types.\n",
      " |  \n",
      " |  mvs_reg : float, [default is set automatically at each iteration based on gradient distribution]\n",
      " |      Regularization parameter for MVS sampling algorithm\n",
      " |  \n",
      " |  monotone_constraints : list or numpy.ndarray or string or dict, [default=None]\n",
      " |      Monotone constraints for features.\n",
      " |  \n",
      " |  feature_weights : list or numpy.ndarray or string or dict, [default=None]\n",
      " |      Coefficient to multiply split gain with specific feature use. Should be non-negative.\n",
      " |  \n",
      " |  penalties_coefficient : float, [default=1]\n",
      " |      Common coefficient for all penalties. Should be non-negative.\n",
      " |  \n",
      " |  first_feature_use_penalties : list or numpy.ndarray or string or dict, [default=None]\n",
      " |      Penalties to first use of specific feature in model. Should be non-negative.\n",
      " |  \n",
      " |  per_object_feature_penalties : list or numpy.ndarray or string or dict, [default=None]\n",
      " |      Penalties for first use of feature for each object. Should be non-negative.\n",
      " |  \n",
      " |  sampling_frequency : string, [default=PerTree]\n",
      " |      Frequency to sample weights and objects when building trees.\n",
      " |      Possible values:\n",
      " |          - 'PerTree' - Before constructing each new tree\n",
      " |          - 'PerTreeLevel' - Before choosing each new split of a tree\n",
      " |  \n",
      " |  sampling_unit : string, [default='Object'].\n",
      " |      Possible values:\n",
      " |          - 'Object'\n",
      " |          - 'Group'\n",
      " |      The parameter allows to specify the sampling scheme:\n",
      " |      sample weights for each object individually or for an entire group of objects together.\n",
      " |  \n",
      " |  dev_score_calc_obj_block_size: int, [default=5000000]\n",
      " |      CPU only. Size of block of samples in score calculation. Should be > 0\n",
      " |      Used only for learning speed tuning.\n",
      " |      Changing this parameter can affect results due to numerical accuracy differences\n",
      " |  \n",
      " |  dev_efb_max_buckets : int, [default=1024]\n",
      " |      CPU only. Maximum bucket count in exclusive features bundle. Should be in an integer between 0 and 65536.\n",
      " |      Used only for learning speed tuning.\n",
      " |  \n",
      " |  sparse_features_conflict_fraction : float, [default=0.0]\n",
      " |      CPU only. Maximum allowed fraction of conflicting non-default values for features in exclusive features bundle.\n",
      " |      Should be a real value in [0, 1) interval.\n",
      " |  \n",
      " |  grow_policy : string, [SymmetricTree,Lossguide,Depthwise], [default=SymmetricTree]\n",
      " |      The tree growing policy. It describes how to perform greedy tree construction.\n",
      " |  \n",
      " |  min_data_in_leaf : int, [default=1].\n",
      " |      The minimum training samples count in leaf.\n",
      " |      CatBoost will not search for new splits in leaves with samples count less than min_data_in_leaf.\n",
      " |      This parameter is used only for Depthwise and Lossguide growing policies.\n",
      " |  \n",
      " |  max_leaves : int, [default=31],\n",
      " |      The maximum leaf count in resulting tree.\n",
      " |      This parameter is used only for Lossguide growing policy.\n",
      " |  \n",
      " |  score_function : string, possible values L2, Cosine, NewtonL2, NewtonCosine, [default=Cosine]\n",
      " |      For growing policy Lossguide default=NewtonL2.\n",
      " |      GPU only. Score that is used during tree construction to select the next tree split.\n",
      " |  \n",
      " |  max_depth : int, Synonym for depth.\n",
      " |  \n",
      " |  n_estimators : int, synonym for iterations.\n",
      " |  \n",
      " |  num_trees : int, synonym for iterations.\n",
      " |  \n",
      " |  num_boost_round : int, synonym for iterations.\n",
      " |  \n",
      " |  colsample_bylevel : float, synonym for rsm.\n",
      " |  \n",
      " |  random_state : int, synonym for random_seed.\n",
      " |  \n",
      " |  reg_lambda : float, synonym for l2_leaf_reg.\n",
      " |  \n",
      " |  objective : string, synonym for loss_function.\n",
      " |  \n",
      " |  num_leaves : int, synonym for max_leaves.\n",
      " |  \n",
      " |  min_child_samples : int, synonym for min_data_in_leaf\n",
      " |  \n",
      " |  eta : float, synonym for learning_rate.\n",
      " |  \n",
      " |  max_bin : float, synonym for border_count.\n",
      " |  \n",
      " |  scale_pos_weight : float, synonym for class_weights.\n",
      " |      Can be used only for binary classification. Sets weight multiplier for\n",
      " |      class 1 to scale_pos_weight value.\n",
      " |  \n",
      " |  metadata : dict, string to string key-value pairs to be stored in model metadata storage\n",
      " |  \n",
      " |  early_stopping_rounds : int\n",
      " |      Synonym for od_wait. Only one of these parameters should be set.\n",
      " |  \n",
      " |  cat_features : list or numpy.ndarray, [default=None]\n",
      " |      If not None, giving the list of Categ features indices or names (names are represented as strings).\n",
      " |      If it contains feature names, feature names must be defined for the training dataset passed to 'fit'.\n",
      " |  \n",
      " |  text_features : list or numpy.ndarray, [default=None]\n",
      " |      If not None, giving the list of Text features indices or names (names are represented as strings).\n",
      " |      If it contains feature names, feature names must be defined for the training dataset passed to 'fit'.\n",
      " |  \n",
      " |  embedding_features : list or numpy.ndarray, [default=None]\n",
      " |      If not None, giving the list of Embedding features indices or names (names are represented as strings).\n",
      " |      If it contains feature names, feature names must be defined for the training dataset passed to 'fit'.\n",
      " |  \n",
      " |  leaf_estimation_backtracking : string, [default=None]\n",
      " |      Type of backtracking during gradient descent.\n",
      " |      Possible values:\n",
      " |          - 'No' - never backtrack; supported on CPU and GPU\n",
      " |          - 'AnyImprovement' - reduce the descent step until the value of loss function is less than before the step; supported on CPU and GPU\n",
      " |          - 'Armijo' - reduce the descent step until Armijo condition is satisfied; supported on GPU only\n",
      " |  \n",
      " |  model_shrink_rate : float, [default=0]\n",
      " |      This parameter enables shrinkage of model at the start of each iteration. CPU only.\n",
      " |      For Constant mode shrinkage coefficient is calculated as (1 - model_shrink_rate * learning_rate).\n",
      " |      For Decreasing mode shrinkage coefficient is calculated as (1 - model_shrink_rate / iteration).\n",
      " |      Shrinkage coefficient should be in [0, 1).\n",
      " |  \n",
      " |  model_shrink_mode : string, [default=None]\n",
      " |      Mode of shrinkage coefficient calculation. CPU only.\n",
      " |      Possible values:\n",
      " |          - 'Constant' - Shrinkage coefficient is constant at each iteration.\n",
      " |          - 'Decreasing' - Shrinkage coefficient decreases at each iteration.\n",
      " |  \n",
      " |  langevin : bool, [default=False]\n",
      " |      Enables the Stochastic Gradient Langevin Boosting. CPU only.\n",
      " |  \n",
      " |  diffusion_temperature : float, [default=0]\n",
      " |      Langevin boosting diffusion temperature. CPU only.\n",
      " |  \n",
      " |  posterior_sampling : bool, [default=False]\n",
      " |      Set group of parameters for further use Uncertainty prediction:\n",
      " |          - Langevin = True\n",
      " |          - Model Shrink Rate = 1/(2N), where N is dataset size\n",
      " |          - Model Shrink Mode = Constant\n",
      " |          - Diffusion-temperature = N, where N is dataset size. CPU only.\n",
      " |  \n",
      " |  boost_from_average : bool, [default=True for RMSE, False for other losses]\n",
      " |      Enables to initialize approx values by best constant value for specified loss function.\n",
      " |      Available for RMSE, Logloss, CrossEntropy, Quantile and MAE.\n",
      " |  \n",
      " |  tokenizers : list of dicts,\n",
      " |      Each dict is a tokenizer description. Example:\n",
      " |      ```\n",
      " |      [\n",
      " |          {\n",
      " |              'tokenizer_id': 'Tokenizer',  # Tokeinzer identifier.\n",
      " |              'lowercasing': 'false',  # Possible values: 'true', 'false'.\n",
      " |              'number_process_policy': 'LeaveAsIs',  # Possible values: 'Skip', 'LeaveAsIs', 'Replace'.\n",
      " |              'number_token': '%',  # Rarely used character. Used in conjunction with Replace NumberProcessPolicy.\n",
      " |              'separator_type': 'ByDelimiter',  # Possible values: 'ByDelimiter', 'BySense'.\n",
      " |              'delimiter': ' ',  # Used in conjunction with ByDelimiter SeparatorType.\n",
      " |              'split_by_set': 'false',  # Each single character in delimiter used as individual delimiter.\n",
      " |              'skip_empty': 'true',  # Possible values: 'true', 'false'.\n",
      " |              'token_types': ['Word', 'Number', 'Unknown'],  # Used in conjunction with BySense SeparatorType.\n",
      " |                  # Possible values: 'Word', 'Number', 'Punctuation', 'SentenceBreak', 'ParagraphBreak', 'Unknown'.\n",
      " |              'subtokens_policy': 'SingleToken',  # Possible values:\n",
      " |                  # 'SingleToken' - All subtokens are interpreted as single token).\n",
      " |                  # 'SeveralTokens' - All subtokens are interpreted as several token.\n",
      " |          },\n",
      " |          ...\n",
      " |      ]\n",
      " |      ```\n",
      " |  \n",
      " |  dictionaries : list of dicts,\n",
      " |      Each dict is a tokenizer description. Example:\n",
      " |      ```\n",
      " |      [\n",
      " |          {\n",
      " |              'dictionary_id': 'Dictionary',  # Dictionary identifier.\n",
      " |              'token_level_type': 'Word',  # Possible values: 'Word', 'Letter'.\n",
      " |              'gram_order': '1',  # 1 for Unigram, 2 for Bigram, ...\n",
      " |              'skip_step': '0',  # 1 for 1-skip-gram, ...\n",
      " |              'end_of_word_token_policy': 'Insert',  # Possible values: 'Insert', 'Skip'.\n",
      " |              'end_of_sentence_token_policy': 'Skip',  # Possible values: 'Insert', 'Skip'.\n",
      " |              'occurrence_lower_bound': '3',  # The lower bound of token occurrences in the text to include it in the dictionary.\n",
      " |              'max_dictionary_size': '50000',  # The max dictionary size.\n",
      " |          },\n",
      " |          ...\n",
      " |      ]\n",
      " |      ```\n",
      " |  \n",
      " |  feature_calcers : list of strings,\n",
      " |      Each string is a calcer description. Example:\n",
      " |      ```\n",
      " |      [\n",
      " |          'NaiveBayes',\n",
      " |          'BM25',\n",
      " |          'BoW:top_tokens_count=2000',\n",
      " |      ]\n",
      " |      ```\n",
      " |  \n",
      " |  text_processing : dict,\n",
      " |      Text processging description.\n",
      " |  \n",
      " |  eval_fraction : float, [default=None]\n",
      " |      Fraction of the train dataset to be used as the evaluation dataset.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CatBoostClassifier\n",
      " |      CatBoost\n",
      " |      _CatBoostBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function=None, border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, target_border=None, classes_count=None, class_weights=None, auto_class_weights=None, class_names=None, one_hot_max_size=None, random_strength=None, random_score_type=None, name=None, ignored_features=None, train_dir=None, custom_loss=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, mvs_reg=None, sampling_unit=None, sampling_frequency=None, dev_score_calc_obj_block_size=None, dev_efb_max_buckets=None, sparse_features_conflict_fraction=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, scale_pos_weight=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, per_object_feature_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, posterior_sampling=None, boost_from_average=None, text_features=None, tokenizers=None, dictionaries=None, feature_calcers=None, text_processing=None, embedding_features=None, callback=None, eval_fraction=None, fixed_binary_splits=None)\n",
      " |      Initialize the CatBoost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : dict\n",
      " |          Parameters for CatBoost.\n",
      " |          If  None, all params are set to their defaults.\n",
      " |          If  dict, overriding parameters present in dict.\n",
      " |  \n",
      " |  fit(self, X, y=None, cat_features=None, text_features=None, embedding_features=None, sample_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, plot_file=None, column_description=None, verbose_eval=None, metric_period=None, silent=None, early_stopping_rounds=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, init_model=None, callbacks=None, log_cout=<ipykernel.iostream.OutStream object at 0x000001C449FA7FD0>, log_cerr=<ipykernel.iostream.OutStream object at 0x000001C449FA7EB0>)\n",
      " |      Fit the CatBoostClassifier model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      " |      \n",
      " |      y : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels, 1 dimensional array like.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      cat_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Categ columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      text_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Text columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      embedding_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Embedding columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      sample_weight : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Instance weights, 1 dimensional array like.\n",
      " |      \n",
      " |      baseline : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving 2 dimensional array like data.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      use_best_model : bool, optional (default=None)\n",
      " |          Flag to use best model\n",
      " |      \n",
      " |      eval_set : catboost.Pool or list of catboost.Pool or tuple (X, y) or list [(X, y)], optional (default=None)\n",
      " |          Validation dataset or datasets for metrics calculation and possibly early stopping.\n",
      " |      \n",
      " |      metric_period : int\n",
      " |          Frequency of evaluating metrics.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      " |          if set to False, logging_level is set to Silent.\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output and\n",
      " |          logging_level is set to Verbose.\n",
      " |      \n",
      " |      silent : bool\n",
      " |          If silent is True, logging_level is set to Silent.\n",
      " |          If silent is False, logging_level is set to Verbose.\n",
      " |      \n",
      " |      logging_level : string, optional (default=None)\n",
      " |          Possible values:\n",
      " |              - 'Silent'\n",
      " |              - 'Verbose'\n",
      " |              - 'Info'\n",
      " |              - 'Debug'\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file\n",
      " |      \n",
      " |      verbose_eval : bool or int\n",
      " |          Synonym for verbose. Only one of these parameters should be set.\n",
      " |      \n",
      " |      early_stopping_rounds : int\n",
      " |          Activates Iter overfitting detector with od_wait set to early_stopping_rounds.\n",
      " |      \n",
      " |      save_snapshot : bool, [default=None]\n",
      " |          Enable progress snapshotting for restoring progress after crashes or interruptions\n",
      " |      \n",
      " |      snapshot_file : string or pathlib.Path, [default=None]\n",
      " |          Learn progress snapshot file path, if None will use default filename\n",
      " |      \n",
      " |      snapshot_interval: int, [default=600]\n",
      " |          Interval between saving snapshots (seconds)\n",
      " |      \n",
      " |      init_model : CatBoost class or string or pathlib.Path, [default=None]\n",
      " |          Continue training starting from the existing model.\n",
      " |          If this parameter is a string or pathlib.Path, load initial model from the path specified by this string.\n",
      " |      \n",
      " |      callbacks : list, optional (default=None)\n",
      " |          List of callback objects that are applied at end of each iteration.\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model : CatBoost\n",
      " |  \n",
      " |  get_probability_threshold(self)\n",
      " |      Get a threshold for class separation in binary classification task\n",
      " |  \n",
      " |  predict(self, data, prediction_type='Class', ntree_start=0, ntree_end=0, thread_count=-1, verbose=None, task_type='CPU')\n",
      " |      Predict with data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      prediction_type : string, optional (default='Class')\n",
      " |          Can be:\n",
      " |          - 'RawFormulaVal' : return raw formula value.\n",
      " |          - 'Class' : return class label.\n",
      " |          - 'Probability' : return probability for every class.\n",
      " |          - 'LogProbability' : return log probability for every class.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool, optional (default=False)\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction:\n",
      " |          If data is for a single object, the return value depends on prediction_type value:\n",
      " |              - 'RawFormulaVal' : return raw formula value.\n",
      " |              - 'Class' : return class label.\n",
      " |              - 'Probability' : return one-dimensional numpy.ndarray with probability for every class.\n",
      " |              - 'LogProbability' : return one-dimensional numpy.ndarray with\n",
      " |                log probability for every class.\n",
      " |          otherwise numpy.ndarray, with values that depend on prediction_type value:\n",
      " |              - 'RawFormulaVal' : one-dimensional array of raw formula value for each object.\n",
      " |              - 'Class' : one-dimensional array of class label for each object.\n",
      " |              - 'Probability' : two-dimensional numpy.ndarray with shape (number_of_objects x number_of_classes)\n",
      " |                with probability for every class for each object.\n",
      " |              - 'LogProbability' : two-dimensional numpy.ndarray with shape (number_of_objects x number_of_classes)\n",
      " |                with log probability for every class for each object.\n",
      " |  \n",
      " |  predict_log_proba(self, data, ntree_start=0, ntree_end=0, thread_count=-1, verbose=None, task_type='CPU')\n",
      " |      Predict class log probability with data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          If data is for a single object\n",
      " |              return one-dimensional numpy.ndarray with log probability for every class.\n",
      " |          otherwise\n",
      " |              return two-dimensional numpy.ndarray with shape (number_of_objects x number_of_classes)\n",
      " |              with log probability for every class for each object.\n",
      " |  \n",
      " |  predict_proba(self, X, ntree_start=0, ntree_end=0, thread_count=-1, verbose=None, task_type='CPU')\n",
      " |      Predict class probability with X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If X is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          If X is for a single object\n",
      " |              return one-dimensional numpy.ndarray with probability for every class.\n",
      " |          otherwise\n",
      " |              return two-dimensional numpy.ndarray with shape (number_of_objects x number_of_classes)\n",
      " |              with probability for every class for each object.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Calculate accuracy.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          Data to apply model on.\n",
      " |      y : list or numpy.ndarray\n",
      " |          True labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      accuracy : float\n",
      " |  \n",
      " |  set_probability_threshold(self, binclass_probability_threshold=None)\n",
      " |      Set a threshold for class separation in binary classification task for a trained model.\n",
      " |      :param binclass_probability_threshold: float number in [0, 1] or None to discard it\n",
      " |  \n",
      " |  staged_predict(self, data, prediction_type='Class', ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      " |      Predict target at each stage for data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      prediction_type : string, optional (default='Class')\n",
      " |          Can be:\n",
      " |          - 'RawFormulaVal' : return raw formula value.\n",
      " |          - 'Class' : return class label.\n",
      " |          - 'Probability' : return probability for every class.\n",
      " |          - 'LogProbability' : return log probability for every class.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : generator for each iteration that generates:\n",
      " |          If data is for a single object, the return value depends on prediction_type value:\n",
      " |              - 'RawFormulaVal' : return raw formula value.\n",
      " |              - 'Class' : return majority vote class.\n",
      " |              - 'Probability' : return one-dimensional numpy.ndarray with probability for every class.\n",
      " |              - 'LogProbability' : return one-dimensional numpy.ndarray with\n",
      " |                log probability for every class.\n",
      " |          otherwise numpy.ndarray, with values that depend on prediction_type value:\n",
      " |              - 'RawFormulaVal' : one-dimensional array of raw formula value for each object.\n",
      " |              - 'Class' : one-dimensional array of class label for each object.\n",
      " |              - 'Probability' : two-dimensional numpy.ndarray with shape (number_of_objects x number_of_classes)\n",
      " |                with probability for every class for each object.\n",
      " |              - 'LogProbability' : two-dimensional numpy.ndarray with shape (number_of_objects x number_of_classes)\n",
      " |                with log probability for every class for each object.\n",
      " |  \n",
      " |  staged_predict_log_proba(self, data, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      " |      Predict classification target at each stage for data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : generator for each iteration that generates:\n",
      " |          If data is for a single object\n",
      " |              return one-dimensional numpy.ndarray with log probability for every class.\n",
      " |          otherwise\n",
      " |              return two-dimensional numpy.ndarray with shape (number_of_objects x number_of_classes)\n",
      " |              with log probability for every class for each object.\n",
      " |  \n",
      " |  staged_predict_proba(self, data, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      " |      Predict classification target at each stage for data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : generator for each iteration that generates:\n",
      " |          If data is for a single object\n",
      " |              return one-dimensional numpy.ndarray with probability for every class.\n",
      " |          otherwise\n",
      " |              return two-dimensional numpy.ndarray with shape (number_of_objects x number_of_classes)\n",
      " |              with probability for every class for each object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from CatBoost:\n",
      " |  \n",
      " |  calc_feature_statistics(self, data, target=None, feature=None, prediction_type=None, cat_feature_values=None, plot=True, max_cat_features_on_plot=10, thread_count=-1, plot_file=None)\n",
      " |      Get statistics for the feature using the model, dataset and target.\n",
      " |      To use this function, you should install plotly.\n",
      " |      \n",
      " |      The catboost model has borders for the float features used in it. The borders divide\n",
      " |      feature values into bins, and the model's prediction depends on the number of the bin where the\n",
      " |      feature value falls in.\n",
      " |      \n",
      " |      For float features this function takes model's borders and computes\n",
      " |      1) Mean target value for every bin;\n",
      " |      2) Mean model prediction for every bin;\n",
      " |      3) The number of objects in dataset which fall into each bin;\n",
      " |      4) Predictions on varying feature. For every object, varies the feature value\n",
      " |      so that it falls into bin #0, bin #1, ... and counts model predictions.\n",
      " |      Then counts average prediction for each bin.\n",
      " |      \n",
      " |      For categorical features (only one-hot supported) does the same, but takes feature values\n",
      " |      provided in cat_feature_values instead of borders.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost. Pool or dict {'pool_name': pool} if you want several pools\n",
      " |          Data to compute statistics on\n",
      " |      target: numpy.ndarray or pandas.Series or dict {'pool_name': target} if you want several pools or None\n",
      " |          Target corresponding to data\n",
      " |          Use only if data is not catboost.Pool.\n",
      " |      feature: None, int, string, or list of int or strings\n",
      " |          Features indexes or names in pd.DataFrame for which you want to get statistics.\n",
      " |          None, if you need statistics for all features.\n",
      " |      prediction_type: str\n",
      " |          Prediction type used for counting mean_prediction: 'Class', 'Probability' or 'RawFormulaVal'.\n",
      " |          If not specified, is derived from the model.\n",
      " |      cat_feature_values: list or numpy.ndarray or pandas.Series or\n",
      " |                          dict: int or string to list or numpy.ndarray or pandas.Series\n",
      " |          Contains categorical feature values you need to get statistics on.\n",
      " |          Use dict, when parameter 'feature' is a list to specify cat values for different features.\n",
      " |          When parameter 'feature' is int or str, you can just pass list of cat values.\n",
      " |      plot: bool\n",
      " |          Plot statistics.\n",
      " |      max_cat_features_on_plot: int\n",
      " |          If categorical feature takes more than max_cat_features_on_plot different unique values,\n",
      " |          output result on several plots, not more than max_cat_features_on_plot feature values on each.\n",
      " |          Used only if plot=True or plot_file is not None.\n",
      " |      thread_count: int\n",
      " |          Number of threads to use for getting statistics.\n",
      " |      plot_file: str\n",
      " |          Output file for plot statistics.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict if parameter 'feature' is int or string, else dict of dicts:\n",
      " |          For each unique feature contain\n",
      " |          python dict with binarized feature statistics.\n",
      " |          For float feature, includes\n",
      " |                  'borders' -- borders for the specified feature in model\n",
      " |                  'binarized_feature' -- numbers of bins where feature values fall\n",
      " |                  'mean_target' -- mean value of target over each bin\n",
      " |                  'mean_prediction' -- mean value of model prediction over each bin\n",
      " |                  'objects_per_bin' -- number of objects per bin\n",
      " |                  'predictions_on_varying_feature' -- averaged over dataset predictions for\n",
      " |                  varying feature (see above)\n",
      " |          For one-hot feature, returns the same, but with 'cat_values' instead of 'borders'\n",
      " |  \n",
      " |  calc_leaf_indexes(self, data, ntree_start=0, ntree_end=0, thread_count=-1, verbose=False)\n",
      " |      Returns indexes of leafs to which objects from pool are mapped by model trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Index of first tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Index of the tree after last tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool (default=False)\n",
      " |          Enable debug logging level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_indexes : 2-dimensional numpy.ndarray of numpy.uint32 with shape (object count, ntree_end - ntree_start).\n",
      " |          i-th row is an array of leaf indexes for i-th object.\n",
      " |  \n",
      " |  compare(self, model, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot_file=None, log_cout=<ipykernel.iostream.OutStream object at 0x000001C449FA7FD0>, log_cerr=<ipykernel.iostream.OutStream object at 0x000001C449FA7EB0>)\n",
      " |      Draw train and eval errors in Jupyter notebook for both models\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      model: CatBoost model\n",
      " |          Another model to draw metrics\n",
      " |      \n",
      " |      data : catboost.Pool\n",
      " |          Data to evaluate metrics on.\n",
      " |      \n",
      " |      metrics : list of strings or catboost.metrics.BuiltinMetric\n",
      " |          List of evaluated metrics.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      tmp_dir : string or pathlib.Path (default=None)\n",
      " |          The name of the temporary directory for intermediate results.\n",
      " |          If None, then the name will be generated.\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging\n",
      " |  \n",
      " |  create_metric_calcer(self, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None)\n",
      " |      Create batch metric calcer. Could be used to aggregate metric on several pools\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |          Same as in eval_metrics except data\n",
      " |      Returns\n",
      " |      -------\n",
      " |          BatchMetricCalcer object\n",
      " |      \n",
      " |      Usage example\n",
      " |      -------\n",
      " |      # Large dataset is partitioned into parts [part1, part2]\n",
      " |      model.fit(params)\n",
      " |      batch_calcer = model.create_metric_calcer(['Logloss'])\n",
      " |      batch_calcer.add(part1)\n",
      " |      batch_calcer.add(part2)\n",
      " |      metrics = batch_calcer.eval_metrics()\n",
      " |  \n",
      " |  drop_unused_features(self)\n",
      " |      Drop unused features information from model\n",
      " |  \n",
      " |  eval_metrics(self, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot=False, plot_file=None, log_cout=<ipykernel.iostream.OutStream object at 0x000001C449FA7FD0>, log_cerr=<ipykernel.iostream.OutStream object at 0x000001C449FA7EB0>)\n",
      " |      Calculate metrics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool\n",
      " |          Data to evaluate metrics on.\n",
      " |      \n",
      " |      metrics : list of strings or catboost.metrics.BuiltinMetric\n",
      " |          List of evaluated metrics.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      tmp_dir : string or pathlib.Path (default=None)\n",
      " |          The name of the temporary directory for intermediate results.\n",
      " |          If None, then the name will be generated.\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : dict: metric -> array of shape [(ntree_end - ntree_start) / eval_period]\n",
      " |  \n",
      " |  get_all_params(self)\n",
      " |      Get all params (specified by user and default params) that were set in training from CatBoost model.\n",
      " |      Full parameters documentation could be found here: https://catboost.ai/docs/concepts/python-reference_parameters-list.html\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : dict\n",
      " |          Dictionary of {param_key: param_value}.\n",
      " |  \n",
      " |  get_borders(self)\n",
      " |      Return map feature_index: borders for float features.\n",
      " |  \n",
      " |  get_cat_feature_indices(self)\n",
      " |  \n",
      " |  get_embedding_feature_indices(self)\n",
      " |  \n",
      " |  get_feature_importance(self, data=None, type=<EFstrType.FeatureImportance: 2>, prettified=False, thread_count=-1, verbose=False, fstr_type=None, shap_mode='Auto', model_output='Raw', interaction_indices=None, shap_calc_type='Regular', reference_data=None, sage_n_samples=128, sage_batch_size=512, sage_detect_convergence=True, log_cout=<ipykernel.iostream.OutStream object at 0x000001C449FA7FD0>, log_cerr=<ipykernel.iostream.OutStream object at 0x000001C449FA7EB0>)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data :\n",
      " |          Data to get feature importance.\n",
      " |          If type in ('LossFunctionChange', 'ShapValues', 'ShapInteractionValues') data must of Pool type.\n",
      " |              For every object in this dataset feature importances will be calculated.\n",
      " |          if type == 'SageValues' data must of Pool type.\n",
      " |              For every feature in this dataset importance will be calculated.\n",
      " |          If type == 'PredictionValuesChange', data is None or a dataset of Pool type\n",
      " |              Dataset specification is needed only in case if the model does not contain leaf weight information (trained with CatBoost v < 0.9).\n",
      " |          If type == 'PredictionDiff' data must contain a matrix of feature values of shape (2, n_features).\n",
      " |              Possible types are catboost.Pool or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData or pandas.SparseDataFrame or scipy.sparse.spmatrix\n",
      " |          If type == 'FeatureImportance'\n",
      " |              See 'PredictionValuesChange' for non-ranking metrics and 'LossFunctionChange' for ranking metrics.\n",
      " |          If type == 'Interaction'\n",
      " |              This parameter is not used.\n",
      " |      \n",
      " |      type : EFstrType or string (converted to EFstrType), optional\n",
      " |                  (default=EFstrType.FeatureImportance)\n",
      " |          Possible values:\n",
      " |              - PredictionValuesChange\n",
      " |                  Calculate score for every feature.\n",
      " |              - LossFunctionChange\n",
      " |                  Calculate score for every feature by loss.\n",
      " |              - FeatureImportance\n",
      " |                  PredictionValuesChange for non-ranking metrics and LossFunctionChange for ranking metrics\n",
      " |              - ShapValues\n",
      " |                  Calculate SHAP Values for every object.\n",
      " |              - ShapInteractionValues\n",
      " |                  Calculate SHAP Interaction Values between each pair of features for every object\n",
      " |              - Interaction\n",
      " |                  Calculate pairwise score between every feature.\n",
      " |              - PredictionDiff\n",
      " |                  Calculate most important features explaining difference in predictions for a pair of documents.\n",
      " |              - SageValues\n",
      " |                  Calculate SAGE value for every feature\n",
      " |      \n",
      " |      prettified : bool, optional (default=False)\n",
      " |          change returned data format to the list of (feature_id, importance) pairs sorted by importance\n",
      " |      \n",
      " |      thread_count : int, optional (default=-1)\n",
      " |          Number of threads.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If False, then evaluation is not logged. If True, then each possible iteration is logged.\n",
      " |          If a positive integer, then it stands for the size of batch N. After processing each batch, print progress\n",
      " |          and remaining time.\n",
      " |      \n",
      " |      fstr_type : string, deprecated, use type instead\n",
      " |      \n",
      " |      shap_mode : string, optional (default=\"Auto\")\n",
      " |          used only for ShapValues type\n",
      " |          Possible values:\n",
      " |              - \"Auto\"\n",
      " |                  Use direct SHAP Values calculation only if data size is smaller than average leaves number\n",
      " |                  (the best of two strategies below is chosen).\n",
      " |              - \"UsePreCalc\"\n",
      " |                  Calculate SHAP Values for every leaf in preprocessing. Final complexity is\n",
      " |                  O(NT(D+F))+O(TL^2 D^2) where N is the number of documents(objects), T - number of trees,\n",
      " |                  D - average tree depth, F - average number of features in tree, L - average number of leaves in tree\n",
      " |                  This is much faster (because of a smaller constant) than direct calculation when N >> L\n",
      " |              - \"NoPreCalc\"\n",
      " |                  Use direct SHAP Values calculation calculation with complexity O(NTLD^2). Direct algorithm\n",
      " |                  is faster when N < L (algorithm from https://arxiv.org/abs/1802.03888)\n",
      " |      \n",
      " |      shap_calc_type : EShapCalcType or string, optional (default=\"Regular\")\n",
      " |          used only for ShapValues type\n",
      " |          Possible values:\n",
      " |              - \"Regular\"\n",
      " |                  Calculate regular SHAP values\n",
      " |              - \"Approximate\"\n",
      " |                  Calculate approximate SHAP values\n",
      " |              - \"Exact\"\n",
      " |                  Calculate exact SHAP values\n",
      " |      \n",
      " |      interaction_indices : list of int or string (feature_idx_1, feature_idx_2), optional (default=None)\n",
      " |          used only for ShapInteractionValues type\n",
      " |          Calculate SHAP Interaction Values between pair of features feature_idx_1 and feature_idx_2 for every object\n",
      " |      \n",
      " |      reference_data: catboost.Pool or None\n",
      " |          Reference data for Independent Tree SHAP values from https://arxiv.org/abs/1905.04610v1\n",
      " |          if type == 'ShapValues' and reference_data is not None, then Independent Tree SHAP values are calculated\n",
      " |      \n",
      " |      sage_n_samples: int, optional (default=32)\n",
      " |          Number of outer samples used in SAGE values approximation algorithm\n",
      " |      sage_batch_size: int, optional (default=min(512, number of samples in dataset))\n",
      " |          Number of samples used on each step of SAGE values approximation algorithm\n",
      " |      sage_detect_convergence: bool, optional (default=False)\n",
      " |          If set True, sage values calculation will be stopped either when sage values converge\n",
      " |          or when sage_n_samples iterations of algorithm pass\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      depends on type:\n",
      " |          - FeatureImportance\n",
      " |              See PredictionValuesChange for non-ranking metrics and LossFunctionChange for ranking metrics.\n",
      " |          - PredictionValuesChange, LossFunctionChange, PredictionDiff, SageValues with prettified=False (default)\n",
      " |              list of length [n_features] with feature_importance values (float) for feature\n",
      " |          - PredictionValuesChange, LossFunctionChange, PredictionDiff, SageValues with prettified=True\n",
      " |              list of length [n_features] with (feature_id (string), feature_importance (float)) pairs, sorted by feature_importance in descending order\n",
      " |          - ShapValues\n",
      " |              np.ndarray of shape (n_objects, n_features + 1) with Shap values (float) for (object, feature).\n",
      " |              In case of multiclass the returned value is np.ndarray of shape\n",
      " |              (n_objects, classes_count, n_features + 1). For each object it contains Shap values (float).\n",
      " |              Values are calculated for RawFormulaVal predictions.\n",
      " |          - ShapInteractionValues\n",
      " |              np.ndarray of shape (n_objects, n_features + 1, n_features + 1) with Shap interaction values (float) for (object, feature(i), feature(j)).\n",
      " |              In case of multiclass the returned value is np.ndarray of shape\n",
      " |              (n_objects, classes_count, n_features + 1, n_features + 1). For each object it contains Shap interaction values (float).\n",
      " |              Values are calculated for RawFormulaVal predictions.\n",
      " |          - Interaction\n",
      " |              list of length [n_features] of 3-element lists of (first_feature_index, second_feature_index, interaction_score (float))\n",
      " |  \n",
      " |  get_object_importance(self, pool, train_pool, top_size=-1, type='Average', update_method='SinglePoint', importance_values_sign='All', thread_count=-1, verbose=False, ostr_type=None, log_cout=<ipykernel.iostream.OutStream object at 0x000001C449FA7FD0>, log_cerr=<ipykernel.iostream.OutStream object at 0x000001C449FA7EB0>)\n",
      " |      This is the implementation of the LeafInfluence algorithm from the following paper:\n",
      " |      https://arxiv.org/pdf/1802.06640.pdf\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      pool : Pool\n",
      " |          The pool for which you want to evaluate the object importances.\n",
      " |      \n",
      " |      train_pool : Pool\n",
      " |          The pool on which the model has been trained.\n",
      " |      \n",
      " |      top_size : int (default=-1)\n",
      " |          Method returns the result of the top_size most important train objects.\n",
      " |          If -1, then the top size is not limited.\n",
      " |      \n",
      " |      type : string, optional (default='Average')\n",
      " |          Possible values:\n",
      " |              - Average (Method returns the mean train objects scores for all input objects)\n",
      " |              - PerObject (Method returns the train objects scores for every input object)\n",
      " |      \n",
      " |      importance_values_sign : string, optional (default='All')\n",
      " |          Method returns only Positive, Negative or All values.\n",
      " |          Possible values:\n",
      " |              - Positive\n",
      " |              - Negative\n",
      " |              - All\n",
      " |      \n",
      " |      update_method : string, optional (default='SinglePoint')\n",
      " |          Possible values:\n",
      " |              - SinglePoint\n",
      " |              - TopKLeaves (It is posible to set top size : TopKLeaves:top=2)\n",
      " |              - AllPoints\n",
      " |          Description of the update set methods are given in section 3.1.3 of the paper.\n",
      " |      \n",
      " |      thread_count : int, optional (default=-1)\n",
      " |          Number of threads.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If False, then evaluation is not logged. If True, then each possible iteration is logged.\n",
      " |          If a positive integer, then it stands for the size of batch N. After processing each batch, print progress\n",
      " |          and remaining time.\n",
      " |      \n",
      " |      ostr_type : string, deprecated, use type instead\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object_importances : tuple of two arrays (indices and scores) of shape = [top_size]\n",
      " |  \n",
      " |  get_param(self, key)\n",
      " |      Get param value from CatBoost model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : string\n",
      " |          The key to get param value from.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value :\n",
      " |          The param value of the key, returns None if param do not exist.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get all params from CatBoost model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : dict\n",
      " |          Dictionary of {param_key: param_value}.\n",
      " |  \n",
      " |  get_text_feature_indices(self)\n",
      " |  \n",
      " |  grid_search(self, param_grid, X, y=None, cv=3, partition_random_seed=0, calc_cv_statistics=True, search_by_train_test_split=True, refit=True, shuffle=True, stratified=None, train_size=0.8, verbose=True, plot=False, plot_file=None, log_cout=<ipykernel.iostream.OutStream object at 0x000001C449FA7FD0>, log_cerr=<ipykernel.iostream.OutStream object at 0x000001C449FA7EB0>)\n",
      " |      Exhaustive search over specified parameter values for a model.\n",
      " |      Aafter calling this method model is fitted and can be used, if not specified otherwise (refit=False).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      param_grid: dict or list of dictionaries\n",
      " |          Dictionary with parameters names (string) as keys and lists of parameter settings\n",
      " |          to try as values, or a list of such dictionaries, in which case the grids spanned by each\n",
      " |          dictionary in the list are explored.\n",
      " |          This enables searching over any sequence of parameter settings.\n",
      " |      \n",
      " |      X: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |          Data to compute statistics on\n",
      " |      \n",
      " |      y: numpy.ndarray or pandas.Series or None\n",
      " |          Target corresponding to data\n",
      " |          Use only if data is not catboost.Pool.\n",
      " |      \n",
      " |      cv: int, cross-validation generator or an iterable, optional (default=None)\n",
      " |          Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
      " |          - None, to use the default 3-fold cross validation,\n",
      " |          - integer, to specify the number of folds in a (Stratified)KFold\n",
      " |          - one of the scikit-learn splitter classes\n",
      " |              (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
      " |          - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |      \n",
      " |      partition_random_seed: int, optional (default=0)\n",
      " |          Use this as the seed value for random permutation of the data.\n",
      " |          Permutation is performed before splitting the data for cross validation.\n",
      " |          Each seed generates unique data splits.\n",
      " |          Used only when cv is None or int.\n",
      " |      \n",
      " |      search_by_train_test_split: bool, optional (default=True)\n",
      " |          If True, source dataset is splitted into train and test parts, models are trained\n",
      " |          on the train part and parameters are compared by loss function score on the test part.\n",
      " |          After that, if calc_cv_statistics=true, statistics on metrics are calculated\n",
      " |          using cross-validation using best parameters and the model is fitted with these parameters.\n",
      " |      \n",
      " |          If False, every iteration of grid search evaluates results on cross-validation.\n",
      " |          It is recommended to set parameter to True for large datasets, and to False for small datasets.\n",
      " |      \n",
      " |      calc_cv_statistics: bool, optional (default=True)\n",
      " |          The parameter determines whether quality should be estimated.\n",
      " |          using cross-validation with the found best parameters. Used only when search_by_train_test_split=True.\n",
      " |      \n",
      " |      refit: bool (default=True)\n",
      " |          Refit an estimator using the best found parameters on the whole dataset.\n",
      " |      \n",
      " |      shuffle: bool, optional (default=True)\n",
      " |          Shuffle the dataset objects before parameters searching.\n",
      " |      \n",
      " |      stratified: bool, optional (default=None)\n",
      " |          Perform stratified sampling. True for classification and False otherwise.\n",
      " |          Currently supported only for final cross-validation.\n",
      " |      \n",
      " |      train_size: float, optional (default=0.8)\n",
      " |          Should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
      " |      \n",
      " |      verbose: bool or int, optional (default=True)\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output\n",
      " |          verbose==True is equal to verbose==1\n",
      " |          When verbose==False, there is no messages\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error for every set of parameters in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error for every set of parameters to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with two fields:\n",
      " |          'params': dict of best found parameters\n",
      " |          'cv_results': dict or pandas.core.frame.DataFrame with cross-validation results\n",
      " |              columns are: test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      " |  \n",
      " |  iterate_leaf_indexes(self, data, ntree_start=0, ntree_end=0)\n",
      " |      Returns indexes of leafs to which objects from pool are mapped by model trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Index of first tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Index of the tree after last tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_indexes : generator. For each object in pool yields one-dimensional numpy.ndarray of leaf indexes.\n",
      " |  \n",
      " |  load_model(self, fname=None, format='cbm', stream=None, blob=None)\n",
      " |      Load model from a file, stream or blob.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string\n",
      " |          Input file name.\n",
      " |  \n",
      " |  plot_partial_dependence(self, data, features, plot=True, plot_file=None, thread_count=-1)\n",
      " |      To use this function, you should install plotly.\n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |      features: int, str, list<int>, tuple<int>, list<string>, tuple<string>\n",
      " |          Float features to calculate partial dependence for. Number of features should be 1 or 2.\n",
      " |      plot: bool\n",
      " |          Plot predictions.\n",
      " |      plot_file: str\n",
      " |          Output file for plot predictions.\n",
      " |      thread_count: int\n",
      " |          Number of threads to use. If -1 use maximum available number of threads.\n",
      " |      Returns\n",
      " |      -------\n",
      " |          If number of features is one - 1d numpy array and figure with line plot.\n",
      " |          If number of features is two - 2d numpy array and figure with 2d heatmap.\n",
      " |  \n",
      " |  plot_predictions(self, data, features_to_change, plot=True, plot_file=None)\n",
      " |      To use this function, you should install plotly.\n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |      feature:\n",
      " |          Float features indexes in pd.DataFrame for which you want vary prediction value.\n",
      " |      plot: bool\n",
      " |          Plot predictions.\n",
      " |      plot_file: str\n",
      " |          Output file for plot predictions.\n",
      " |      Returns\n",
      " |      -------\n",
      " |          List of list of predictions for all buckets for all documents in data\n",
      " |  \n",
      " |  plot_tree(self, tree_idx, pool=None)\n",
      " |  \n",
      " |  randomized_search(self, param_distributions, X, y=None, cv=3, n_iter=10, partition_random_seed=0, calc_cv_statistics=True, search_by_train_test_split=True, refit=True, shuffle=True, stratified=None, train_size=0.8, verbose=True, plot=False, plot_file=None, log_cout=<ipykernel.iostream.OutStream object at 0x000001C449FA7FD0>, log_cerr=<ipykernel.iostream.OutStream object at 0x000001C449FA7EB0>)\n",
      " |      Randomized search on hyper parameters.\n",
      " |      After calling this method model is fitted and can be used, if not specified otherwise (refit=False).\n",
      " |      \n",
      " |      In contrast to grid_search, not all parameter values are tried out,\n",
      " |      but rather a fixed number of parameter settings is sampled from the specified distributions.\n",
      " |      The number of parameter settings that are tried is given by n_iter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      param_distributions: dict\n",
      " |          Dictionary with parameters names (string) as keys and distributions or lists of parameters to try.\n",
      " |          Distributions must provide a rvs method for sampling (such as those from scipy.stats.distributions).\n",
      " |          If a list is given, it is sampled uniformly.\n",
      " |      \n",
      " |      X: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |          Data to compute statistics on\n",
      " |      \n",
      " |      y: numpy.ndarray or pandas.Series or None\n",
      " |          Target corresponding to data\n",
      " |          Use only if data is not catboost.Pool.\n",
      " |      \n",
      " |      cv: int, cross-validation generator or an iterable, optional (default=None)\n",
      " |          Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
      " |          - None, to use the default 3-fold cross validation,\n",
      " |          - integer, to specify the number of folds in a (Stratified)KFold\n",
      " |          - one of the scikit-learn splitter classes\n",
      " |              (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
      " |          - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |      \n",
      " |      n_iter: int\n",
      " |          Number of parameter settings that are sampled.\n",
      " |          n_iter trades off runtime vs quality of the solution.\n",
      " |      \n",
      " |      partition_random_seed: int, optional (default=0)\n",
      " |          Use this as the seed value for random permutation of the data.\n",
      " |          Permutation is performed before splitting the data for cross validation.\n",
      " |          Each seed generates unique data splits.\n",
      " |          Used only when cv is None or int.\n",
      " |      \n",
      " |      search_by_train_test_split: bool, optional (default=True)\n",
      " |          If True, source dataset is splitted into train and test parts, models are trained\n",
      " |          on the train part and parameters are compared by loss function score on the test part.\n",
      " |          After that, if calc_cv_statistics=true, statistics on metrics are calculated\n",
      " |          using cross-validation using best parameters and the model is fitted with these parameters.\n",
      " |      \n",
      " |          If False, every iteration of grid search evaluates results on cross-validation.\n",
      " |          It is recommended to set parameter to True for large datasets, and to False for small datasets.\n",
      " |      \n",
      " |      calc_cv_statistics: bool, optional (default=True)\n",
      " |          The parameter determines whether quality should be estimated.\n",
      " |          using cross-validation with the found best parameters. Used only when search_by_train_test_split=True.\n",
      " |      \n",
      " |      refit: bool (default=True)\n",
      " |          Refit an estimator using the best found parameters on the whole dataset.\n",
      " |      \n",
      " |      shuffle: bool, optional (default=True)\n",
      " |          Shuffle the dataset objects before parameters searching.\n",
      " |      \n",
      " |      stratified: bool, optional (default=None)\n",
      " |          Perform stratified sampling. True for classification and False otherwise.\n",
      " |          Currently supported only for cross-validation.\n",
      " |      \n",
      " |      train_size: float, optional (default=0.8)\n",
      " |          Should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
      " |      \n",
      " |      verbose: bool or int, optional (default=True)\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output\n",
      " |          verbose==True is equal to verbose==1\n",
      " |          When verbose==False, there is no messages\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error for every set of parameters in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error for every set of parameters to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with two fields:\n",
      " |          'params': dict of best found parameters\n",
      " |          'cv_results': dict or pandas.core.frame.DataFrame with cross-validation results\n",
      " |              columns are: test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      " |  \n",
      " |  save_borders(self, fname)\n",
      " |      Save the model borders to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or pathlib.Path\n",
      " |          Output file name.\n",
      " |  \n",
      " |  save_model(self, fname, format='cbm', export_parameters=None, pool=None)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string\n",
      " |          Output file name.\n",
      " |      format : string\n",
      " |          Possible values:\n",
      " |              * 'cbm' for catboost binary format,\n",
      " |              * 'coreml' to export into Apple CoreML format\n",
      " |              * 'onnx' to export into ONNX-ML format\n",
      " |              * 'pmml' to export into PMML format\n",
      " |              * 'cpp' to export as C++ code\n",
      " |              * 'python' to export as Python code.\n",
      " |      export_parameters : dict\n",
      " |          Parameters for CoreML export:\n",
      " |              * prediction_type : string - either 'probability' or 'raw'\n",
      " |              * coreml_description : string\n",
      " |              * coreml_model_version : string\n",
      " |              * coreml_model_author : string\n",
      " |              * coreml_model_license: string\n",
      " |          Parameters for PMML export:\n",
      " |              * pmml_copyright : string\n",
      " |              * pmml_description : string\n",
      " |              * pmml_model_version : string\n",
      " |      pool : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series or catboost.FeaturesData\n",
      " |          Training pool.\n",
      " |  \n",
      " |  select_features(self, X, y=None, eval_set=None, features_for_select=None, num_features_to_select=None, algorithm=None, steps=None, shap_calc_type=None, train_final_model=True, verbose=None, logging_level=None, plot=False, plot_file=None, log_cout=<ipykernel.iostream.OutStream object at 0x000001C449FA7FD0>, log_cerr=<ipykernel.iostream.OutStream object at 0x000001C449FA7EB0>, grouping=None, features_tags_for_select=None, num_features_tags_to_select=None)\n",
      " |      Select best features from pool according to loss value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      " |      \n",
      " |      y : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels, 1 dimensional array like.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      eval_set : catboost.Pool or list of catboost.Pool or tuple (X, y) or list [(X, y)], optional (default=None)\n",
      " |          Validation dataset or datasets for metrics calculation and possibly early stopping.\n",
      " |      \n",
      " |      features_for_select : str or list of feature indices, names or ranges\n",
      " |          (for grouping = Individual)\n",
      " |          Which features should participate in the selection.\n",
      " |          Format examples:\n",
      " |              - [0, 2, 3, 4, 17]\n",
      " |              - [0, \"2-4\", 17] (both ends in ranges are inclusive)\n",
      " |              - \"0,2-4,20\"\n",
      " |              - [\"Name0\", \"Name2\", \"Name3\", \"Name4\", \"Name20\"]\n",
      " |      \n",
      " |      num_features_to_select : positive int\n",
      " |          (for grouping = Individual)\n",
      " |          How many features to select from features_for_select.\n",
      " |      \n",
      " |      algorithm : EFeaturesSelectionAlgorithm or string, optional (default=RecursiveByShapValues)\n",
      " |          Which algorithm to use for features selection.\n",
      " |          Possible values:\n",
      " |              - RecursiveByPredictionValuesChange\n",
      " |                  Use prediction values change as feature strength, eliminate batch of features at once.\n",
      " |              - RecursiveByLossFunctionChange\n",
      " |                  Use loss function change as feature strength, eliminate batch of features at each step.\n",
      " |              - RecursiveByShapValues\n",
      " |                  Use shap values to estimate loss function change, eliminate features one by one.\n",
      " |      \n",
      " |      steps : positive int, optional (default=1)\n",
      " |          How many steps should be performed. In other words, how many times a full model will be trained.\n",
      " |          More steps give more accurate results.\n",
      " |      \n",
      " |      shap_calc_type : EShapCalcType or string, optional (default=Regular)\n",
      " |          Which method to use for calculation of shap values.\n",
      " |          Possible values:\n",
      " |              - Regular\n",
      " |                  Calculate regular SHAP values\n",
      " |              - Approximate\n",
      " |                  Calculate approximate SHAP values\n",
      " |              - Exact\n",
      " |                  Calculate exact SHAP values\n",
      " |      \n",
      " |      train_final_model : bool, optional (default=True)\n",
      " |          Need to fit model with selected features.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      " |          if set to False, logging_level is set to Silent.\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output and\n",
      " |          logging_level is set to Verbose.\n",
      " |      \n",
      " |      logging_level : string, optional (default=None)\n",
      " |          Possible values:\n",
      " |              - 'Silent'\n",
      " |              - 'Verbose'\n",
      " |              - 'Info'\n",
      " |              - 'Debug'\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook.\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging\n",
      " |      \n",
      " |      grouping : EFeaturesSelectionGrouping or string, optional (default=Individual)\n",
      " |          Which grouping to use for features selection.\n",
      " |          Possible values:\n",
      " |              - Individual\n",
      " |                  Select individual features\n",
      " |              - ByTags\n",
      " |                  Select feature groups (marked by tags)\n",
      " |      \n",
      " |      features_tags_for_select : list of strings\n",
      " |          (for grouping = ByTags)\n",
      " |          Which features tags should participate in the selection.\n",
      " |      \n",
      " |      num_features_tags_to_select : positive int\n",
      " |          (for grouping = ByTags)\n",
      " |          How many features tags to select from features_tags_for_select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with fields:\n",
      " |          'selected_features': list of selected features indices\n",
      " |          'eliminated_features': list of eliminated features indices\n",
      " |          'selected_features_tags': list of selected features tags (optional, present if grouping == ByTags)\n",
      " |          'eliminated_features_tags': list of selected features tags (optional, present if grouping == ByTags)\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set parameters into CatBoost model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : key=value format\n",
      " |          List of key=value paris. Example: model.set_params(iterations=500, thread_count=2).\n",
      " |  \n",
      " |  shrink(self, ntree_end, ntree_start=0)\n",
      " |      Shrink the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntree_end: int\n",
      " |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |  \n",
      " |  virtual_ensembles_predict(self, data, prediction_type='VirtEnsembles', ntree_end=0, virtual_ensembles_count=10, thread_count=-1, verbose=None)\n",
      " |      Predict with data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      prediction_type : string, optional (default='RawFormulaVal')\n",
      " |          Can be:\n",
      " |          - 'VirtEnsembles': return V (virtual_ensembles_count) predictions.\n",
      " |              k-th virtEnsemle consists of trees [0, T/2] + [T/2 + T/(2V) * k, T/2 + T/(2V) * (k + 1)]  * constant.\n",
      " |          - 'TotalUncertainty': see returned predictions format in 'Returns' part\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      virtual_ensembles_count: int, optional (default=10)\n",
      " |          virtual ensembles count for 'TotalUncertainty' and 'VirtEnsembles' prediction types.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool, optional (default=False)\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          (with V as virtual_ensembles_count and T as trees count,\n",
      " |          k-th virtEnsemle consists of trees [0, T/2] + [T/2 + T/(2V) * k, T/2 + T/(2V) * (k + 1)]  * constant)\n",
      " |          If data is for a single object, return 1-dimensional array of predictions with size depends on prediction type,\n",
      " |          otherwise return 2-dimensional numpy.ndarray with shape (number_of_objects x size depends on prediction type);\n",
      " |          Returned predictions depends on prediction type:\n",
      " |          If loss-function was RMSEWithUncertainty:\n",
      " |              - 'VirtEnsembles': [mean0, var0, mean1, var1, ..., vark-1].\n",
      " |              - 'TotalUncertainty': [mean_predict, KnowledgeUnc, DataUnc].\n",
      " |          otherwise for regression:\n",
      " |              - 'VirtEnsembles':  [mean0, mean1, ...].\n",
      " |              - 'TotalUncertainty': [mean_predicts, KnowledgeUnc].\n",
      " |          otherwise for binary classification:\n",
      " |              - 'VirtEnsembles':  [ApproxRawFormulaVal0, ApproxRawFormulaVal1, ..., ApproxRawFormulaValk-1].\n",
      " |              - 'TotalUncertainty':  [DataUnc, TotalUnc].\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from CatBoost:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |  \n",
      " |  __deepcopy__(self, _)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  copy(self)\n",
      " |  \n",
      " |  get_best_iteration(self)\n",
      " |  \n",
      " |  get_best_score(self)\n",
      " |  \n",
      " |  get_evals_result(self)\n",
      " |  \n",
      " |  get_leaf_values(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_values : 1d-array of leaf values for all trees.\n",
      " |      Value corresponding to j-th leaf of i-th tree is at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  get_leaf_weights(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_weights : 1d-array of leaf weights for all trees.\n",
      " |      Weight of j-th leaf of i-th tree is at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  get_metadata(self)\n",
      " |  \n",
      " |  get_n_features_in(self)\n",
      " |  \n",
      " |  get_scale_and_bias(self)\n",
      " |  \n",
      " |  get_test_eval(self)\n",
      " |  \n",
      " |  get_test_evals(self)\n",
      " |  \n",
      " |  get_tree_leaf_counts(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tree_leaf_counts : 1d-array of numpy.uint32 of size tree_count_.\n",
      " |      tree_leaf_counts[i] equals to the number of leafs in i-th tree of the ensemble.\n",
      " |  \n",
      " |  is_fitted(self)\n",
      " |  \n",
      " |  set_feature_names(self, feature_names)\n",
      " |      Sets feature names equal to feature_names\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      feature_names: 1-d array of strings with new feature names in the same order as in pool\n",
      " |  \n",
      " |  set_leaf_values(self, new_leaf_values)\n",
      " |      Sets values at tree leafs of ensemble equal to new_leaf_values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_leaf_values : 1d-array with new leaf values for all trees.\n",
      " |      It's size should be equal to sum(get_tree_leaf_counts()).\n",
      " |      Value corresponding to j-th leaf of i-th tree should be at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  set_scale_and_bias(self, scale, bias)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from _CatBoostBase:\n",
      " |  \n",
      " |  best_iteration_\n",
      " |  \n",
      " |  best_score_\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  evals_result_\n",
      " |  \n",
      " |  feature_names_\n",
      " |  \n",
      " |  learning_rate_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  random_seed_\n",
      " |  \n",
      " |  tree_count_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CatBoostClassifier)\n",
    "CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def plot_hist_ee(df, bins=1_000, xlim=None):\n",
    "    df_X = df.copy().drop(['userId', 'lastFirstName', 'home_ownership_class'], axis=1)\n",
    "    df_names = df.copy()[['userId', 'lastFirstName']]\n",
    "    n_samples = df.shape[0]\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaled_data = scaler.fit_transform(df_X)\n",
    "    scaled_data = df_X\n",
    "\n",
    "    model = EllipticEnvelope(random_state=0)\n",
    "    model.fit(scaled_data)\n",
    "    \n",
    "    model_scores = model.score_samples(scaled_data)\n",
    "    \n",
    "    plt.hist(model_scores, bins=bins)\n",
    "    plt.xlabel('Elliptic Envelope scores')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Elliptic Envelope score histogram')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim, 0)\n",
    "    plt.show()\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def plot_ee(df, scores, threshold):\n",
    "    model_scores = scores\n",
    "\n",
    "    outlier_mask = model_scores < threshold\n",
    "    plt.scatter(df.iloc[outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='purple',\n",
    "                label='Predicted Outliers')\n",
    "    plt.scatter(df.iloc[~outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[~outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='yellow',\n",
    "                label='Predicted Inliers')\n",
    "    plt.xlabel('Basic Monthly Salary')\n",
    "    plt.ylabel('Monthly Family Income')\n",
    "    plt.title(f'Elliptic Envelope, Threshold = {threshold}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2['pred_outlier'] = (model_scores.reshape(-1, 1) < threshold)\n",
    "\n",
    "    print('Number of predicted outliers:',\n",
    "          df2[df2['pred_outlier'] == True].shape[0])\n",
    "    display(df2[df2['pred_outlier'] == True])\n",
    "\n",
    "def plot_hist_gmm(df, n_components, covariance_type='full', bins=1_000, xlim=None):\n",
    "    df_X = df.copy().drop(['userId', 'lastFirstName', 'home_ownership_class'], axis=1)\n",
    "    df_names = df.copy()[['userId', 'lastFirstName']]\n",
    "    n_samples = df.shape[0]\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaled_data = scaler.fit_transform(df_X)\n",
    "    scaled_data = df_X\n",
    "\n",
    "    model = GaussianMixture(n_components=n_components,\n",
    "                            covariance_type=covariance_type,\n",
    "                            random_state=0)\n",
    "    model.fit(scaled_data)\n",
    "    \n",
    "    model_scores = model.score_samples(scaled_data)\n",
    "    \n",
    "    plt.hist(model_scores, bins=bins)\n",
    "    plt.xlabel(f'{n_components}-component Gaussian Mixture Model scores')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'{n_components}-component Gaussian Mixture Model score histogram')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim, 0)\n",
    "    plt.show()\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def plot_gmm(df, n_components, scores, threshold):\n",
    "    model_scores = scores\n",
    "\n",
    "    outlier_mask = model_scores < threshold\n",
    "    plt.scatter(df.iloc[outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='purple',\n",
    "                label='Predicted Outliers')\n",
    "    plt.scatter(df.iloc[~outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[~outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='yellow',\n",
    "                label='Predicted Inliers')\n",
    "    plt.xlabel('Basic Monthly Salary')\n",
    "    plt.ylabel('Monthly Family Income')\n",
    "    plt.title(f'{n_components}-component Gaussian Mixture Model, Threshold = {threshold}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2['pred_outlier'] = (model_scores.reshape(-1, 1) < threshold)\n",
    "\n",
    "    print('Number of predicted outliers:',\n",
    "          df2[df2['pred_outlier'] == True].shape[0])\n",
    "    display(df2[df2['pred_outlier'] == True])\n",
    "\n",
    "def plot_hist_lof(df, n_neighbors=20, bins=1_000, xlim=None):\n",
    "    df_X = df.copy().drop(['userId', 'lastFirstName', 'home_ownership_class'], axis=1)\n",
    "    df_names = df.copy()[['userId', 'lastFirstName']]\n",
    "    n_samples = df.shape[0]\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaled_data = scaler.fit_transform(df_X)\n",
    "    scaled_data = df_X\n",
    "\n",
    "    model = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
    "    model.fit(scaled_data)\n",
    "    \n",
    "#     model_scores = model.score_samples(scaled_data)\n",
    "    model_scores = model.negative_outlier_factor_\n",
    "    \n",
    "    plt.hist(model_scores, bins=bins)\n",
    "    plt.xlabel(f'{n_neighbors}-neighbor Local Outlier Factor (LOF) scores')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'{n_neighbors}-neighbor Local Outlier Factor (LOF) score histogram')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim, 0)\n",
    "    plt.show()\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def plot_lof(df, n_neighbors, scores, threshold):\n",
    "    model_scores = scores\n",
    "\n",
    "    outlier_mask = model_scores < threshold\n",
    "    plt.scatter(df.iloc[outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='purple',\n",
    "                label='Predicted Outliers')\n",
    "    plt.scatter(df.iloc[~outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[~outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='yellow',\n",
    "                label='Predicted Inliers')\n",
    "    plt.xlabel('Basic Monthly Salary')\n",
    "    plt.ylabel('Monthly Family Income')\n",
    "    plt.title(f'{n_neighbors}-neighbor Local Outlier Factor (LOF), Threshold = {threshold}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2['pred_outlier'] = (model_scores.reshape(-1, 1) < threshold)\n",
    "\n",
    "    print('Number of predicted outliers:',\n",
    "          df2[df2['pred_outlier'] == True].shape[0])\n",
    "    display(df2[df2['pred_outlier'] == True])\n",
    "\n",
    "def plot_hist_ocsvm(df, kernel='rbf', bins=1_000, xlim=None):\n",
    "    df_X = df.copy().drop(['userId', 'lastFirstName', 'home_ownership_class'], axis=1)\n",
    "    df_names = df.copy()[['userId', 'lastFirstName']]\n",
    "    n_samples = df.shape[0]\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaled_data = scaler.fit_transform(df_X)\n",
    "    scaled_data = df_X\n",
    "\n",
    "    model = OneClassSVM(kernel=kernel, degree=4)\n",
    "    model.fit(scaled_data)\n",
    "    \n",
    "    model_scores = model.score_samples(scaled_data)\n",
    "    \n",
    "    plt.hist(model_scores, bins=bins)\n",
    "    plt.xlabel(f'{kernel}-kernel One-Class SVM (OCSVM) scores')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'{kernel}-kernel One-Class SVM (OCSVM) score histogram')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim, 0)\n",
    "    plt.show()\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def plot_hist_ocsvm2(df, kernel='rbf', bins=1_000, xlim=None):\n",
    "    df_X = df.copy().drop(['userId', 'lastFirstName', 'ageing_class'], axis=1)\n",
    "    df_names = df.copy()[['userId', 'lastFirstName']]\n",
    "    n_samples = df.shape[0]\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaled_data = scaler.fit_transform(df_X)\n",
    "    scaled_data = df_X\n",
    "\n",
    "    model = OneClassSVM(kernel=kernel, degree=4)\n",
    "    model.fit(scaled_data)\n",
    "    \n",
    "    model_scores = model.score_samples(scaled_data)\n",
    "    \n",
    "    plt.hist(model_scores, bins=bins)\n",
    "    plt.xlabel(f'{kernel}-kernel One-Class SVM (OCSVM) scores')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'{kernel}-kernel One-Class SVM (OCSVM) score histogram')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim, 0)\n",
    "    plt.show()\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def plot_ocsvm(df, kernel, scores, threshold):\n",
    "    model_scores = scores\n",
    "\n",
    "    outlier_mask = model_scores < threshold\n",
    "    plt.scatter(df.iloc[outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='purple',\n",
    "                label='Predicted Outliers')\n",
    "    plt.scatter(df.iloc[~outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[~outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='yellow',\n",
    "                label='Predicted Inliers')\n",
    "    plt.xlabel('Basic Monthly Salary')\n",
    "    plt.ylabel('Monthly Family Income')\n",
    "    plt.title(f'{kernel}-kernel One-Class SVM (OCSVM), Threshold = {threshold}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2['pred_outlier'] = (model_scores.reshape(-1, 1) < threshold)\n",
    "\n",
    "    print('Number of predicted outliers:',\n",
    "          df2[df2['pred_outlier'] == True].shape[0])\n",
    "    display(df2[df2['pred_outlier'] == True])\n",
    "\n",
    "    return list(df2[df2['pred_outlier'] == True].index)\n",
    "\n",
    "def plot_hist_if(df, n_estimators=100, bins=1_000, xlim=None):\n",
    "    df_X = df.copy().drop(['userId', 'lastFirstName', 'home_ownership_class'], axis=1)\n",
    "    df_names = df.copy()[['userId', 'lastFirstName']]\n",
    "    n_samples = df.shape[0]\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaled_data = scaler.fit_transform(df_X)\n",
    "    scaled_data = df_X\n",
    "\n",
    "    model = IsolationForest(n_estimators=n_estimators, random_state=0)\n",
    "    model.fit(scaled_data)\n",
    "    \n",
    "    model_scores = model.score_samples(scaled_data)\n",
    "    \n",
    "    plt.hist(model_scores, bins=bins)\n",
    "    plt.xlabel(f'{n_estimators}-estimator Isolation Forest (IF) scores')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'{n_estimators}-estimator Isolation Forest (IF) score histogram')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim, 0)\n",
    "    plt.show()\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def plot_if(df, n_estimators, scores, threshold):\n",
    "    model_scores = scores\n",
    "\n",
    "    outlier_mask = model_scores < threshold\n",
    "    plt.scatter(df.iloc[outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='purple',\n",
    "                label='Predicted Outliers')\n",
    "    plt.scatter(df.iloc[~outlier_mask, df.columns.get_loc('basicMonthlySalary')],\n",
    "                df.iloc[~outlier_mask, df.columns.get_loc('monthlyFamilyIncome')], c='yellow',\n",
    "                label='Predicted Inliers')\n",
    "    plt.xlabel('Basic Monthly Salary')\n",
    "    plt.ylabel('Monthly Family Income')\n",
    "    plt.title(f'{n_estimators}-estimator Isolation Forest (IF), Threshold = {threshold}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2['pred_outlier'] = (model_scores.reshape(-1, 1) < threshold)\n",
    "\n",
    "    print('Number of predicted outliers:',\n",
    "          df2[df2['pred_outlier'] == True].shape[0])\n",
    "    display(df2[df2['pred_outlier'] == True])\n",
    "\n",
    "    return list(df2[df2['pred_outlier'] == True].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>lastFirstName</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>province</th>\n",
       "      <th>job</th>\n",
       "      <th>basicMonthlySalary</th>\n",
       "      <th>preferredNetDisposableIncomeId</th>\n",
       "      <th>workingFamilyCount</th>\n",
       "      <th>residentsCount</th>\n",
       "      <th>monthlyFamilyIncome</th>\n",
       "      <th>food</th>\n",
       "      <th>hygiene</th>\n",
       "      <th>houseCleaning</th>\n",
       "      <th>fare</th>\n",
       "      <th>parking</th>\n",
       "      <th>gasoline</th>\n",
       "      <th>tuition</th>\n",
       "      <th>allowance</th>\n",
       "      <th>uniform</th>\n",
       "      <th>otherEducation</th>\n",
       "      <th>emergency</th>\n",
       "      <th>medicine</th>\n",
       "      <th>water</th>\n",
       "      <th>electricity</th>\n",
       "      <th>rent</th>\n",
       "      <th>repair</th>\n",
       "      <th>cinema</th>\n",
       "      <th>dineOut</th>\n",
       "      <th>leisure</th>\n",
       "      <th>personalCare</th>\n",
       "      <th>clothing</th>\n",
       "      <th>mobileLoad</th>\n",
       "      <th>internet</th>\n",
       "      <th>vehicleLoan</th>\n",
       "      <th>informalLenders</th>\n",
       "      <th>companyLoan</th>\n",
       "      <th>privateLoans</th>\n",
       "      <th>governmentLoans</th>\n",
       "      <th>smoking</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>gambling</th>\n",
       "      <th>smallLottery</th>\n",
       "      <th>otherVices</th>\n",
       "      <th>savings</th>\n",
       "      <th>OSDate</th>\n",
       "      <th>OSDate - dateEntry</th>\n",
       "      <th>HDMFDate</th>\n",
       "      <th>HDMFDate - dateEntry</th>\n",
       "      <th>loanGroup</th>\n",
       "      <th>loanVal</th>\n",
       "      <th>loanPersonal</th>\n",
       "      <th>payInsurance</th>\n",
       "      <th>loanSSS</th>\n",
       "      <th>loanPagIbig</th>\n",
       "      <th>loanOthers</th>\n",
       "      <th>loanGSIS</th>\n",
       "      <th>payFamilySupport</th>\n",
       "      <th>houseHasFreelancer</th>\n",
       "      <th>houseHasBusiness</th>\n",
       "      <th>houseHasGovtEmployee</th>\n",
       "      <th>houseHasOFW</th>\n",
       "      <th>houseHasPrivateEmployee</th>\n",
       "      <th>houseHasPensioner</th>\n",
       "      <th>houseOnlyFamily</th>\n",
       "      <th>houseExtendedFamily</th>\n",
       "      <th>home_ownership_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370</td>\n",
       "      <td>IBALI, HOWARD</td>\n",
       "      <td>24</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>19000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>40000</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>18/10/2022</td>\n",
       "      <td>179.0</td>\n",
       "      <td>01/03/2023</td>\n",
       "      <td>313.0</td>\n",
       "      <td>SHDG</td>\n",
       "      <td>652000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1025</td>\n",
       "      <td>PATALINGHOG, KIMBERLY</td>\n",
       "      <td>26</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>5000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1105</td>\n",
       "      <td>TEMILLOSO, DENNIS</td>\n",
       "      <td>40</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30000</td>\n",
       "      <td>3000</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1719</td>\n",
       "      <td>OSCARES, ELMER</td>\n",
       "      <td>32</td>\n",
       "      <td>MALE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>MACHINE OPERATOR</td>\n",
       "      <td>21200</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12000</td>\n",
       "      <td>2000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/11/2022</td>\n",
       "      <td>228.0</td>\n",
       "      <td>LE</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2081</td>\n",
       "      <td>LEGASPI, MANNY</td>\n",
       "      <td>39</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>CLERICAL SUPPORT</td>\n",
       "      <td>19800</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>5000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>500</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>12850</td>\n",
       "      <td>LIPANGO, ARVIN</td>\n",
       "      <td>34</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>ASSOCIATE PROFESSIONAL</td>\n",
       "      <td>19000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>1500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>12852</td>\n",
       "      <td>TEJADA, JERIC</td>\n",
       "      <td>27</td>\n",
       "      <td>MALE</td>\n",
       "      <td>LAGUNA</td>\n",
       "      <td>CRAFT AND TRADE</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>5000</td>\n",
       "      <td>500</td>\n",
       "      <td>400</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>12853</td>\n",
       "      <td>RAMOS, RHEALYN</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CAVITE</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>13962</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>40000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>1000</td>\n",
       "      <td>150</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>12854</td>\n",
       "      <td>BURGOS, LIEZEL</td>\n",
       "      <td>48</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ILOILO</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>51000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>51000</td>\n",
       "      <td>5000</td>\n",
       "      <td>3000</td>\n",
       "      <td>1500</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>12857</td>\n",
       "      <td>SEERES, JENNY MAE</td>\n",
       "      <td>24</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>98800</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>143800</td>\n",
       "      <td>7000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>1650</td>\n",
       "      <td>17000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows  67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId          lastFirstName  age  gender      province  \\\n",
       "0        370          IBALI, HOWARD   24    MALE  METRO MANILA   \n",
       "1       1025  PATALINGHOG, KIMBERLY   26  FEMALE  METRO MANILA   \n",
       "2       1105      TEMILLOSO, DENNIS   40    MALE  METRO MANILA   \n",
       "3       1719         OSCARES, ELMER   32    MALE       UNKNOWN   \n",
       "4       2081         LEGASPI, MANNY   39    MALE  METRO MANILA   \n",
       "...      ...                    ...  ...     ...           ...   \n",
       "1065   12850         LIPANGO, ARVIN   34    MALE  METRO MANILA   \n",
       "1066   12852          TEJADA, JERIC   27    MALE        LAGUNA   \n",
       "1067   12853         RAMOS, RHEALYN   27  FEMALE        CAVITE   \n",
       "1068   12854         BURGOS, LIEZEL   48  FEMALE        ILOILO   \n",
       "1069   12857     SEERES, JENNY MAE   24  FEMALE  METRO MANILA   \n",
       "\n",
       "                         job  basicMonthlySalary  \\\n",
       "0          SERVICE AND SALES               19000   \n",
       "1          SERVICE AND SALES               15000   \n",
       "2          SERVICE AND SALES               20000   \n",
       "3           MACHINE OPERATOR               21200   \n",
       "4           CLERICAL SUPPORT               19800   \n",
       "...                      ...                 ...   \n",
       "1065  ASSOCIATE PROFESSIONAL               19000   \n",
       "1066         CRAFT AND TRADE                  20   \n",
       "1067       SERVICE AND SALES               13962   \n",
       "1068       SERVICE AND SALES               51000   \n",
       "1069       SERVICE AND SALES               98800   \n",
       "\n",
       "      preferredNetDisposableIncomeId  workingFamilyCount  residentsCount  \\\n",
       "0                                  2                   3               3   \n",
       "1                                  3                   2               4   \n",
       "2                                  2                   0               3   \n",
       "3                                  2                   0               5   \n",
       "4                                  2                   0               0   \n",
       "...                              ...                 ...             ...   \n",
       "1065                               2                   2               4   \n",
       "1066                               2                   1               1   \n",
       "1067                               1                   2               4   \n",
       "1068                               2                   0               5   \n",
       "1069                               3                   3               3   \n",
       "\n",
       "      monthlyFamilyIncome  food  hygiene  houseCleaning  fare  parking  \\\n",
       "0                   40000  1000      500            200   200        0   \n",
       "1                   30000  5000     3000           2000  2000        0   \n",
       "2                   30000  3000      500            300   200       50   \n",
       "3                   12000  2000      500            200   392        0   \n",
       "4                   25000  5000     2000           1000  1500        0   \n",
       "...                   ...   ...      ...            ...   ...      ...   \n",
       "1065                19000  5000     1000           1000     1        1   \n",
       "1066                20000  5000      500            400   280        0   \n",
       "1067                40000     4        2              1     3        1   \n",
       "1068                51000  5000     3000           1500  2000        0   \n",
       "1069               143800  7000     3000           2000     0        0   \n",
       "\n",
       "      gasoline  tuition  allowance  uniform  otherEducation  emergency  \\\n",
       "0            0        0         50        0               0        500   \n",
       "1            0        0          0        0               0       2000   \n",
       "2           50      500        100      100              50        500   \n",
       "3            0        0          0        0               0        100   \n",
       "4            0     1000        500     1500               0          0   \n",
       "...        ...      ...        ...      ...             ...        ...   \n",
       "1065         1     1000        500        1            1000       1000   \n",
       "1066         0        0          0        0               0          0   \n",
       "1067         1        0          0        0               0      30000   \n",
       "1068         0    15000       9000        0               0       1000   \n",
       "1069      6000        0          0        0               0       5000   \n",
       "\n",
       "      medicine  water  electricity  rent  repair  cinema  dineOut  leisure  \\\n",
       "0          450      0            0     0       0       0        0        0   \n",
       "1            0    200          200  1000     500       0        0        0   \n",
       "2          100    200          500     0     200       0      100      100   \n",
       "3            0    200          200  3000       0       0        0        0   \n",
       "4         1000    300         1900     0    1000       0     1000     1000   \n",
       "...        ...    ...          ...   ...     ...     ...      ...      ...   \n",
       "1065       500    200         1500  5000    1000       1        1        1   \n",
       "1066         0      0            0     0       0       0        0        0   \n",
       "1067      1000    150         1000  2000     500       0     1000        0   \n",
       "1068      1000    300          800     0       0       0      500      500   \n",
       "1069      1000      0            0  6000       0     500     2000     1000   \n",
       "\n",
       "      personalCare  clothing  mobileLoad  internet  vehicleLoan  \\\n",
       "0                0         0          50         0            0   \n",
       "1                0         0           0         0            0   \n",
       "2              100       200         200       200            0   \n",
       "3              100       200         400         0            0   \n",
       "4             1500      1500         500      1600            0   \n",
       "...            ...       ...         ...       ...          ...   \n",
       "1065             1         1         500         1            1   \n",
       "1066             0         0         200         0            0   \n",
       "1067             0         0         300         0            0   \n",
       "1068           300       500         300       800            0   \n",
       "1069          1000      1000         200      1650        17000   \n",
       "\n",
       "      informalLenders  companyLoan  privateLoans  governmentLoans  smoking  \\\n",
       "0                   0            0             0                0        0   \n",
       "1                   0            0             0                0        0   \n",
       "2                   0            0             0                0        0   \n",
       "3                   0            0             0              876        0   \n",
       "4                   0            0             0                0        0   \n",
       "...               ...          ...           ...              ...      ...   \n",
       "1065                1            1             1                1        1   \n",
       "1066                0            0             0             1672        0   \n",
       "1067                0          500             0                0        0   \n",
       "1068                0            0             0                0        0   \n",
       "1069                0            0             0                0        0   \n",
       "\n",
       "      alcohol  gambling  smallLottery  otherVices  savings      OSDate  \\\n",
       "0           0         0             0           0     2000  18/10/2022   \n",
       "1           0         0             0           0     2000       FALSE   \n",
       "2           0         0             0           0     1000       FALSE   \n",
       "3           0         0             0           0      500       FALSE   \n",
       "4           0         0             0           0    10000       FALSE   \n",
       "...       ...       ...           ...         ...      ...         ...   \n",
       "1065        1         1             1           1     2000       FALSE   \n",
       "1066        0         0             0           0      500       FALSE   \n",
       "1067        0         0             0           0     2000       FALSE   \n",
       "1068        0         0             0           0     1000       FALSE   \n",
       "1069        0         0             0           0    10000       FALSE   \n",
       "\n",
       "      OSDate - dateEntry    HDMFDate  HDMFDate - dateEntry loanGroup loanVal  \\\n",
       "0                  179.0  01/03/2023                 313.0      SHDG  652000   \n",
       "1                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "2                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "3                    NaN  18/11/2022                 228.0        LE  800000   \n",
       "4                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "...                  ...         ...                   ...       ...     ...   \n",
       "1065                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1066                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1067                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1068                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1069                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "\n",
       "      loanPersonal  payInsurance  loanSSS  loanPagIbig  loanOthers  loanGSIS  \\\n",
       "0                0             0        0            0           0         0   \n",
       "1                0             0        1            1           0         0   \n",
       "2                0             0        0            0           0         0   \n",
       "3                0             0        1            0           0         0   \n",
       "4                0             0        0            0           0         0   \n",
       "...            ...           ...      ...          ...         ...       ...   \n",
       "1065             1             0        0            0           0         0   \n",
       "1066             0             0        1            1           0         0   \n",
       "1067             0             0        0            0           0         0   \n",
       "1068             0             0        0            0           0         0   \n",
       "1069             0             0        0            0           0         0   \n",
       "\n",
       "      payFamilySupport  houseHasFreelancer  houseHasBusiness  \\\n",
       "0                    0                   0                 0   \n",
       "1                    1                   0                 0   \n",
       "2                    0                   1                 0   \n",
       "3                    0                   0                 0   \n",
       "4                    0                   0                 0   \n",
       "...                ...                 ...               ...   \n",
       "1065                 0                   0                 0   \n",
       "1066                 0                   0                 0   \n",
       "1067                 0                   0                 0   \n",
       "1068                 0                   0                 0   \n",
       "1069                 0                   1                 0   \n",
       "\n",
       "      houseHasGovtEmployee  houseHasOFW  houseHasPrivateEmployee  \\\n",
       "0                        0            1                        1   \n",
       "1                        0            0                        1   \n",
       "2                        0            0                        1   \n",
       "3                        0            0                        1   \n",
       "4                        0            0                        0   \n",
       "...                    ...          ...                      ...   \n",
       "1065                     0            0                        1   \n",
       "1066                     0            0                        1   \n",
       "1067                     0            0                        1   \n",
       "1068                     0            1                        0   \n",
       "1069                     0            1                        1   \n",
       "\n",
       "      houseHasPensioner  houseOnlyFamily  houseExtendedFamily  \\\n",
       "0                     0                0                    1   \n",
       "1                     0                1                    0   \n",
       "2                     0                0                    1   \n",
       "3                     0                1                    0   \n",
       "4                     0                0                    0   \n",
       "...                 ...              ...                  ...   \n",
       "1065                  0                1                    0   \n",
       "1066                  0                0                    0   \n",
       "1067                  0                1                    0   \n",
       "1068                  0                0                    0   \n",
       "1069                  0                1                    0   \n",
       "\n",
       "      home_ownership_class  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  \n",
       "...                    ...  \n",
       "1065                     1  \n",
       "1066                     1  \n",
       "1067                     1  \n",
       "1068                     1  \n",
       "1069                     1  \n",
       "\n",
       "[1070 rows x 67 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "dataset = pd.read_csv('data/df_merged_no_nans_delta_T.csv')\n",
    "# dataset = dataset.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Creating 'daysFromDateEntryStart'\n",
    "# dataset['dateEntry'] = pd.to_datetime(dataset['dateEntry'], format='%Y-%m-%d')\n",
    "# dateEntryStart = pd.to_datetime('2022-03-28', format='%Y-%m-%d')\n",
    "# dataset['daysFromDateEntryStart'] = (dataset['dateEntry'] - dateEntryStart).dt.days\n",
    "\n",
    "# Dropping irrelevant columns\n",
    "cols_to_drop = [\n",
    "    'id', 'fullName', 'firstName', 'lastName', 'address', 'occupation', 'dateEntry'\n",
    "]\n",
    "dataset = dataset.drop(cols_to_drop, axis=1)\n",
    "\n",
    "boolean_columns = [col for col in dataset.columns if dataset[col].dtype == bool]\n",
    "dataset[boolean_columns] = dataset[boolean_columns].apply(lambda x: x.astype('int'))\n",
    "\n",
    "columns_to_move = ['lastFirstName', 'age', 'gender', 'province', 'job']\n",
    "columns_remaining = [col for col in dataset.columns if col not in columns_to_move]\n",
    "\n",
    "new_column_order = columns_to_move + columns_remaining\n",
    "dataset = dataset[new_column_order]\n",
    "dataset.insert(0, 'userId', dataset.pop('userId'))\n",
    "\n",
    "def map_ageing_class(row):\n",
    "    found_in_hdmf = row['foundInHDMF']\n",
    "    home_ownership_class = row['home_ownership_class']\n",
    "\n",
    "    if home_ownership_class == 0:\n",
    "        return np.nan\n",
    "    elif found_in_hdmf in [' Current', 'FP', '01 mos', '02 mos', '03 mos']:\n",
    "        return 0\n",
    "    elif found_in_hdmf in ['04 mos', '05 mos']:\n",
    "        return 1\n",
    "\n",
    "# One-hot encoding of categorical columns\n",
    "# dataset = pd.get_dummies(dataset, columns=['gender'], prefix='gender', drop_first='True')\n",
    "# dataset = pd.get_dummies(dataset, columns=['province'], prefix='province')\n",
    "# dataset = pd.get_dummies(dataset, columns=['job'], prefix='job')\n",
    "\n",
    "dataset['home_ownership_class'] = ((dataset['foundInOS'] != 'False') |\n",
    "                                   (dataset['foundInHDMF'] != 'False')).astype('int')\n",
    "\n",
    "# dataset['ageing_class'] = dataset['home_ownership_class'].astype('int64')\n",
    "# dataset['ageing_class'] = dataset.apply(map_ageing_class, axis=1)\n",
    "\n",
    "cols_to_drop = ['foundInOS', 'foundInHDMF']\n",
    "dataset = dataset.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# Selecting only Cluster 1 from the dataset\n",
    "# dataset = dataset[dataset['cluster'] == 1].drop(columns=['cluster'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>lastFirstName</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>province</th>\n",
       "      <th>job</th>\n",
       "      <th>basicMonthlySalary</th>\n",
       "      <th>preferredNetDisposableIncomeId</th>\n",
       "      <th>workingFamilyCount</th>\n",
       "      <th>residentsCount</th>\n",
       "      <th>monthlyFamilyIncome</th>\n",
       "      <th>food</th>\n",
       "      <th>hygiene</th>\n",
       "      <th>houseCleaning</th>\n",
       "      <th>fare</th>\n",
       "      <th>parking</th>\n",
       "      <th>gasoline</th>\n",
       "      <th>tuition</th>\n",
       "      <th>allowance</th>\n",
       "      <th>uniform</th>\n",
       "      <th>otherEducation</th>\n",
       "      <th>emergency</th>\n",
       "      <th>medicine</th>\n",
       "      <th>water</th>\n",
       "      <th>electricity</th>\n",
       "      <th>rent</th>\n",
       "      <th>repair</th>\n",
       "      <th>cinema</th>\n",
       "      <th>dineOut</th>\n",
       "      <th>leisure</th>\n",
       "      <th>personalCare</th>\n",
       "      <th>clothing</th>\n",
       "      <th>mobileLoad</th>\n",
       "      <th>internet</th>\n",
       "      <th>vehicleLoan</th>\n",
       "      <th>informalLenders</th>\n",
       "      <th>companyLoan</th>\n",
       "      <th>privateLoans</th>\n",
       "      <th>governmentLoans</th>\n",
       "      <th>smoking</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>gambling</th>\n",
       "      <th>smallLottery</th>\n",
       "      <th>otherVices</th>\n",
       "      <th>savings</th>\n",
       "      <th>OSDate</th>\n",
       "      <th>OSDate - dateEntry</th>\n",
       "      <th>HDMFDate</th>\n",
       "      <th>HDMFDate - dateEntry</th>\n",
       "      <th>loanGroup</th>\n",
       "      <th>loanVal</th>\n",
       "      <th>loanPersonal</th>\n",
       "      <th>payInsurance</th>\n",
       "      <th>loanSSS</th>\n",
       "      <th>loanPagIbig</th>\n",
       "      <th>loanOthers</th>\n",
       "      <th>loanGSIS</th>\n",
       "      <th>payFamilySupport</th>\n",
       "      <th>houseHasFreelancer</th>\n",
       "      <th>houseHasBusiness</th>\n",
       "      <th>houseHasGovtEmployee</th>\n",
       "      <th>houseHasOFW</th>\n",
       "      <th>houseHasPrivateEmployee</th>\n",
       "      <th>houseHasPensioner</th>\n",
       "      <th>houseOnlyFamily</th>\n",
       "      <th>houseExtendedFamily</th>\n",
       "      <th>home_ownership_class</th>\n",
       "      <th>monthlyUtilityBills</th>\n",
       "      <th>monthlyVices</th>\n",
       "      <th>monthlyExpenses</th>\n",
       "      <th>monthlySoloNetIncome</th>\n",
       "      <th>positiveMonthlySoloNetIncome</th>\n",
       "      <th>monthlyFamilyNetIncome</th>\n",
       "      <th>positiveMonthlyFamilyNetIncome</th>\n",
       "      <th>monthlySoloNetIncomeWithSavings</th>\n",
       "      <th>positiveMonthlySoloNetIncomeWithSavings</th>\n",
       "      <th>monthlyFamilyNetIncomeWithSavings</th>\n",
       "      <th>positiveMonthlyFamilyNetIncomeWithSavings</th>\n",
       "      <th>monthlyFamilyIncome - basicMonthlySalary</th>\n",
       "      <th>positive monthlyFamilyIncome - basicMonthlySalary</th>\n",
       "      <th>basicMonthlySalary - monthlyExpenses</th>\n",
       "      <th>positive basicMonthlySalary - monthlyExpenses</th>\n",
       "      <th>monthlyFamilyIncome - monthlyExpenses</th>\n",
       "      <th>positive monthlyFamilyIncome - monthlyExpenses</th>\n",
       "      <th>basicMonthlySalary / monthlyFamilyIncome</th>\n",
       "      <th>monthlyExpenses / basicMonthlySalary</th>\n",
       "      <th>monthlyExpenses / monthlyFamilyIncome</th>\n",
       "      <th>monthlyVices / basicMonthlySalary</th>\n",
       "      <th>monthlyVices / monthlyFamilyIncome</th>\n",
       "      <th>basicMonthlySalary / workingFamilyCount</th>\n",
       "      <th>basicMonthlySalary / residentsCount</th>\n",
       "      <th>monthlyFamilyIncome / workingFamilyCount</th>\n",
       "      <th>monthlyFamilyIncome / residentsCount</th>\n",
       "      <th>monthlyExpenses / workingFamilyCount</th>\n",
       "      <th>monthlyExpenses / residentsCount</th>\n",
       "      <th>monthlyUtilityBills / workingFamilyCount</th>\n",
       "      <th>monthlyUtilityBills / residentsCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370</td>\n",
       "      <td>IBALI, HOWARD</td>\n",
       "      <td>24</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>19000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>40000</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>18/10/2022</td>\n",
       "      <td>179.0</td>\n",
       "      <td>01/03/2023</td>\n",
       "      <td>313.0</td>\n",
       "      <td>SHDG</td>\n",
       "      <td>652000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2950</td>\n",
       "      <td>16050</td>\n",
       "      <td>1</td>\n",
       "      <td>37050</td>\n",
       "      <td>1</td>\n",
       "      <td>18050</td>\n",
       "      <td>1</td>\n",
       "      <td>39050</td>\n",
       "      <td>1</td>\n",
       "      <td>21000</td>\n",
       "      <td>1</td>\n",
       "      <td>16050</td>\n",
       "      <td>1</td>\n",
       "      <td>37050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.155263</td>\n",
       "      <td>0.073750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6333.333333</td>\n",
       "      <td>6333.333333</td>\n",
       "      <td>13333.333333</td>\n",
       "      <td>13333.333333</td>\n",
       "      <td>983.333333</td>\n",
       "      <td>983.333333</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1025</td>\n",
       "      <td>PATALINGHOG, KIMBERLY</td>\n",
       "      <td>26</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>5000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>15900</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>14100</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>16100</td>\n",
       "      <td>1</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>14100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7950.000000</td>\n",
       "      <td>3975.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>350.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1105</td>\n",
       "      <td>TEMILLOSO, DENNIS</td>\n",
       "      <td>40</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30000</td>\n",
       "      <td>3000</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "      <td>7250</td>\n",
       "      <td>12750</td>\n",
       "      <td>1</td>\n",
       "      <td>22750</td>\n",
       "      <td>1</td>\n",
       "      <td>13750</td>\n",
       "      <td>1</td>\n",
       "      <td>23750</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>12750</td>\n",
       "      <td>1</td>\n",
       "      <td>22750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6666.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2416.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1719</td>\n",
       "      <td>OSCARES, ELMER</td>\n",
       "      <td>32</td>\n",
       "      <td>MALE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>MACHINE OPERATOR</td>\n",
       "      <td>21200</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12000</td>\n",
       "      <td>2000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/11/2022</td>\n",
       "      <td>228.0</td>\n",
       "      <td>LE</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3800</td>\n",
       "      <td>0</td>\n",
       "      <td>8168</td>\n",
       "      <td>13032</td>\n",
       "      <td>1</td>\n",
       "      <td>3832</td>\n",
       "      <td>1</td>\n",
       "      <td>13532</td>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>1</td>\n",
       "      <td>-9200</td>\n",
       "      <td>0</td>\n",
       "      <td>13032</td>\n",
       "      <td>1</td>\n",
       "      <td>3832</td>\n",
       "      <td>1</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.385283</td>\n",
       "      <td>0.680667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1633.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2081</td>\n",
       "      <td>LEGASPI, MANNY</td>\n",
       "      <td>39</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>CLERICAL SUPPORT</td>\n",
       "      <td>19800</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>5000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>500</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4300</td>\n",
       "      <td>0</td>\n",
       "      <td>23800</td>\n",
       "      <td>-4000</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>11200</td>\n",
       "      <td>1</td>\n",
       "      <td>5200</td>\n",
       "      <td>1</td>\n",
       "      <td>-4000</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>1.202020</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>12850</td>\n",
       "      <td>LIPANGO, ARVIN</td>\n",
       "      <td>34</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>ASSOCIATE PROFESSIONAL</td>\n",
       "      <td>19000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>1500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7201</td>\n",
       "      <td>5</td>\n",
       "      <td>19220</td>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "      <td>1780</td>\n",
       "      <td>1</td>\n",
       "      <td>1780</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.011579</td>\n",
       "      <td>1.011579</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>9500.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "      <td>9500.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>4805.000000</td>\n",
       "      <td>3600.500000</td>\n",
       "      <td>1800.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>12852</td>\n",
       "      <td>TEJADA, JERIC</td>\n",
       "      <td>27</td>\n",
       "      <td>MALE</td>\n",
       "      <td>LAGUNA</td>\n",
       "      <td>CRAFT AND TRADE</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>5000</td>\n",
       "      <td>500</td>\n",
       "      <td>400</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>8052</td>\n",
       "      <td>-8032</td>\n",
       "      <td>0</td>\n",
       "      <td>11948</td>\n",
       "      <td>1</td>\n",
       "      <td>-7532</td>\n",
       "      <td>0</td>\n",
       "      <td>12448</td>\n",
       "      <td>1</td>\n",
       "      <td>19980</td>\n",
       "      <td>1</td>\n",
       "      <td>-8032</td>\n",
       "      <td>0</td>\n",
       "      <td>11948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>402.600000</td>\n",
       "      <td>0.402600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>8052.000000</td>\n",
       "      <td>8052.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>12853</td>\n",
       "      <td>RAMOS, RHEALYN</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CAVITE</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>13962</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>40000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>1000</td>\n",
       "      <td>150</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3450</td>\n",
       "      <td>0</td>\n",
       "      <td>36462</td>\n",
       "      <td>-22500</td>\n",
       "      <td>0</td>\n",
       "      <td>3538</td>\n",
       "      <td>1</td>\n",
       "      <td>-20500</td>\n",
       "      <td>0</td>\n",
       "      <td>5538</td>\n",
       "      <td>1</td>\n",
       "      <td>26038</td>\n",
       "      <td>1</td>\n",
       "      <td>-22500</td>\n",
       "      <td>0</td>\n",
       "      <td>3538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349050</td>\n",
       "      <td>2.611517</td>\n",
       "      <td>0.911550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6981.000000</td>\n",
       "      <td>3490.500000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>18231.000000</td>\n",
       "      <td>9115.500000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>862.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>12854</td>\n",
       "      <td>BURGOS, LIEZEL</td>\n",
       "      <td>48</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ILOILO</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>51000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>51000</td>\n",
       "      <td>5000</td>\n",
       "      <td>3000</td>\n",
       "      <td>1500</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>41500</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>10500</td>\n",
       "      <td>1</td>\n",
       "      <td>10500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10200.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10200.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8300.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>12857</td>\n",
       "      <td>SEERES, JENNY MAE</td>\n",
       "      <td>24</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>98800</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>143800</td>\n",
       "      <td>7000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>1650</td>\n",
       "      <td>17000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7850</td>\n",
       "      <td>0</td>\n",
       "      <td>54350</td>\n",
       "      <td>44450</td>\n",
       "      <td>1</td>\n",
       "      <td>89450</td>\n",
       "      <td>1</td>\n",
       "      <td>54450</td>\n",
       "      <td>1</td>\n",
       "      <td>99450</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "      <td>1</td>\n",
       "      <td>44450</td>\n",
       "      <td>1</td>\n",
       "      <td>89450</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687065</td>\n",
       "      <td>0.550101</td>\n",
       "      <td>0.377955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32933.333333</td>\n",
       "      <td>32933.333333</td>\n",
       "      <td>47933.333333</td>\n",
       "      <td>47933.333333</td>\n",
       "      <td>18116.666667</td>\n",
       "      <td>18116.666667</td>\n",
       "      <td>2616.666667</td>\n",
       "      <td>2616.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows  97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId          lastFirstName  age  gender      province  \\\n",
       "0       370          IBALI, HOWARD   24    MALE  METRO MANILA   \n",
       "1      1025  PATALINGHOG, KIMBERLY   26  FEMALE  METRO MANILA   \n",
       "2      1105      TEMILLOSO, DENNIS   40    MALE  METRO MANILA   \n",
       "3      1719         OSCARES, ELMER   32    MALE       UNKNOWN   \n",
       "4      2081         LEGASPI, MANNY   39    MALE  METRO MANILA   \n",
       "...     ...                    ...  ...     ...           ...   \n",
       "1065  12850         LIPANGO, ARVIN   34    MALE  METRO MANILA   \n",
       "1066  12852          TEJADA, JERIC   27    MALE        LAGUNA   \n",
       "1067  12853         RAMOS, RHEALYN   27  FEMALE        CAVITE   \n",
       "1068  12854         BURGOS, LIEZEL   48  FEMALE        ILOILO   \n",
       "1069  12857     SEERES, JENNY MAE   24  FEMALE  METRO MANILA   \n",
       "\n",
       "                         job  basicMonthlySalary  \\\n",
       "0          SERVICE AND SALES               19000   \n",
       "1          SERVICE AND SALES               15000   \n",
       "2          SERVICE AND SALES               20000   \n",
       "3           MACHINE OPERATOR               21200   \n",
       "4           CLERICAL SUPPORT               19800   \n",
       "...                      ...                 ...   \n",
       "1065  ASSOCIATE PROFESSIONAL               19000   \n",
       "1066         CRAFT AND TRADE                  20   \n",
       "1067       SERVICE AND SALES               13962   \n",
       "1068       SERVICE AND SALES               51000   \n",
       "1069       SERVICE AND SALES               98800   \n",
       "\n",
       "      preferredNetDisposableIncomeId  workingFamilyCount  residentsCount  \\\n",
       "0                                  2                   3               3   \n",
       "1                                  3                   2               4   \n",
       "2                                  2                   0               3   \n",
       "3                                  2                   0               5   \n",
       "4                                  2                   0               0   \n",
       "...                              ...                 ...             ...   \n",
       "1065                               2                   2               4   \n",
       "1066                               2                   1               1   \n",
       "1067                               1                   2               4   \n",
       "1068                               2                   0               5   \n",
       "1069                               3                   3               3   \n",
       "\n",
       "      monthlyFamilyIncome  food  hygiene  houseCleaning  fare  parking  \\\n",
       "0                   40000  1000      500            200   200        0   \n",
       "1                   30000  5000     3000           2000  2000        0   \n",
       "2                   30000  3000      500            300   200       50   \n",
       "3                   12000  2000      500            200   392        0   \n",
       "4                   25000  5000     2000           1000  1500        0   \n",
       "...                   ...   ...      ...            ...   ...      ...   \n",
       "1065                19000  5000     1000           1000     1        1   \n",
       "1066                20000  5000      500            400   280        0   \n",
       "1067                40000     4        2              1     3        1   \n",
       "1068                51000  5000     3000           1500  2000        0   \n",
       "1069               143800  7000     3000           2000     0        0   \n",
       "\n",
       "      gasoline  tuition  allowance  uniform  otherEducation  emergency  \\\n",
       "0            0        0         50        0               0        500   \n",
       "1            0        0          0        0               0       2000   \n",
       "2           50      500        100      100              50        500   \n",
       "3            0        0          0        0               0        100   \n",
       "4            0     1000        500     1500               0          0   \n",
       "...        ...      ...        ...      ...             ...        ...   \n",
       "1065         1     1000        500        1            1000       1000   \n",
       "1066         0        0          0        0               0          0   \n",
       "1067         1        0          0        0               0      30000   \n",
       "1068         0    15000       9000        0               0       1000   \n",
       "1069      6000        0          0        0               0       5000   \n",
       "\n",
       "      medicine  water  electricity  rent  repair  cinema  dineOut  leisure  \\\n",
       "0          450      0            0     0       0       0        0        0   \n",
       "1            0    200          200  1000     500       0        0        0   \n",
       "2          100    200          500     0     200       0      100      100   \n",
       "3            0    200          200  3000       0       0        0        0   \n",
       "4         1000    300         1900     0    1000       0     1000     1000   \n",
       "...        ...    ...          ...   ...     ...     ...      ...      ...   \n",
       "1065       500    200         1500  5000    1000       1        1        1   \n",
       "1066         0      0            0     0       0       0        0        0   \n",
       "1067      1000    150         1000  2000     500       0     1000        0   \n",
       "1068      1000    300          800     0       0       0      500      500   \n",
       "1069      1000      0            0  6000       0     500     2000     1000   \n",
       "\n",
       "      personalCare  clothing  mobileLoad  internet  vehicleLoan  \\\n",
       "0                0         0          50         0            0   \n",
       "1                0         0           0         0            0   \n",
       "2              100       200         200       200            0   \n",
       "3              100       200         400         0            0   \n",
       "4             1500      1500         500      1600            0   \n",
       "...            ...       ...         ...       ...          ...   \n",
       "1065             1         1         500         1            1   \n",
       "1066             0         0         200         0            0   \n",
       "1067             0         0         300         0            0   \n",
       "1068           300       500         300       800            0   \n",
       "1069          1000      1000         200      1650        17000   \n",
       "\n",
       "      informalLenders  companyLoan  privateLoans  governmentLoans  smoking  \\\n",
       "0                   0            0             0                0        0   \n",
       "1                   0            0             0                0        0   \n",
       "2                   0            0             0                0        0   \n",
       "3                   0            0             0              876        0   \n",
       "4                   0            0             0                0        0   \n",
       "...               ...          ...           ...              ...      ...   \n",
       "1065                1            1             1                1        1   \n",
       "1066                0            0             0             1672        0   \n",
       "1067                0          500             0                0        0   \n",
       "1068                0            0             0                0        0   \n",
       "1069                0            0             0                0        0   \n",
       "\n",
       "      alcohol  gambling  smallLottery  otherVices  savings      OSDate  \\\n",
       "0           0         0             0           0     2000  18/10/2022   \n",
       "1           0         0             0           0     2000       FALSE   \n",
       "2           0         0             0           0     1000       FALSE   \n",
       "3           0         0             0           0      500       FALSE   \n",
       "4           0         0             0           0    10000       FALSE   \n",
       "...       ...       ...           ...         ...      ...         ...   \n",
       "1065        1         1             1           1     2000       FALSE   \n",
       "1066        0         0             0           0      500       FALSE   \n",
       "1067        0         0             0           0     2000       FALSE   \n",
       "1068        0         0             0           0     1000       FALSE   \n",
       "1069        0         0             0           0    10000       FALSE   \n",
       "\n",
       "      OSDate - dateEntry    HDMFDate  HDMFDate - dateEntry loanGroup loanVal  \\\n",
       "0                  179.0  01/03/2023                 313.0      SHDG  652000   \n",
       "1                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "2                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "3                    NaN  18/11/2022                 228.0        LE  800000   \n",
       "4                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "...                  ...         ...                   ...       ...     ...   \n",
       "1065                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1066                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1067                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1068                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1069                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "\n",
       "      loanPersonal  payInsurance  loanSSS  loanPagIbig  loanOthers  loanGSIS  \\\n",
       "0                0             0        0            0           0         0   \n",
       "1                0             0        1            1           0         0   \n",
       "2                0             0        0            0           0         0   \n",
       "3                0             0        1            0           0         0   \n",
       "4                0             0        0            0           0         0   \n",
       "...            ...           ...      ...          ...         ...       ...   \n",
       "1065             1             0        0            0           0         0   \n",
       "1066             0             0        1            1           0         0   \n",
       "1067             0             0        0            0           0         0   \n",
       "1068             0             0        0            0           0         0   \n",
       "1069             0             0        0            0           0         0   \n",
       "\n",
       "      payFamilySupport  houseHasFreelancer  houseHasBusiness  \\\n",
       "0                    0                   0                 0   \n",
       "1                    1                   0                 0   \n",
       "2                    0                   1                 0   \n",
       "3                    0                   0                 0   \n",
       "4                    0                   0                 0   \n",
       "...                ...                 ...               ...   \n",
       "1065                 0                   0                 0   \n",
       "1066                 0                   0                 0   \n",
       "1067                 0                   0                 0   \n",
       "1068                 0                   0                 0   \n",
       "1069                 0                   1                 0   \n",
       "\n",
       "      houseHasGovtEmployee  houseHasOFW  houseHasPrivateEmployee  \\\n",
       "0                        0            1                        1   \n",
       "1                        0            0                        1   \n",
       "2                        0            0                        1   \n",
       "3                        0            0                        1   \n",
       "4                        0            0                        0   \n",
       "...                    ...          ...                      ...   \n",
       "1065                     0            0                        1   \n",
       "1066                     0            0                        1   \n",
       "1067                     0            0                        1   \n",
       "1068                     0            1                        0   \n",
       "1069                     0            1                        1   \n",
       "\n",
       "      houseHasPensioner  houseOnlyFamily  houseExtendedFamily  \\\n",
       "0                     0                0                    1   \n",
       "1                     0                1                    0   \n",
       "2                     0                0                    1   \n",
       "3                     0                1                    0   \n",
       "4                     0                0                    0   \n",
       "...                 ...              ...                  ...   \n",
       "1065                  0                1                    0   \n",
       "1066                  0                0                    0   \n",
       "1067                  0                1                    0   \n",
       "1068                  0                0                    0   \n",
       "1069                  0                1                    0   \n",
       "\n",
       "      home_ownership_class  monthlyUtilityBills  monthlyVices  \\\n",
       "0                        1                   50             0   \n",
       "1                        1                 1400             0   \n",
       "2                        1                 1100             0   \n",
       "3                        1                 3800             0   \n",
       "4                        1                 4300             0   \n",
       "...                    ...                  ...           ...   \n",
       "1065                     1                 7201             5   \n",
       "1066                     1                  200             0   \n",
       "1067                     1                 3450             0   \n",
       "1068                     1                 2200             0   \n",
       "1069                     1                 7850             0   \n",
       "\n",
       "      monthlyExpenses  monthlySoloNetIncome  positiveMonthlySoloNetIncome  \\\n",
       "0                2950                 16050                             1   \n",
       "1               15900                  -900                             0   \n",
       "2                7250                 12750                             1   \n",
       "3                8168                 13032                             1   \n",
       "4               23800                 -4000                             0   \n",
       "...               ...                   ...                           ...   \n",
       "1065            19220                  -220                             0   \n",
       "1066             8052                 -8032                             0   \n",
       "1067            36462                -22500                             0   \n",
       "1068            41500                  9500                             1   \n",
       "1069            54350                 44450                             1   \n",
       "\n",
       "      monthlyFamilyNetIncome  positiveMonthlyFamilyNetIncome  \\\n",
       "0                      37050                               1   \n",
       "1                      14100                               1   \n",
       "2                      22750                               1   \n",
       "3                       3832                               1   \n",
       "4                       1200                               1   \n",
       "...                      ...                             ...   \n",
       "1065                    -220                               0   \n",
       "1066                   11948                               1   \n",
       "1067                    3538                               1   \n",
       "1068                    9500                               1   \n",
       "1069                   89450                               1   \n",
       "\n",
       "      monthlySoloNetIncomeWithSavings  \\\n",
       "0                               18050   \n",
       "1                                1100   \n",
       "2                               13750   \n",
       "3                               13532   \n",
       "4                                6000   \n",
       "...                               ...   \n",
       "1065                             1780   \n",
       "1066                            -7532   \n",
       "1067                           -20500   \n",
       "1068                            10500   \n",
       "1069                            54450   \n",
       "\n",
       "      positiveMonthlySoloNetIncomeWithSavings  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "...                                       ...   \n",
       "1065                                        1   \n",
       "1066                                        0   \n",
       "1067                                        0   \n",
       "1068                                        1   \n",
       "1069                                        1   \n",
       "\n",
       "      monthlyFamilyNetIncomeWithSavings  \\\n",
       "0                                 39050   \n",
       "1                                 16100   \n",
       "2                                 23750   \n",
       "3                                  4332   \n",
       "4                                 11200   \n",
       "...                                 ...   \n",
       "1065                               1780   \n",
       "1066                              12448   \n",
       "1067                               5538   \n",
       "1068                              10500   \n",
       "1069                              99450   \n",
       "\n",
       "      positiveMonthlyFamilyNetIncomeWithSavings  \\\n",
       "0                                             1   \n",
       "1                                             1   \n",
       "2                                             1   \n",
       "3                                             1   \n",
       "4                                             1   \n",
       "...                                         ...   \n",
       "1065                                          1   \n",
       "1066                                          1   \n",
       "1067                                          1   \n",
       "1068                                          1   \n",
       "1069                                          1   \n",
       "\n",
       "      monthlyFamilyIncome - basicMonthlySalary  \\\n",
       "0                                        21000   \n",
       "1                                        15000   \n",
       "2                                        10000   \n",
       "3                                        -9200   \n",
       "4                                         5200   \n",
       "...                                        ...   \n",
       "1065                                         0   \n",
       "1066                                     19980   \n",
       "1067                                     26038   \n",
       "1068                                         0   \n",
       "1069                                     45000   \n",
       "\n",
       "      positive monthlyFamilyIncome - basicMonthlySalary  \\\n",
       "0                                                     1   \n",
       "1                                                     1   \n",
       "2                                                     1   \n",
       "3                                                     0   \n",
       "4                                                     1   \n",
       "...                                                 ...   \n",
       "1065                                                  0   \n",
       "1066                                                  1   \n",
       "1067                                                  1   \n",
       "1068                                                  0   \n",
       "1069                                                  1   \n",
       "\n",
       "      basicMonthlySalary - monthlyExpenses  \\\n",
       "0                                    16050   \n",
       "1                                     -900   \n",
       "2                                    12750   \n",
       "3                                    13032   \n",
       "4                                    -4000   \n",
       "...                                    ...   \n",
       "1065                                  -220   \n",
       "1066                                 -8032   \n",
       "1067                                -22500   \n",
       "1068                                  9500   \n",
       "1069                                 44450   \n",
       "\n",
       "      positive basicMonthlySalary - monthlyExpenses  \\\n",
       "0                                                 1   \n",
       "1                                                 0   \n",
       "2                                                 1   \n",
       "3                                                 1   \n",
       "4                                                 0   \n",
       "...                                             ...   \n",
       "1065                                              0   \n",
       "1066                                              0   \n",
       "1067                                              0   \n",
       "1068                                              1   \n",
       "1069                                              1   \n",
       "\n",
       "      monthlyFamilyIncome - monthlyExpenses  \\\n",
       "0                                     37050   \n",
       "1                                     14100   \n",
       "2                                     22750   \n",
       "3                                      3832   \n",
       "4                                      1200   \n",
       "...                                     ...   \n",
       "1065                                   -220   \n",
       "1066                                  11948   \n",
       "1067                                   3538   \n",
       "1068                                   9500   \n",
       "1069                                  89450   \n",
       "\n",
       "      positive monthlyFamilyIncome - monthlyExpenses  \\\n",
       "0                                                  1   \n",
       "1                                                  1   \n",
       "2                                                  1   \n",
       "3                                                  1   \n",
       "4                                                  1   \n",
       "...                                              ...   \n",
       "1065                                               0   \n",
       "1066                                               1   \n",
       "1067                                               1   \n",
       "1068                                               1   \n",
       "1069                                               1   \n",
       "\n",
       "      basicMonthlySalary / monthlyFamilyIncome  \\\n",
       "0                                     0.475000   \n",
       "1                                     0.500000   \n",
       "2                                     0.666667   \n",
       "3                                     1.766667   \n",
       "4                                     0.792000   \n",
       "...                                        ...   \n",
       "1065                                  1.000000   \n",
       "1066                                  0.001000   \n",
       "1067                                  0.349050   \n",
       "1068                                  1.000000   \n",
       "1069                                  0.687065   \n",
       "\n",
       "      monthlyExpenses / basicMonthlySalary  \\\n",
       "0                                 0.155263   \n",
       "1                                 1.060000   \n",
       "2                                 0.362500   \n",
       "3                                 0.385283   \n",
       "4                                 1.202020   \n",
       "...                                    ...   \n",
       "1065                              1.011579   \n",
       "1066                            402.600000   \n",
       "1067                              2.611517   \n",
       "1068                              0.813725   \n",
       "1069                              0.550101   \n",
       "\n",
       "      monthlyExpenses / monthlyFamilyIncome  \\\n",
       "0                                  0.073750   \n",
       "1                                  0.530000   \n",
       "2                                  0.241667   \n",
       "3                                  0.680667   \n",
       "4                                  0.952000   \n",
       "...                                     ...   \n",
       "1065                               1.011579   \n",
       "1066                               0.402600   \n",
       "1067                               0.911550   \n",
       "1068                               0.813725   \n",
       "1069                               0.377955   \n",
       "\n",
       "      monthlyVices / basicMonthlySalary  monthlyVices / monthlyFamilyIncome  \\\n",
       "0                              0.000000                            0.000000   \n",
       "1                              0.000000                            0.000000   \n",
       "2                              0.000000                            0.000000   \n",
       "3                              0.000000                            0.000000   \n",
       "4                              0.000000                            0.000000   \n",
       "...                                 ...                                 ...   \n",
       "1065                           0.000263                            0.000263   \n",
       "1066                           0.000000                            0.000000   \n",
       "1067                           0.000000                            0.000000   \n",
       "1068                           0.000000                            0.000000   \n",
       "1069                           0.000000                            0.000000   \n",
       "\n",
       "      basicMonthlySalary / workingFamilyCount  \\\n",
       "0                                 6333.333333   \n",
       "1                                 7500.000000   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "...                                       ...   \n",
       "1065                              9500.000000   \n",
       "1066                                20.000000   \n",
       "1067                              6981.000000   \n",
       "1068                                      NaN   \n",
       "1069                             32933.333333   \n",
       "\n",
       "      basicMonthlySalary / residentsCount  \\\n",
       "0                             6333.333333   \n",
       "1                             3750.000000   \n",
       "2                             6666.666667   \n",
       "3                             4240.000000   \n",
       "4                                     NaN   \n",
       "...                                   ...   \n",
       "1065                          4750.000000   \n",
       "1066                            20.000000   \n",
       "1067                          3490.500000   \n",
       "1068                         10200.000000   \n",
       "1069                         32933.333333   \n",
       "\n",
       "      monthlyFamilyIncome / workingFamilyCount  \\\n",
       "0                                 13333.333333   \n",
       "1                                 15000.000000   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "1065                               9500.000000   \n",
       "1066                              20000.000000   \n",
       "1067                              20000.000000   \n",
       "1068                                       NaN   \n",
       "1069                              47933.333333   \n",
       "\n",
       "      monthlyFamilyIncome / residentsCount  \\\n",
       "0                             13333.333333   \n",
       "1                              7500.000000   \n",
       "2                             10000.000000   \n",
       "3                              2400.000000   \n",
       "4                                      NaN   \n",
       "...                                    ...   \n",
       "1065                           4750.000000   \n",
       "1066                          20000.000000   \n",
       "1067                          10000.000000   \n",
       "1068                          10200.000000   \n",
       "1069                          47933.333333   \n",
       "\n",
       "      monthlyExpenses / workingFamilyCount  monthlyExpenses / residentsCount  \\\n",
       "0                               983.333333                        983.333333   \n",
       "1                              7950.000000                       3975.000000   \n",
       "2                                      NaN                       2416.666667   \n",
       "3                                      NaN                       1633.600000   \n",
       "4                                      NaN                               NaN   \n",
       "...                                    ...                               ...   \n",
       "1065                           9610.000000                       4805.000000   \n",
       "1066                           8052.000000                       8052.000000   \n",
       "1067                          18231.000000                       9115.500000   \n",
       "1068                                   NaN                       8300.000000   \n",
       "1069                          18116.666667                      18116.666667   \n",
       "\n",
       "      monthlyUtilityBills / workingFamilyCount  \\\n",
       "0                                    16.666667   \n",
       "1                                   700.000000   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "1065                               3600.500000   \n",
       "1066                                200.000000   \n",
       "1067                               1725.000000   \n",
       "1068                                       NaN   \n",
       "1069                               2616.666667   \n",
       "\n",
       "      monthlyUtilityBills / residentsCount  \n",
       "0                                16.666667  \n",
       "1                               350.000000  \n",
       "2                               366.666667  \n",
       "3                               760.000000  \n",
       "4                                      NaN  \n",
       "...                                    ...  \n",
       "1065                           1800.250000  \n",
       "1066                            200.000000  \n",
       "1067                            862.500000  \n",
       "1068                            440.000000  \n",
       "1069                           2616.666667  \n",
       "\n",
       "[1070 rows x 97 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.copy()\n",
    "\n",
    "df['monthlyUtilityBills'] = (\n",
    "    df['water'] + df['electricity'] + df['rent'] +\n",
    "    df['internet'] + df['mobileLoad']\n",
    ")\n",
    "df['monthlyVices'] = (\n",
    "    df['smoking'] + df['alcohol'] + df['gambling'] +\n",
    "    df['smallLottery'] + df['otherVices']\n",
    ")\n",
    "df['monthlyExpenses'] = (\n",
    "    df['food'] + df['hygiene'] + df['houseCleaning'] +\n",
    "    df['fare'] + df['parking'] + df['gasoline'] +\n",
    "    df['tuition'] + df['allowance'] + df['uniform'] +\n",
    "    df['otherEducation'] + df['emergency'] + df['medicine'] +\n",
    "    df['repair'] + df['cinema'] + df['dineOut'] +\n",
    "    df['leisure'] + df['personalCare'] + df['clothing'] +\n",
    "    df['vehicleLoan'] + df['monthlyUtilityBills'] +\n",
    "    df['informalLenders'] + df['companyLoan'] + df['privateLoans'] +\n",
    "    df['governmentLoans'] + df['monthlyVices']\n",
    ")\n",
    "df['monthlySoloNetIncome'] = (\n",
    "    df['basicMonthlySalary'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positiveMonthlySoloNetIncome'] = (\n",
    "    df['monthlySoloNetIncome'] > 0\n",
    ").astype(int)\n",
    "df['monthlyFamilyNetIncome'] = (\n",
    "    df['monthlyFamilyIncome'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positiveMonthlyFamilyNetIncome'] = (\n",
    "    df['monthlyFamilyNetIncome'] > 0\n",
    ").astype(int)\n",
    "df['monthlySoloNetIncomeWithSavings'] = (\n",
    "    df['basicMonthlySalary'] + df['savings'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positiveMonthlySoloNetIncomeWithSavings'] = (\n",
    "    df['monthlySoloNetIncomeWithSavings'] > 0\n",
    ").astype(int)\n",
    "df['monthlyFamilyNetIncomeWithSavings'] = (\n",
    "    df['monthlyFamilyIncome'] + df['savings'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positiveMonthlyFamilyNetIncomeWithSavings'] = (\n",
    "    df['monthlyFamilyNetIncomeWithSavings'] > 0\n",
    ").astype(int)\n",
    "df['monthlyFamilyIncome - basicMonthlySalary'] = (\n",
    "    df['monthlyFamilyIncome'] - df['basicMonthlySalary']\n",
    ")\n",
    "df['positive monthlyFamilyIncome - basicMonthlySalary'] = (\n",
    "    df['monthlyFamilyIncome - basicMonthlySalary'] > 0\n",
    ").astype(int)\n",
    "df['basicMonthlySalary - monthlyExpenses'] = (\n",
    "    df['basicMonthlySalary'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positive basicMonthlySalary - monthlyExpenses'] = (\n",
    "    df['basicMonthlySalary - monthlyExpenses'] > 0\n",
    ").astype(int)\n",
    "df['monthlyFamilyIncome - monthlyExpenses'] = (\n",
    "    df['monthlyFamilyIncome'] - df['monthlyExpenses']\n",
    ")\n",
    "df['positive monthlyFamilyIncome - monthlyExpenses'] = (\n",
    "    df['monthlyFamilyIncome - monthlyExpenses'] > 0\n",
    ").astype(int)\n",
    "df['basicMonthlySalary / monthlyFamilyIncome'] = np.where(\n",
    "    df['monthlyFamilyIncome'] == 0,\n",
    "    np.nan,\n",
    "    df['basicMonthlySalary'] / df['monthlyFamilyIncome']\n",
    ")\n",
    "df['monthlyExpenses / basicMonthlySalary'] = np.where(\n",
    "    df['basicMonthlySalary'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyExpenses'] / df['basicMonthlySalary']\n",
    ")\n",
    "df['monthlyExpenses / monthlyFamilyIncome'] = np.where(\n",
    "    df['monthlyFamilyIncome'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyExpenses'] / df['monthlyFamilyIncome']\n",
    ")\n",
    "df['monthlyVices / basicMonthlySalary'] = np.where(\n",
    "    df['basicMonthlySalary'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyVices'] / df['basicMonthlySalary']\n",
    ")\n",
    "df['monthlyVices / monthlyFamilyIncome'] = np.where(\n",
    "    df['monthlyFamilyIncome'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyVices'] / df['monthlyFamilyIncome']\n",
    ")\n",
    "df['basicMonthlySalary / workingFamilyCount'] = np.where(\n",
    "    df['workingFamilyCount'] == 0,\n",
    "    np.nan,\n",
    "    df['basicMonthlySalary'] / df['workingFamilyCount']\n",
    ")\n",
    "df['basicMonthlySalary / residentsCount'] = np.where(\n",
    "    df['residentsCount'] == 0,\n",
    "    np.nan,\n",
    "    df['basicMonthlySalary'] / df['residentsCount']\n",
    ")\n",
    "df['monthlyFamilyIncome / workingFamilyCount'] = np.where(\n",
    "    df['workingFamilyCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyFamilyIncome'] / df['workingFamilyCount']\n",
    ")\n",
    "df['monthlyFamilyIncome / residentsCount'] = np.where(\n",
    "    df['residentsCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyFamilyIncome'] / df['residentsCount']\n",
    ")\n",
    "df['monthlyExpenses / workingFamilyCount'] = np.where(\n",
    "    df['workingFamilyCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyExpenses'] / df['workingFamilyCount']\n",
    ")\n",
    "df['monthlyExpenses / residentsCount'] = np.where(\n",
    "    df['residentsCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyExpenses'] / df['residentsCount']\n",
    ")\n",
    "df['monthlyUtilityBills / workingFamilyCount'] = np.where(\n",
    "    df['workingFamilyCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyUtilityBills'] / df['workingFamilyCount']\n",
    ")\n",
    "df['monthlyUtilityBills / residentsCount'] = np.where(\n",
    "    df['residentsCount'] == 0,\n",
    "    np.nan,\n",
    "    df['monthlyUtilityBills'] / df['residentsCount']\n",
    ")\n",
    "dataset = df.copy()\n",
    "\n",
    "# Convert all int32 columns to int64\n",
    "for col in dataset.select_dtypes(include='int32').columns:\n",
    "    dataset[col] = dataset[col].astype('int64')\n",
    "\n",
    "dataset['userId'] = dataset['userId'].astype(str)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1070 entries, 0 to 1069\n",
      "Data columns (total 97 columns):\n",
      " #   Column                                             Non-Null Count  Dtype  \n",
      "---  ------                                             --------------  -----  \n",
      " 0   userId                                             1070 non-null   object \n",
      " 1   lastFirstName                                      1070 non-null   object \n",
      " 2   age                                                1070 non-null   int64  \n",
      " 3   gender                                             1070 non-null   object \n",
      " 4   province                                           1070 non-null   object \n",
      " 5   job                                                1070 non-null   object \n",
      " 6   basicMonthlySalary                                 1070 non-null   int64  \n",
      " 7   preferredNetDisposableIncomeId                     1070 non-null   int64  \n",
      " 8   workingFamilyCount                                 1070 non-null   int64  \n",
      " 9   residentsCount                                     1070 non-null   int64  \n",
      " 10  monthlyFamilyIncome                                1070 non-null   int64  \n",
      " 11  food                                               1070 non-null   int64  \n",
      " 12  hygiene                                            1070 non-null   int64  \n",
      " 13  houseCleaning                                      1070 non-null   int64  \n",
      " 14  fare                                               1070 non-null   int64  \n",
      " 15  parking                                            1070 non-null   int64  \n",
      " 16  gasoline                                           1070 non-null   int64  \n",
      " 17  tuition                                            1070 non-null   int64  \n",
      " 18  allowance                                          1070 non-null   int64  \n",
      " 19  uniform                                            1070 non-null   int64  \n",
      " 20  otherEducation                                     1070 non-null   int64  \n",
      " 21  emergency                                          1070 non-null   int64  \n",
      " 22  medicine                                           1070 non-null   int64  \n",
      " 23  water                                              1070 non-null   int64  \n",
      " 24  electricity                                        1070 non-null   int64  \n",
      " 25  rent                                               1070 non-null   int64  \n",
      " 26  repair                                             1070 non-null   int64  \n",
      " 27  cinema                                             1070 non-null   int64  \n",
      " 28  dineOut                                            1070 non-null   int64  \n",
      " 29  leisure                                            1070 non-null   int64  \n",
      " 30  personalCare                                       1070 non-null   int64  \n",
      " 31  clothing                                           1070 non-null   int64  \n",
      " 32  mobileLoad                                         1070 non-null   int64  \n",
      " 33  internet                                           1070 non-null   int64  \n",
      " 34  vehicleLoan                                        1070 non-null   int64  \n",
      " 35  informalLenders                                    1070 non-null   int64  \n",
      " 36  companyLoan                                        1070 non-null   int64  \n",
      " 37  privateLoans                                       1070 non-null   int64  \n",
      " 38  governmentLoans                                    1070 non-null   int64  \n",
      " 39  smoking                                            1070 non-null   int64  \n",
      " 40  alcohol                                            1070 non-null   int64  \n",
      " 41  gambling                                           1070 non-null   int64  \n",
      " 42  smallLottery                                       1070 non-null   int64  \n",
      " 43  otherVices                                         1070 non-null   int64  \n",
      " 44  savings                                            1070 non-null   int64  \n",
      " 45  OSDate                                             1070 non-null   object \n",
      " 46  OSDate - dateEntry                                 36 non-null     float64\n",
      " 47  HDMFDate                                           1070 non-null   object \n",
      " 48  HDMFDate - dateEntry                               244 non-null    float64\n",
      " 49  loanGroup                                          1070 non-null   object \n",
      " 50  loanVal                                            1070 non-null   object \n",
      " 51  loanPersonal                                       1070 non-null   int64  \n",
      " 52  payInsurance                                       1070 non-null   int64  \n",
      " 53  loanSSS                                            1070 non-null   int64  \n",
      " 54  loanPagIbig                                        1070 non-null   int64  \n",
      " 55  loanOthers                                         1070 non-null   int64  \n",
      " 56  loanGSIS                                           1070 non-null   int64  \n",
      " 57  payFamilySupport                                   1070 non-null   int64  \n",
      " 58  houseHasFreelancer                                 1070 non-null   int64  \n",
      " 59  houseHasBusiness                                   1070 non-null   int64  \n",
      " 60  houseHasGovtEmployee                               1070 non-null   int64  \n",
      " 61  houseHasOFW                                        1070 non-null   int64  \n",
      " 62  houseHasPrivateEmployee                            1070 non-null   int64  \n",
      " 63  houseHasPensioner                                  1070 non-null   int64  \n",
      " 64  houseOnlyFamily                                    1070 non-null   int64  \n",
      " 65  houseExtendedFamily                                1070 non-null   int64  \n",
      " 66  home_ownership_class                               1070 non-null   int64  \n",
      " 67  monthlyUtilityBills                                1070 non-null   int64  \n",
      " 68  monthlyVices                                       1070 non-null   int64  \n",
      " 69  monthlyExpenses                                    1070 non-null   int64  \n",
      " 70  monthlySoloNetIncome                               1070 non-null   int64  \n",
      " 71  positiveMonthlySoloNetIncome                       1070 non-null   int64  \n",
      " 72  monthlyFamilyNetIncome                             1070 non-null   int64  \n",
      " 73  positiveMonthlyFamilyNetIncome                     1070 non-null   int64  \n",
      " 74  monthlySoloNetIncomeWithSavings                    1070 non-null   int64  \n",
      " 75  positiveMonthlySoloNetIncomeWithSavings            1070 non-null   int64  \n",
      " 76  monthlyFamilyNetIncomeWithSavings                  1070 non-null   int64  \n",
      " 77  positiveMonthlyFamilyNetIncomeWithSavings          1070 non-null   int64  \n",
      " 78  monthlyFamilyIncome - basicMonthlySalary           1070 non-null   int64  \n",
      " 79  positive monthlyFamilyIncome - basicMonthlySalary  1070 non-null   int64  \n",
      " 80  basicMonthlySalary - monthlyExpenses               1070 non-null   int64  \n",
      " 81  positive basicMonthlySalary - monthlyExpenses      1070 non-null   int64  \n",
      " 82  monthlyFamilyIncome - monthlyExpenses              1070 non-null   int64  \n",
      " 83  positive monthlyFamilyIncome - monthlyExpenses     1070 non-null   int64  \n",
      " 84  basicMonthlySalary / monthlyFamilyIncome           1070 non-null   float64\n",
      " 85  monthlyExpenses / basicMonthlySalary               1069 non-null   float64\n",
      " 86  monthlyExpenses / monthlyFamilyIncome              1070 non-null   float64\n",
      " 87  monthlyVices / basicMonthlySalary                  1069 non-null   float64\n",
      " 88  monthlyVices / monthlyFamilyIncome                 1070 non-null   float64\n",
      " 89  basicMonthlySalary / workingFamilyCount            935 non-null    float64\n",
      " 90  basicMonthlySalary / residentsCount                995 non-null    float64\n",
      " 91  monthlyFamilyIncome / workingFamilyCount           935 non-null    float64\n",
      " 92  monthlyFamilyIncome / residentsCount               995 non-null    float64\n",
      " 93  monthlyExpenses / workingFamilyCount               935 non-null    float64\n",
      " 94  monthlyExpenses / residentsCount                   995 non-null    float64\n",
      " 95  monthlyUtilityBills / workingFamilyCount           935 non-null    float64\n",
      " 96  monthlyUtilityBills / residentsCount               995 non-null    float64\n",
      "dtypes: float64(15), int64(73), object(9)\n",
      "memory usage: 811.0+ KB\n"
     ]
    }
   ],
   "source": [
    "cols_with_nulls = [\n",
    "    'monthlyExpenses / basicMonthlySalary',\n",
    "    'monthlyVices / basicMonthlySalary',\n",
    "    'basicMonthlySalary / workingFamilyCount',\n",
    "    'basicMonthlySalary / residentsCount',\n",
    "    'monthlyFamilyIncome / workingFamilyCount',\n",
    "    'monthlyFamilyIncome / residentsCount',\n",
    "    'monthlyExpenses / workingFamilyCount',\n",
    "    'monthlyExpenses / residentsCount',\n",
    "    'monthlyUtilityBills / workingFamilyCount',\n",
    "    'monthlyUtilityBills / residentsCount'\n",
    "]\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>lastFirstName</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>province</th>\n",
       "      <th>job</th>\n",
       "      <th>basicMonthlySalary</th>\n",
       "      <th>preferredNetDisposableIncomeId</th>\n",
       "      <th>workingFamilyCount</th>\n",
       "      <th>residentsCount</th>\n",
       "      <th>monthlyFamilyIncome</th>\n",
       "      <th>food</th>\n",
       "      <th>hygiene</th>\n",
       "      <th>houseCleaning</th>\n",
       "      <th>fare</th>\n",
       "      <th>parking</th>\n",
       "      <th>gasoline</th>\n",
       "      <th>tuition</th>\n",
       "      <th>allowance</th>\n",
       "      <th>uniform</th>\n",
       "      <th>otherEducation</th>\n",
       "      <th>emergency</th>\n",
       "      <th>medicine</th>\n",
       "      <th>water</th>\n",
       "      <th>electricity</th>\n",
       "      <th>rent</th>\n",
       "      <th>repair</th>\n",
       "      <th>cinema</th>\n",
       "      <th>dineOut</th>\n",
       "      <th>leisure</th>\n",
       "      <th>personalCare</th>\n",
       "      <th>clothing</th>\n",
       "      <th>mobileLoad</th>\n",
       "      <th>internet</th>\n",
       "      <th>vehicleLoan</th>\n",
       "      <th>informalLenders</th>\n",
       "      <th>companyLoan</th>\n",
       "      <th>privateLoans</th>\n",
       "      <th>governmentLoans</th>\n",
       "      <th>smoking</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>gambling</th>\n",
       "      <th>smallLottery</th>\n",
       "      <th>otherVices</th>\n",
       "      <th>savings</th>\n",
       "      <th>OSDate</th>\n",
       "      <th>OSDate - dateEntry</th>\n",
       "      <th>HDMFDate</th>\n",
       "      <th>HDMFDate - dateEntry</th>\n",
       "      <th>loanGroup</th>\n",
       "      <th>loanVal</th>\n",
       "      <th>loanPersonal</th>\n",
       "      <th>payInsurance</th>\n",
       "      <th>loanSSS</th>\n",
       "      <th>loanPagIbig</th>\n",
       "      <th>loanOthers</th>\n",
       "      <th>loanGSIS</th>\n",
       "      <th>payFamilySupport</th>\n",
       "      <th>houseHasFreelancer</th>\n",
       "      <th>houseHasBusiness</th>\n",
       "      <th>houseHasGovtEmployee</th>\n",
       "      <th>houseHasOFW</th>\n",
       "      <th>houseHasPrivateEmployee</th>\n",
       "      <th>houseHasPensioner</th>\n",
       "      <th>houseOnlyFamily</th>\n",
       "      <th>houseExtendedFamily</th>\n",
       "      <th>home_ownership_class</th>\n",
       "      <th>monthlyUtilityBills</th>\n",
       "      <th>monthlyVices</th>\n",
       "      <th>monthlyExpenses</th>\n",
       "      <th>monthlySoloNetIncome</th>\n",
       "      <th>positiveMonthlySoloNetIncome</th>\n",
       "      <th>monthlyFamilyNetIncome</th>\n",
       "      <th>positiveMonthlyFamilyNetIncome</th>\n",
       "      <th>monthlySoloNetIncomeWithSavings</th>\n",
       "      <th>positiveMonthlySoloNetIncomeWithSavings</th>\n",
       "      <th>monthlyFamilyNetIncomeWithSavings</th>\n",
       "      <th>positiveMonthlyFamilyNetIncomeWithSavings</th>\n",
       "      <th>monthlyFamilyIncome - basicMonthlySalary</th>\n",
       "      <th>positive monthlyFamilyIncome - basicMonthlySalary</th>\n",
       "      <th>basicMonthlySalary - monthlyExpenses</th>\n",
       "      <th>positive basicMonthlySalary - monthlyExpenses</th>\n",
       "      <th>monthlyFamilyIncome - monthlyExpenses</th>\n",
       "      <th>positive monthlyFamilyIncome - monthlyExpenses</th>\n",
       "      <th>basicMonthlySalary / monthlyFamilyIncome</th>\n",
       "      <th>monthlyExpenses / basicMonthlySalary</th>\n",
       "      <th>monthlyExpenses / monthlyFamilyIncome</th>\n",
       "      <th>monthlyVices / basicMonthlySalary</th>\n",
       "      <th>monthlyVices / monthlyFamilyIncome</th>\n",
       "      <th>basicMonthlySalary / workingFamilyCount</th>\n",
       "      <th>basicMonthlySalary / residentsCount</th>\n",
       "      <th>monthlyFamilyIncome / workingFamilyCount</th>\n",
       "      <th>monthlyFamilyIncome / residentsCount</th>\n",
       "      <th>monthlyExpenses / workingFamilyCount</th>\n",
       "      <th>monthlyExpenses / residentsCount</th>\n",
       "      <th>monthlyUtilityBills / workingFamilyCount</th>\n",
       "      <th>monthlyUtilityBills / residentsCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370</td>\n",
       "      <td>IBALI, HOWARD</td>\n",
       "      <td>24</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>19000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>40000</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>18/10/2022</td>\n",
       "      <td>179.0</td>\n",
       "      <td>01/03/2023</td>\n",
       "      <td>313.0</td>\n",
       "      <td>SHDG</td>\n",
       "      <td>652000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2950</td>\n",
       "      <td>16050</td>\n",
       "      <td>1</td>\n",
       "      <td>37050</td>\n",
       "      <td>1</td>\n",
       "      <td>18050</td>\n",
       "      <td>1</td>\n",
       "      <td>39050</td>\n",
       "      <td>1</td>\n",
       "      <td>21000</td>\n",
       "      <td>1</td>\n",
       "      <td>16050</td>\n",
       "      <td>1</td>\n",
       "      <td>37050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.155263</td>\n",
       "      <td>0.073750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6333.333333</td>\n",
       "      <td>6333.333333</td>\n",
       "      <td>13333.333333</td>\n",
       "      <td>13333.333333</td>\n",
       "      <td>983.333333</td>\n",
       "      <td>983.333333</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1025</td>\n",
       "      <td>PATALINGHOG, KIMBERLY</td>\n",
       "      <td>26</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>5000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>15900</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>14100</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>16100</td>\n",
       "      <td>1</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>14100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7950.000000</td>\n",
       "      <td>3975.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>350.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1105</td>\n",
       "      <td>TEMILLOSO, DENNIS</td>\n",
       "      <td>40</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30000</td>\n",
       "      <td>3000</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "      <td>7250</td>\n",
       "      <td>12750</td>\n",
       "      <td>1</td>\n",
       "      <td>22750</td>\n",
       "      <td>1</td>\n",
       "      <td>13750</td>\n",
       "      <td>1</td>\n",
       "      <td>23750</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>12750</td>\n",
       "      <td>1</td>\n",
       "      <td>22750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6666.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2416.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1719</td>\n",
       "      <td>OSCARES, ELMER</td>\n",
       "      <td>32</td>\n",
       "      <td>MALE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>MACHINE OPERATOR</td>\n",
       "      <td>21200</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12000</td>\n",
       "      <td>2000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/11/2022</td>\n",
       "      <td>228.0</td>\n",
       "      <td>LE</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3800</td>\n",
       "      <td>0</td>\n",
       "      <td>8168</td>\n",
       "      <td>13032</td>\n",
       "      <td>1</td>\n",
       "      <td>3832</td>\n",
       "      <td>1</td>\n",
       "      <td>13532</td>\n",
       "      <td>1</td>\n",
       "      <td>4332</td>\n",
       "      <td>1</td>\n",
       "      <td>-9200</td>\n",
       "      <td>0</td>\n",
       "      <td>13032</td>\n",
       "      <td>1</td>\n",
       "      <td>3832</td>\n",
       "      <td>1</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.385283</td>\n",
       "      <td>0.680667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1633.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2081</td>\n",
       "      <td>LEGASPI, MANNY</td>\n",
       "      <td>39</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>CLERICAL SUPPORT</td>\n",
       "      <td>19800</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>5000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>500</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4300</td>\n",
       "      <td>0</td>\n",
       "      <td>23800</td>\n",
       "      <td>-4000</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>11200</td>\n",
       "      <td>1</td>\n",
       "      <td>5200</td>\n",
       "      <td>1</td>\n",
       "      <td>-4000</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>1.202020</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>12850</td>\n",
       "      <td>LIPANGO, ARVIN</td>\n",
       "      <td>34</td>\n",
       "      <td>MALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>ASSOCIATE PROFESSIONAL</td>\n",
       "      <td>19000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>1500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7201</td>\n",
       "      <td>5</td>\n",
       "      <td>19220</td>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "      <td>1780</td>\n",
       "      <td>1</td>\n",
       "      <td>1780</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.011579</td>\n",
       "      <td>1.011579</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>9500.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "      <td>9500.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>4805.000000</td>\n",
       "      <td>3600.500000</td>\n",
       "      <td>1800.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>12852</td>\n",
       "      <td>TEJADA, JERIC</td>\n",
       "      <td>27</td>\n",
       "      <td>MALE</td>\n",
       "      <td>LAGUNA</td>\n",
       "      <td>CRAFT AND TRADE</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>5000</td>\n",
       "      <td>500</td>\n",
       "      <td>400</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>8052</td>\n",
       "      <td>-8032</td>\n",
       "      <td>0</td>\n",
       "      <td>11948</td>\n",
       "      <td>1</td>\n",
       "      <td>-7532</td>\n",
       "      <td>0</td>\n",
       "      <td>12448</td>\n",
       "      <td>1</td>\n",
       "      <td>19980</td>\n",
       "      <td>1</td>\n",
       "      <td>-8032</td>\n",
       "      <td>0</td>\n",
       "      <td>11948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>402.600000</td>\n",
       "      <td>0.402600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>8052.000000</td>\n",
       "      <td>8052.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>12853</td>\n",
       "      <td>RAMOS, RHEALYN</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>CAVITE</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>13962</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>40000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>1000</td>\n",
       "      <td>150</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3450</td>\n",
       "      <td>0</td>\n",
       "      <td>36462</td>\n",
       "      <td>-22500</td>\n",
       "      <td>0</td>\n",
       "      <td>3538</td>\n",
       "      <td>1</td>\n",
       "      <td>-20500</td>\n",
       "      <td>0</td>\n",
       "      <td>5538</td>\n",
       "      <td>1</td>\n",
       "      <td>26038</td>\n",
       "      <td>1</td>\n",
       "      <td>-22500</td>\n",
       "      <td>0</td>\n",
       "      <td>3538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349050</td>\n",
       "      <td>2.611517</td>\n",
       "      <td>0.911550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6981.000000</td>\n",
       "      <td>3490.500000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>18231.000000</td>\n",
       "      <td>9115.500000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>862.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>12854</td>\n",
       "      <td>BURGOS, LIEZEL</td>\n",
       "      <td>48</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ILOILO</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>51000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>51000</td>\n",
       "      <td>5000</td>\n",
       "      <td>3000</td>\n",
       "      <td>1500</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>41500</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>10500</td>\n",
       "      <td>1</td>\n",
       "      <td>10500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10200.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10200.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8300.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>12857</td>\n",
       "      <td>SEERES, JENNY MAE</td>\n",
       "      <td>24</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>METRO MANILA</td>\n",
       "      <td>SERVICE AND SALES</td>\n",
       "      <td>98800</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>143800</td>\n",
       "      <td>7000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>1650</td>\n",
       "      <td>17000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7850</td>\n",
       "      <td>0</td>\n",
       "      <td>54350</td>\n",
       "      <td>44450</td>\n",
       "      <td>1</td>\n",
       "      <td>89450</td>\n",
       "      <td>1</td>\n",
       "      <td>54450</td>\n",
       "      <td>1</td>\n",
       "      <td>99450</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "      <td>1</td>\n",
       "      <td>44450</td>\n",
       "      <td>1</td>\n",
       "      <td>89450</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687065</td>\n",
       "      <td>0.550101</td>\n",
       "      <td>0.377955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32933.333333</td>\n",
       "      <td>32933.333333</td>\n",
       "      <td>47933.333333</td>\n",
       "      <td>47933.333333</td>\n",
       "      <td>18116.666667</td>\n",
       "      <td>18116.666667</td>\n",
       "      <td>2616.666667</td>\n",
       "      <td>2616.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows  97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId          lastFirstName  age  gender      province  \\\n",
       "0       370          IBALI, HOWARD   24    MALE  METRO MANILA   \n",
       "1      1025  PATALINGHOG, KIMBERLY   26  FEMALE  METRO MANILA   \n",
       "2      1105      TEMILLOSO, DENNIS   40    MALE  METRO MANILA   \n",
       "3      1719         OSCARES, ELMER   32    MALE       UNKNOWN   \n",
       "4      2081         LEGASPI, MANNY   39    MALE  METRO MANILA   \n",
       "...     ...                    ...  ...     ...           ...   \n",
       "1065  12850         LIPANGO, ARVIN   34    MALE  METRO MANILA   \n",
       "1066  12852          TEJADA, JERIC   27    MALE        LAGUNA   \n",
       "1067  12853         RAMOS, RHEALYN   27  FEMALE        CAVITE   \n",
       "1068  12854         BURGOS, LIEZEL   48  FEMALE        ILOILO   \n",
       "1069  12857     SEERES, JENNY MAE   24  FEMALE  METRO MANILA   \n",
       "\n",
       "                         job  basicMonthlySalary  \\\n",
       "0          SERVICE AND SALES               19000   \n",
       "1          SERVICE AND SALES               15000   \n",
       "2          SERVICE AND SALES               20000   \n",
       "3           MACHINE OPERATOR               21200   \n",
       "4           CLERICAL SUPPORT               19800   \n",
       "...                      ...                 ...   \n",
       "1065  ASSOCIATE PROFESSIONAL               19000   \n",
       "1066         CRAFT AND TRADE                  20   \n",
       "1067       SERVICE AND SALES               13962   \n",
       "1068       SERVICE AND SALES               51000   \n",
       "1069       SERVICE AND SALES               98800   \n",
       "\n",
       "      preferredNetDisposableIncomeId  workingFamilyCount  residentsCount  \\\n",
       "0                                  2                   3               3   \n",
       "1                                  3                   2               4   \n",
       "2                                  2                   0               3   \n",
       "3                                  2                   0               5   \n",
       "4                                  2                   0               0   \n",
       "...                              ...                 ...             ...   \n",
       "1065                               2                   2               4   \n",
       "1066                               2                   1               1   \n",
       "1067                               1                   2               4   \n",
       "1068                               2                   0               5   \n",
       "1069                               3                   3               3   \n",
       "\n",
       "      monthlyFamilyIncome  food  hygiene  houseCleaning  fare  parking  \\\n",
       "0                   40000  1000      500            200   200        0   \n",
       "1                   30000  5000     3000           2000  2000        0   \n",
       "2                   30000  3000      500            300   200       50   \n",
       "3                   12000  2000      500            200   392        0   \n",
       "4                   25000  5000     2000           1000  1500        0   \n",
       "...                   ...   ...      ...            ...   ...      ...   \n",
       "1065                19000  5000     1000           1000     1        1   \n",
       "1066                20000  5000      500            400   280        0   \n",
       "1067                40000     4        2              1     3        1   \n",
       "1068                51000  5000     3000           1500  2000        0   \n",
       "1069               143800  7000     3000           2000     0        0   \n",
       "\n",
       "      gasoline  tuition  allowance  uniform  otherEducation  emergency  \\\n",
       "0            0        0         50        0               0        500   \n",
       "1            0        0          0        0               0       2000   \n",
       "2           50      500        100      100              50        500   \n",
       "3            0        0          0        0               0        100   \n",
       "4            0     1000        500     1500               0          0   \n",
       "...        ...      ...        ...      ...             ...        ...   \n",
       "1065         1     1000        500        1            1000       1000   \n",
       "1066         0        0          0        0               0          0   \n",
       "1067         1        0          0        0               0      30000   \n",
       "1068         0    15000       9000        0               0       1000   \n",
       "1069      6000        0          0        0               0       5000   \n",
       "\n",
       "      medicine  water  electricity  rent  repair  cinema  dineOut  leisure  \\\n",
       "0          450      0            0     0       0       0        0        0   \n",
       "1            0    200          200  1000     500       0        0        0   \n",
       "2          100    200          500     0     200       0      100      100   \n",
       "3            0    200          200  3000       0       0        0        0   \n",
       "4         1000    300         1900     0    1000       0     1000     1000   \n",
       "...        ...    ...          ...   ...     ...     ...      ...      ...   \n",
       "1065       500    200         1500  5000    1000       1        1        1   \n",
       "1066         0      0            0     0       0       0        0        0   \n",
       "1067      1000    150         1000  2000     500       0     1000        0   \n",
       "1068      1000    300          800     0       0       0      500      500   \n",
       "1069      1000      0            0  6000       0     500     2000     1000   \n",
       "\n",
       "      personalCare  clothing  mobileLoad  internet  vehicleLoan  \\\n",
       "0                0         0          50         0            0   \n",
       "1                0         0           0         0            0   \n",
       "2              100       200         200       200            0   \n",
       "3              100       200         400         0            0   \n",
       "4             1500      1500         500      1600            0   \n",
       "...            ...       ...         ...       ...          ...   \n",
       "1065             1         1         500         1            1   \n",
       "1066             0         0         200         0            0   \n",
       "1067             0         0         300         0            0   \n",
       "1068           300       500         300       800            0   \n",
       "1069          1000      1000         200      1650        17000   \n",
       "\n",
       "      informalLenders  companyLoan  privateLoans  governmentLoans  smoking  \\\n",
       "0                   0            0             0                0        0   \n",
       "1                   0            0             0                0        0   \n",
       "2                   0            0             0                0        0   \n",
       "3                   0            0             0              876        0   \n",
       "4                   0            0             0                0        0   \n",
       "...               ...          ...           ...              ...      ...   \n",
       "1065                1            1             1                1        1   \n",
       "1066                0            0             0             1672        0   \n",
       "1067                0          500             0                0        0   \n",
       "1068                0            0             0                0        0   \n",
       "1069                0            0             0                0        0   \n",
       "\n",
       "      alcohol  gambling  smallLottery  otherVices  savings      OSDate  \\\n",
       "0           0         0             0           0     2000  18/10/2022   \n",
       "1           0         0             0           0     2000       FALSE   \n",
       "2           0         0             0           0     1000       FALSE   \n",
       "3           0         0             0           0      500       FALSE   \n",
       "4           0         0             0           0    10000       FALSE   \n",
       "...       ...       ...           ...         ...      ...         ...   \n",
       "1065        1         1             1           1     2000       FALSE   \n",
       "1066        0         0             0           0      500       FALSE   \n",
       "1067        0         0             0           0     2000       FALSE   \n",
       "1068        0         0             0           0     1000       FALSE   \n",
       "1069        0         0             0           0    10000       FALSE   \n",
       "\n",
       "      OSDate - dateEntry    HDMFDate  HDMFDate - dateEntry loanGroup loanVal  \\\n",
       "0                  179.0  01/03/2023                 313.0      SHDG  652000   \n",
       "1                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "2                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "3                    NaN  18/11/2022                 228.0        LE  800000   \n",
       "4                    NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "...                  ...         ...                   ...       ...     ...   \n",
       "1065                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1066                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1067                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1068                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "1069                 NaN       FALSE                   NaN     FALSE   FALSE   \n",
       "\n",
       "      loanPersonal  payInsurance  loanSSS  loanPagIbig  loanOthers  loanGSIS  \\\n",
       "0                0             0        0            0           0         0   \n",
       "1                0             0        1            1           0         0   \n",
       "2                0             0        0            0           0         0   \n",
       "3                0             0        1            0           0         0   \n",
       "4                0             0        0            0           0         0   \n",
       "...            ...           ...      ...          ...         ...       ...   \n",
       "1065             1             0        0            0           0         0   \n",
       "1066             0             0        1            1           0         0   \n",
       "1067             0             0        0            0           0         0   \n",
       "1068             0             0        0            0           0         0   \n",
       "1069             0             0        0            0           0         0   \n",
       "\n",
       "      payFamilySupport  houseHasFreelancer  houseHasBusiness  \\\n",
       "0                    0                   0                 0   \n",
       "1                    1                   0                 0   \n",
       "2                    0                   1                 0   \n",
       "3                    0                   0                 0   \n",
       "4                    0                   0                 0   \n",
       "...                ...                 ...               ...   \n",
       "1065                 0                   0                 0   \n",
       "1066                 0                   0                 0   \n",
       "1067                 0                   0                 0   \n",
       "1068                 0                   0                 0   \n",
       "1069                 0                   1                 0   \n",
       "\n",
       "      houseHasGovtEmployee  houseHasOFW  houseHasPrivateEmployee  \\\n",
       "0                        0            1                        1   \n",
       "1                        0            0                        1   \n",
       "2                        0            0                        1   \n",
       "3                        0            0                        1   \n",
       "4                        0            0                        0   \n",
       "...                    ...          ...                      ...   \n",
       "1065                     0            0                        1   \n",
       "1066                     0            0                        1   \n",
       "1067                     0            0                        1   \n",
       "1068                     0            1                        0   \n",
       "1069                     0            1                        1   \n",
       "\n",
       "      houseHasPensioner  houseOnlyFamily  houseExtendedFamily  \\\n",
       "0                     0                0                    1   \n",
       "1                     0                1                    0   \n",
       "2                     0                0                    1   \n",
       "3                     0                1                    0   \n",
       "4                     0                0                    0   \n",
       "...                 ...              ...                  ...   \n",
       "1065                  0                1                    0   \n",
       "1066                  0                0                    0   \n",
       "1067                  0                1                    0   \n",
       "1068                  0                0                    0   \n",
       "1069                  0                1                    0   \n",
       "\n",
       "      home_ownership_class  monthlyUtilityBills  monthlyVices  \\\n",
       "0                        1                   50             0   \n",
       "1                        1                 1400             0   \n",
       "2                        1                 1100             0   \n",
       "3                        1                 3800             0   \n",
       "4                        1                 4300             0   \n",
       "...                    ...                  ...           ...   \n",
       "1065                     1                 7201             5   \n",
       "1066                     1                  200             0   \n",
       "1067                     1                 3450             0   \n",
       "1068                     1                 2200             0   \n",
       "1069                     1                 7850             0   \n",
       "\n",
       "      monthlyExpenses  monthlySoloNetIncome  positiveMonthlySoloNetIncome  \\\n",
       "0                2950                 16050                             1   \n",
       "1               15900                  -900                             0   \n",
       "2                7250                 12750                             1   \n",
       "3                8168                 13032                             1   \n",
       "4               23800                 -4000                             0   \n",
       "...               ...                   ...                           ...   \n",
       "1065            19220                  -220                             0   \n",
       "1066             8052                 -8032                             0   \n",
       "1067            36462                -22500                             0   \n",
       "1068            41500                  9500                             1   \n",
       "1069            54350                 44450                             1   \n",
       "\n",
       "      monthlyFamilyNetIncome  positiveMonthlyFamilyNetIncome  \\\n",
       "0                      37050                               1   \n",
       "1                      14100                               1   \n",
       "2                      22750                               1   \n",
       "3                       3832                               1   \n",
       "4                       1200                               1   \n",
       "...                      ...                             ...   \n",
       "1065                    -220                               0   \n",
       "1066                   11948                               1   \n",
       "1067                    3538                               1   \n",
       "1068                    9500                               1   \n",
       "1069                   89450                               1   \n",
       "\n",
       "      monthlySoloNetIncomeWithSavings  \\\n",
       "0                               18050   \n",
       "1                                1100   \n",
       "2                               13750   \n",
       "3                               13532   \n",
       "4                                6000   \n",
       "...                               ...   \n",
       "1065                             1780   \n",
       "1066                            -7532   \n",
       "1067                           -20500   \n",
       "1068                            10500   \n",
       "1069                            54450   \n",
       "\n",
       "      positiveMonthlySoloNetIncomeWithSavings  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "...                                       ...   \n",
       "1065                                        1   \n",
       "1066                                        0   \n",
       "1067                                        0   \n",
       "1068                                        1   \n",
       "1069                                        1   \n",
       "\n",
       "      monthlyFamilyNetIncomeWithSavings  \\\n",
       "0                                 39050   \n",
       "1                                 16100   \n",
       "2                                 23750   \n",
       "3                                  4332   \n",
       "4                                 11200   \n",
       "...                                 ...   \n",
       "1065                               1780   \n",
       "1066                              12448   \n",
       "1067                               5538   \n",
       "1068                              10500   \n",
       "1069                              99450   \n",
       "\n",
       "      positiveMonthlyFamilyNetIncomeWithSavings  \\\n",
       "0                                             1   \n",
       "1                                             1   \n",
       "2                                             1   \n",
       "3                                             1   \n",
       "4                                             1   \n",
       "...                                         ...   \n",
       "1065                                          1   \n",
       "1066                                          1   \n",
       "1067                                          1   \n",
       "1068                                          1   \n",
       "1069                                          1   \n",
       "\n",
       "      monthlyFamilyIncome - basicMonthlySalary  \\\n",
       "0                                        21000   \n",
       "1                                        15000   \n",
       "2                                        10000   \n",
       "3                                        -9200   \n",
       "4                                         5200   \n",
       "...                                        ...   \n",
       "1065                                         0   \n",
       "1066                                     19980   \n",
       "1067                                     26038   \n",
       "1068                                         0   \n",
       "1069                                     45000   \n",
       "\n",
       "      positive monthlyFamilyIncome - basicMonthlySalary  \\\n",
       "0                                                     1   \n",
       "1                                                     1   \n",
       "2                                                     1   \n",
       "3                                                     0   \n",
       "4                                                     1   \n",
       "...                                                 ...   \n",
       "1065                                                  0   \n",
       "1066                                                  1   \n",
       "1067                                                  1   \n",
       "1068                                                  0   \n",
       "1069                                                  1   \n",
       "\n",
       "      basicMonthlySalary - monthlyExpenses  \\\n",
       "0                                    16050   \n",
       "1                                     -900   \n",
       "2                                    12750   \n",
       "3                                    13032   \n",
       "4                                    -4000   \n",
       "...                                    ...   \n",
       "1065                                  -220   \n",
       "1066                                 -8032   \n",
       "1067                                -22500   \n",
       "1068                                  9500   \n",
       "1069                                 44450   \n",
       "\n",
       "      positive basicMonthlySalary - monthlyExpenses  \\\n",
       "0                                                 1   \n",
       "1                                                 0   \n",
       "2                                                 1   \n",
       "3                                                 1   \n",
       "4                                                 0   \n",
       "...                                             ...   \n",
       "1065                                              0   \n",
       "1066                                              0   \n",
       "1067                                              0   \n",
       "1068                                              1   \n",
       "1069                                              1   \n",
       "\n",
       "      monthlyFamilyIncome - monthlyExpenses  \\\n",
       "0                                     37050   \n",
       "1                                     14100   \n",
       "2                                     22750   \n",
       "3                                      3832   \n",
       "4                                      1200   \n",
       "...                                     ...   \n",
       "1065                                   -220   \n",
       "1066                                  11948   \n",
       "1067                                   3538   \n",
       "1068                                   9500   \n",
       "1069                                  89450   \n",
       "\n",
       "      positive monthlyFamilyIncome - monthlyExpenses  \\\n",
       "0                                                  1   \n",
       "1                                                  1   \n",
       "2                                                  1   \n",
       "3                                                  1   \n",
       "4                                                  1   \n",
       "...                                              ...   \n",
       "1065                                               0   \n",
       "1066                                               1   \n",
       "1067                                               1   \n",
       "1068                                               1   \n",
       "1069                                               1   \n",
       "\n",
       "      basicMonthlySalary / monthlyFamilyIncome  \\\n",
       "0                                     0.475000   \n",
       "1                                     0.500000   \n",
       "2                                     0.666667   \n",
       "3                                     1.766667   \n",
       "4                                     0.792000   \n",
       "...                                        ...   \n",
       "1065                                  1.000000   \n",
       "1066                                  0.001000   \n",
       "1067                                  0.349050   \n",
       "1068                                  1.000000   \n",
       "1069                                  0.687065   \n",
       "\n",
       "      monthlyExpenses / basicMonthlySalary  \\\n",
       "0                                 0.155263   \n",
       "1                                 1.060000   \n",
       "2                                 0.362500   \n",
       "3                                 0.385283   \n",
       "4                                 1.202020   \n",
       "...                                    ...   \n",
       "1065                              1.011579   \n",
       "1066                            402.600000   \n",
       "1067                              2.611517   \n",
       "1068                              0.813725   \n",
       "1069                              0.550101   \n",
       "\n",
       "      monthlyExpenses / monthlyFamilyIncome  \\\n",
       "0                                  0.073750   \n",
       "1                                  0.530000   \n",
       "2                                  0.241667   \n",
       "3                                  0.680667   \n",
       "4                                  0.952000   \n",
       "...                                     ...   \n",
       "1065                               1.011579   \n",
       "1066                               0.402600   \n",
       "1067                               0.911550   \n",
       "1068                               0.813725   \n",
       "1069                               0.377955   \n",
       "\n",
       "      monthlyVices / basicMonthlySalary  monthlyVices / monthlyFamilyIncome  \\\n",
       "0                              0.000000                            0.000000   \n",
       "1                              0.000000                            0.000000   \n",
       "2                              0.000000                            0.000000   \n",
       "3                              0.000000                            0.000000   \n",
       "4                              0.000000                            0.000000   \n",
       "...                                 ...                                 ...   \n",
       "1065                           0.000263                            0.000263   \n",
       "1066                           0.000000                            0.000000   \n",
       "1067                           0.000000                            0.000000   \n",
       "1068                           0.000000                            0.000000   \n",
       "1069                           0.000000                            0.000000   \n",
       "\n",
       "      basicMonthlySalary / workingFamilyCount  \\\n",
       "0                                 6333.333333   \n",
       "1                                 7500.000000   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "...                                       ...   \n",
       "1065                              9500.000000   \n",
       "1066                                20.000000   \n",
       "1067                              6981.000000   \n",
       "1068                                      NaN   \n",
       "1069                             32933.333333   \n",
       "\n",
       "      basicMonthlySalary / residentsCount  \\\n",
       "0                             6333.333333   \n",
       "1                             3750.000000   \n",
       "2                             6666.666667   \n",
       "3                             4240.000000   \n",
       "4                                     NaN   \n",
       "...                                   ...   \n",
       "1065                          4750.000000   \n",
       "1066                            20.000000   \n",
       "1067                          3490.500000   \n",
       "1068                         10200.000000   \n",
       "1069                         32933.333333   \n",
       "\n",
       "      monthlyFamilyIncome / workingFamilyCount  \\\n",
       "0                                 13333.333333   \n",
       "1                                 15000.000000   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "1065                               9500.000000   \n",
       "1066                              20000.000000   \n",
       "1067                              20000.000000   \n",
       "1068                                       NaN   \n",
       "1069                              47933.333333   \n",
       "\n",
       "      monthlyFamilyIncome / residentsCount  \\\n",
       "0                             13333.333333   \n",
       "1                              7500.000000   \n",
       "2                             10000.000000   \n",
       "3                              2400.000000   \n",
       "4                                      NaN   \n",
       "...                                    ...   \n",
       "1065                           4750.000000   \n",
       "1066                          20000.000000   \n",
       "1067                          10000.000000   \n",
       "1068                          10200.000000   \n",
       "1069                          47933.333333   \n",
       "\n",
       "      monthlyExpenses / workingFamilyCount  monthlyExpenses / residentsCount  \\\n",
       "0                               983.333333                        983.333333   \n",
       "1                              7950.000000                       3975.000000   \n",
       "2                                      NaN                       2416.666667   \n",
       "3                                      NaN                       1633.600000   \n",
       "4                                      NaN                               NaN   \n",
       "...                                    ...                               ...   \n",
       "1065                           9610.000000                       4805.000000   \n",
       "1066                           8052.000000                       8052.000000   \n",
       "1067                          18231.000000                       9115.500000   \n",
       "1068                                   NaN                       8300.000000   \n",
       "1069                          18116.666667                      18116.666667   \n",
       "\n",
       "      monthlyUtilityBills / workingFamilyCount  \\\n",
       "0                                    16.666667   \n",
       "1                                   700.000000   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "1065                               3600.500000   \n",
       "1066                                200.000000   \n",
       "1067                               1725.000000   \n",
       "1068                                       NaN   \n",
       "1069                               2616.666667   \n",
       "\n",
       "      monthlyUtilityBills / residentsCount  \n",
       "0                                16.666667  \n",
       "1                               350.000000  \n",
       "2                               366.666667  \n",
       "3                               760.000000  \n",
       "4                                      NaN  \n",
       "...                                    ...  \n",
       "1065                           1800.250000  \n",
       "1066                            200.000000  \n",
       "1067                            862.500000  \n",
       "1068                            440.000000  \n",
       "1069                           2616.666667  \n",
       "\n",
       "[1070 rows x 97 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset[dataset['monthlyExpenses / basicMonthlySalary'].isnull()]\n",
    "# dataset = dataset.copy().drop(columns=['Unnamed: 0'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      36.000000\n",
       "mean     -291.333333\n",
       "std       711.310581\n",
       "min     -2158.000000\n",
       "25%      -347.500000\n",
       "50%        17.500000\n",
       "75%       200.500000\n",
       "max       275.000000\n",
       "Name: OSDate - dateEntry, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OSDate - dateEntry'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['OSDate - dateEntry'], bins=20, edgecolor='k')  # You can adjust the number of bins as needed\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Age')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     244.000000\n",
       "mean       44.913934\n",
       "std       157.208666\n",
       "min     -1620.000000\n",
       "25%        43.000000\n",
       "50%        63.000000\n",
       "75%        91.000000\n",
       "max       313.000000\n",
       "Name: HDMFDate - dateEntry, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HDMFDate - dateEntry'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['HDMFDate - dateEntry'], bins=20, edgecolor='k')  # You can adjust the number of bins as needed\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Age')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
